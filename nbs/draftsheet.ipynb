{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Required Libraries\n",
    "Import the necessary pdf2image and OpenAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required libraries\n",
    "from fastcore.all import AttrDict\n",
    "import io\n",
    "from pdf2image import convert_from_path\n",
    "from pypdf import PdfReader\n",
    "import openai\n",
    "import os\n",
    "import base64\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()  # Carga las variables de entorno desde .env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Convert PDF to Image\n",
    "Use PyPDF2 pdf2image to load the PDF file and convert it into an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the PDF file\n",
    "path = '../example_data/1.pdf'\n",
    "\n",
    "# Open and read the PDF file\n",
    "reader = PdfReader(path)\n",
    "\n",
    "# Check if the PDF has more than one page\n",
    "if len(reader.pages) > 1:\n",
    "    print(\"The PDF has more than one page. Only the first page will be converted to an image.\")\n",
    "\n",
    "# Convert the first page of the PDF to an image\n",
    "images = convert_from_path(path, first_page=1, last_page=1, fmt='jpeg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crop the image\n",
    "image = images[0].crop((0, 0, images[0].width, 450))\n",
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Call OpenAI ChatGPT API with Vision Model\n",
    "Use the OpenAI API to call the ChatGPT model with the vision capability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffered = io.BytesIO()\n",
    "images[0].save(buffered, format=\"JPEG\")\n",
    "base64_image = base64.b64encode(buffered.getvalue()).decode('utf-8')\n",
    "base64_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load moodle students information\n",
    "import pandas as pd\n",
    "\n",
    "# Cargar el CSV de alumnos y grupos\n",
    "students_info = [\"./../data/courseid_422_participants.csv\", \"./../data/courseid_23101_participants.csv\"]\n",
    "dfs = [ pd.read_csv(filename) for filename in students_info ]\n",
    "\n",
    "df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Puedes opcionalmente limpiar espacios y convertir a mayúsculas para facilitar coincidencias\n",
    "df[\"Nombre\"] = df[\"Nombre\"].str.strip().str.upper()\n",
    "df[\"Apellido(s)\"] = df[\"Apellido(s)\"].str.strip().str.upper()\n",
    "\n",
    "guia_texto = \"\\n\".join(\n",
    "    f\"{row['Nombre']} {row['Apellido(s)']} - Grupo: {row['Grupos']}\"\n",
    "    for _, row in df.iterrows()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(guia_texto[:3])\n",
    "#print(guia_texto[3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = os.environ[\"OPENAI_API_KEY\"] # *\n",
    "prompt = \"\"\"Extract the last name (Apellidos in Spanish), the first name (Nombre in Spanish) and the group (Grupo in Spanish)\n",
    " from the top of the image. You will find them handwritten after the labels `Apellidos`,  `Nombre` and `Grupo` respectively. The fields of your JSON output will have those exact same label names\n",
    " Here is a list of expected students and their groups as a reference: \n",
    " {guia_texto}\n",
    " \"\"\" # *\n",
    "model = \"gpt-4o\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "  \"Content-Type\": \"application/json\",\n",
    "  \"Authorization\": f\"Bearer {api_key}\"\n",
    "}\n",
    "\n",
    "payload = {\n",
    "  \"model\": f'{model}',\n",
    "  \"response_format\": { \"type\": \"json_object\" },\n",
    "  \"messages\": [\n",
    "    {\n",
    "        \"role\": \"system\", \n",
    "        \"content\": \"You are a helpful assistant designed to see an exam and output JSON \\\n",
    "           with the extracted information. You will be given an image of the exam.\\\n",
    "           the default group in case of empty string is extraviado\",   \n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": [\n",
    "        {\n",
    "          \"type\": \"text\",\n",
    "          \"text\": f\"{prompt}\"\n",
    "        },\n",
    "        {\n",
    "          \"type\": \"image_url\",\n",
    "          \"image_url\": {\n",
    "            \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "          }\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  ],\n",
    "  \"max_tokens\": 300\n",
    "}\n",
    "\n",
    "response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Apellidos': 'RODRIGUEZ FERNANDEZ', 'Nombre': 'VICTOR', 'Grupo': 'extraviado'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Obtener el JSON como string\n",
    "info_str = response.json()['choices'][0]['message']['content']\n",
    "\n",
    "# Convertir a diccionario Python\n",
    "info = json.loads(info_str)\n",
    "\n",
    "# Si el grupo está vacío, marcarlo como \"extraviado\"\n",
    "if not info.get(\"Grupo\"):  # También cubre None y \"\"\n",
    "    info[\"Grupo\"] = \"extraviado\"\n",
    "\n",
    "# Mostrar resultado\n",
    "print(info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add path to the info dictionary\n",
    "info['path'] = path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../example_data/1.pdf'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "import unicodedata\n",
    "import re\n",
    "\n",
    "def normalizar_texto(texto):\n",
    "    \"\"\"Normaliza texto eliminando acentos y caracteres especiales\"\"\"\n",
    "    texto = unicodedata.normalize('NFD', texto)\n",
    "    texto = ''.join(char for char in texto if unicodedata.category(char) != 'Mn')\n",
    "    texto = texto.upper().strip()\n",
    "    texto = re.sub(r'[^A-Z0-9\\s]', '', texto)\n",
    "    return texto\n",
    "\n",
    "def buscar_practica_en_zips(apellidos, nombre, practica_num=3, ruta_data=\"./../data/\"):\n",
    "    \"\"\"\n",
    "    Busca si existe una práctica para un alumno en los archivos ZIP\n",
    "    \n",
    "    Args:\n",
    "        apellidos: Apellidos del alumno\n",
    "        nombre: Nombre del alumno\n",
    "        practica_num: Número de práctica (3 o 5)\n",
    "        ruta_data: Ruta base a la carpeta data\n",
    "    \"\"\"\n",
    "    ruta_practica = Path(ruta_data) / f\"Practica{practica_num}\"\n",
    "    \n",
    "    if not ruta_practica.exists():\n",
    "        return False\n",
    "    \n",
    "    # Normalizar apellidos y nombre\n",
    "    apellidos_norm = normalizar_texto(apellidos)\n",
    "    nombre_norm = normalizar_texto(nombre)\n",
    "    \n",
    "    # Buscar en todos los archivos ZIP\n",
    "    for archivo_zip in ruta_practica.glob(\"*.zip\"):\n",
    "        try:\n",
    "            with zipfile.ZipFile(archivo_zip, 'r') as zip_ref:\n",
    "                for archivo in zip_ref.namelist():\n",
    "                    archivo_norm = normalizar_texto(archivo)\n",
    "                    \n",
    "                    # Verificar si el archivo contiene apellidos y nombre\n",
    "                    if apellidos_norm in archivo_norm and nombre_norm in archivo_norm:\n",
    "                        return True\n",
    "        except Exception as e:\n",
    "            continue\n",
    "    \n",
    "    return False\n",
    "\n",
    "def verificar_todas_las_practicas(df, ruta_data=\"./../data/\"):\n",
    "    \"\"\"\n",
    "    Añade columnas de verificación de prácticas al DataFrame existente\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame con columnas 'Nombre' y 'Apellido(s)'\n",
    "        ruta_data: Ruta base a la carpeta data\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame modificado con las nuevas columnas\n",
    "    \"\"\"\n",
    "    \n",
    "    # Crear copias para evitar warnings\n",
    "    df_resultado = df.copy()\n",
    "    \n",
    "    # Inicializar las nuevas columnas\n",
    "    df_resultado['Presentada_3'] = 0\n",
    "    df_resultado['Comentario_3'] = 'NP'\n",
    "    df_resultado['Presentada_5'] = 0\n",
    "    df_resultado['Comentario_5'] = 'NP'\n",
    "    \n",
    "    print(\"Verificando entregas de prácticas...\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    practicas_3_encontradas = 0\n",
    "    practicas_5_encontradas = 0\n",
    "    total_alumnos = len(df_resultado)\n",
    "    \n",
    "    for idx, row in df_resultado.iterrows():\n",
    "        nombre = str(row['Nombre'])\n",
    "        apellidos = str(row['Apellido(s)'])\n",
    "        \n",
    "        # Verificar Práctica 3\n",
    "        tiene_practica3 = buscar_practica_en_zips(apellidos, nombre, 3, ruta_data)\n",
    "        if tiene_practica3:\n",
    "            df_resultado.loc[idx, 'Presentada_3'] = 1\n",
    "            df_resultado.loc[idx, 'Comentario_3'] = ''\n",
    "            practicas_3_encontradas += 1\n",
    "        \n",
    "        # Verificar Práctica 5\n",
    "        tiene_practica5 = buscar_practica_en_zips(apellidos, nombre, 5, ruta_data)\n",
    "        if tiene_practica5:\n",
    "            df_resultado.loc[idx, 'Presentada_5'] = 1\n",
    "            df_resultado.loc[idx, 'Comentario_5'] = ''\n",
    "            practicas_5_encontradas += 1\n",
    "        \n",
    "        # Mostrar progreso\n",
    "        status_3 = \"✓\" if tiene_practica3 else \"✗\"\n",
    "        status_5 = \"✓\" if tiene_practica5 else \"✗\"\n",
    "        print(f\"{status_3} P3 | {status_5} P5 | {apellidos}, {nombre}\")\n",
    "    \n",
    "    print(\"=\"*50)\n",
    "    print(f\"RESUMEN:\")\n",
    "    print(f\"Total alumnos verificados: {total_alumnos}\")\n",
    "    print(f\"Práctica 3 - Entregadas: {practicas_3_encontradas} | No entregadas: {total_alumnos - practicas_3_encontradas}\")\n",
    "    print(f\"Práctica 5 - Entregadas: {practicas_5_encontradas} | No entregadas: {total_alumnos - practicas_5_encontradas}\")\n",
    "    \n",
    "    return df_resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame original cargado:\n",
      "Total alumnos: 444\n",
      "        Nombre       Apellido(s)                   Dirección de correo  \\\n",
      "0        SOFIA   AGAPITO DELGADO              s.agapito@alumnos.upm.es   \n",
      "1  LLOYD DAREN    AGUILAR DESIAR          daren.aguilar@alumnos.upm.es   \n",
      "2       JAVIER   AGUIRRE HERVIAS  javier.aguirrehervias@alumnos.upm.es   \n",
      "3        MATEO          ALBRIZIO         mateo.albrizio@alumnos.upm.es   \n",
      "4      NICOLAS  ALONSO FERNANDEZ              ni.alonso@alumnos.upm.es   \n",
      "\n",
      "    Grupos  \n",
      "0  IWSIT11  \n",
      "1  IWSIM12  \n",
      "2  IWSIM12  \n",
      "3  IWSIM12  \n",
      "4  IWSIM12  \n",
      "\n",
      "\n",
      "Verificando entregas de prácticas...\n",
      "==================================================\n",
      "✗ P3 | ✓ P5 | AGAPITO DELGADO, SOFIA\n",
      "✗ P3 | ✓ P5 | AGUILAR DESIAR, LLOYD DAREN\n",
      "✗ P3 | ✓ P5 | AGUIRRE HERVIAS, JAVIER\n",
      "✗ P3 | ✓ P5 | ALBRIZIO, MATEO\n",
      "✗ P3 | ✗ P5 | ALONSO FERNANDEZ, NICOLAS\n",
      "✗ P3 | ✓ P5 | ALVAREZ AREVALO, MIGUEL\n",
      "✗ P3 | ✓ P5 | APUNTE SIERRA, AARON ALEJANDRO\n",
      "✗ P3 | ✗ P5 | ARTACHO BORDINO, JORGE\n",
      "✗ P3 | ✓ P5 | AUSIN MORENO, MARCOS\n",
      "✗ P3 | ✓ P5 | AYALA MAYA, JULIO\n",
      "✗ P3 | ✓ P5 | AYDIN CONDE, ALP ASLAN\n",
      "✓ P3 | ✓ P5 | BABYN BABYN, DAVID\n",
      "✗ P3 | ✓ P5 | BALLESTEROS LESMES, JAVIER\n",
      "✓ P3 | ✓ P5 | BARRERA VELASQUEZ, ESAU EZEQUIEL\n",
      "✓ P3 | ✓ P5 | BEAUTELL NAVARRO, HUGO\n",
      "✗ P3 | ✗ P5 | BELTRAN PRADOS, CARLOS\n",
      "✓ P3 | ✗ P5 | BENJELLOUN, GHITA\n",
      "✗ P3 | ✓ P5 | BLANCO MARCHAL, SIMON\n",
      "✗ P3 | ✓ P5 | BLANCO VAZQUEZ, XABIER\n",
      "✓ P3 | ✓ P5 | BLASCO RIVAS, SERGIO\n",
      "✗ P3 | ✓ P5 | BRAVO CUEVA, ALVARO\n",
      "✗ P3 | ✓ P5 | BUENO MORENO, ISMAEL\n",
      "✗ P3 | ✓ P5 | CABRAS BLASCO, DANIEL\n",
      "✗ P3 | ✓ P5 | CAMARA VILKOVA, VERONICA LUISA\n",
      "✓ P3 | ✓ P5 | CARO ANCOCHEA, RAFAEL\n",
      "✓ P3 | ✓ P5 | CARRASCO PARDO, SERGIO\n",
      "✗ P3 | ✗ P5 | CARRETERO TERRONES, GUILLERMO\n",
      "✗ P3 | ✗ P5 | CASANOVA MATEO, CARLOS\n",
      "✗ P3 | ✓ P5 | CEREZO LLEDO, ALVARO\n",
      "✗ P3 | ✓ P5 | CEREZO RODRIGUEZ, JERONIMO\n",
      "✗ P3 | ✓ P5 | CHEN, HAOYU\n",
      "✗ P3 | ✓ P5 | CHEN, NUO\n",
      "✗ P3 | ✗ P5 | CHEN, WENJUN\n",
      "✗ P3 | ✓ P5 | CIUCA, DENNIS ANDREI\n",
      "✓ P3 | ✓ P5 | COLINAS GARCIA, DIEGO\n",
      "✗ P3 | ✓ P5 | CONDE IZQUIERDO, SANTIAGO\n",
      "✗ P3 | ✗ P5 | CONEJERO NOVELO-CASANOVA, ALONSO\n",
      "✗ P3 | ✗ P5 | CORUT, NICOLAS ROBERT\n",
      "✗ P3 | ✓ P5 | CRESPO LAFUENTE, JUAN\n",
      "✗ P3 | ✓ P5 | CRUZ REAL, SEBASTIAN\n",
      "✗ P3 | ✓ P5 | DE ANTONIO BARON, SAUL\n",
      "✗ P3 | ✓ P5 | DE LA VEGA RODRIGUEZ, IGNACIO\n",
      "✗ P3 | ✓ P5 | DE LOS MOZOS DE LA CRUZ, DIEGO\n",
      "✗ P3 | ✗ P5 | DE VICENTE SALAZAR, FERNANDO\n",
      "✗ P3 | ✗ P5 | DEL CAZ SANZ, DIEGO\n",
      "✗ P3 | ✓ P5 | DELGADO GONZALEZ, VICTOR\n",
      "✗ P3 | ✗ P5 | DIAZ MARTINEZ, MIGUEL ANGEL\n",
      "✓ P3 | ✓ P5 | DIAZ PEÑA, JORGE\n",
      "✗ P3 | ✓ P5 | DIAZ SANTIAGO, JOEL\n",
      "✓ P3 | ✓ P5 | DIAZ SERRANO, MARIA JOSE\n",
      "✗ P3 | ✓ P5 | DOMINGUEZ ALVAREZ, JAVIER\n",
      "✗ P3 | ✓ P5 | DONG, JINGHONG\n",
      "✗ P3 | ✓ P5 | DRAGAN, ELISA ELENA\n",
      "✗ P3 | ✗ P5 | ELESPE CHELI, TOMAS\n",
      "✗ P3 | ✗ P5 | ELICES HERNANDEZ, MARTA\n",
      "✗ P3 | ✓ P5 | ELMJABBAD ESPINEL, OMAR\n",
      "✗ P3 | ✓ P5 | ELVIRA PEREZ, SAMUEL\n",
      "✗ P3 | ✓ P5 | EMILOV RADKOV, DANIEL\n",
      "✗ P3 | ✓ P5 | ESPADA GARCIA, MARCO ANIBAL\n",
      "✗ P3 | ✓ P5 | ESTRADA SARANGO, EDUARDO\n",
      "✗ P3 | ✗ P5 | EVALUADOR EXTERNO, DOCENTIA\n",
      "✗ P3 | ✓ P5 | FERNANDES SIMOES, ANDRES EDUARDO\n",
      "✗ P3 | ✓ P5 | FERNANDEZ CARRASCO, LAURA\n",
      "✗ P3 | ✓ P5 | FERNANDEZ DE LUZ RODRIGUEZ, JULIO\n",
      "✗ P3 | ✓ P5 | FERNANDEZ HERRERO, DIEGO\n",
      "✗ P3 | ✓ P5 | FIDALGO TAPIA, FROILAN\n",
      "✗ P3 | ✓ P5 | FRANCESCH COLOMER, DANIEL\n",
      "✗ P3 | ✗ P5 | FRUTOS VELASCO, JUAN ALBERTO DE\n",
      "✓ P3 | ✓ P5 | FUENTE MARTINEZ, HERNAN GABRIEL DE LA\n",
      "✗ P3 | ✗ P5 | FUERIS FRUTOS, MANUEL\n",
      "✗ P3 | ✓ P5 | GALLEGO GARCIA, ALEJANDRO\n",
      "✗ P3 | ✗ P5 | GARCIA ALVAREZ, NEMESIO\n",
      "✗ P3 | ✓ P5 | GARCIA AZCARRETA, MIGUEL\n",
      "✗ P3 | ✓ P5 | GARCIA GARCIA, VICTOR\n",
      "✗ P3 | ✓ P5 | GARCIA GARCIA-NAVAS, ALESSANDRO\n",
      "✗ P3 | ✓ P5 | GARCIA HERNANDEZ, ALEJANDRO\n",
      "✗ P3 | ✓ P5 | GARCIA LEON, HUGO\n",
      "✗ P3 | ✗ P5 | GARCIA MARTINEZ, DANIEL\n",
      "✗ P3 | ✗ P5 | GARCIA SIMARRRO, JAVIER\n",
      "✗ P3 | ✓ P5 | GARCIA SOTO, ADRIAN\n",
      "✓ P3 | ✗ P5 | GARCIA VIDAL, ANTON\n",
      "✗ P3 | ✗ P5 | GARCIA-MINGUILLAN FERNANDEZ, DAVID\n",
      "✗ P3 | ✗ P5 | GHEORGHITA CARAPET, LUCAS\n",
      "✗ P3 | ✓ P5 | GIL ESTEBAN, DAVID\n",
      "✗ P3 | ✓ P5 | GONZALEZ BENITO, ANDRES\n",
      "✗ P3 | ✓ P5 | GONZALEZ RAMON, ANDRES\n",
      "✗ P3 | ✓ P5 | GUEVARA BERRUGA, JAIME\n",
      "✗ P3 | ✓ P5 | GUINEA RODRIGUEZ LOSADA, SANTIAGO\n",
      "✗ P3 | ✗ P5 | HARVEY MARTIN, DAVID\n",
      "✓ P3 | ✓ P5 | HEINRICKS GONZALEZ, BRANDON\n",
      "✗ P3 | ✗ P5 | HERNANDEZ DORADO, ANA\n",
      "✗ P3 | ✓ P5 | HERNANDEZ GARNACHO, JOSE ANGEL\n",
      "✗ P3 | ✓ P5 | HERNANDEZ MONTERO, LUCIA\n",
      "✗ P3 | ✗ P5 | HERRAN CEREZO, FRANCISCO\n",
      "✗ P3 | ✓ P5 | HERRERA GALERA, PEDRO ALEJANDRO\n",
      "✗ P3 | ✓ P5 | HIDALGO PARIENTE, MARCO\n",
      "✗ P3 | ✗ P5 | HUANG, JING\n",
      "✗ P3 | ✓ P5 | HUERTAS DIAZ, ALVARO\n",
      "✗ P3 | ✓ P5 | IANCU IANCU, GEORGIAN SORIN\n",
      "✓ P3 | ✓ P5 | IGLESIAS ALCAZAR, CARLOS\n",
      "✗ P3 | ✓ P5 | ILIYANOVA ATANASOVA, ALICIA\n",
      "✗ P3 | ✗ P5 | IÑIGO LAHERA, MATEO\n",
      "✗ P3 | ✓ P5 | IONESCU SOARE, ALEJANDRO RAFAEL\n",
      "✓ P3 | ✓ P5 | IVASIV KOSYK, MAXYM\n",
      "✗ P3 | ✗ P5 | JIANG ZHU, QIN HAO\n",
      "✗ P3 | ✓ P5 | JIMENEZ GARCIA, ANGELA\n",
      "✗ P3 | ✓ P5 | JIMENEZ JIMENEZ, ANDREA\n",
      "✗ P3 | ✓ P5 | JIMENEZ JIMENEZ, DIEGO\n",
      "✗ P3 | ✓ P5 | JIMENEZ RAMOS, DANIEL\n",
      "✗ P3 | ✓ P5 | JUAREZ GELARDO, TOMAS\n",
      "✗ P3 | ✓ P5 | JUSUE ZAVALA, JOSE RAMON\n",
      "✗ P3 | ✓ P5 | KE, TAILI\n",
      "✗ P3 | ✗ P5 | LABRADA MEDINA, JAVIER\n",
      "✗ P3 | ✓ P5 | LAFUENTE SANZ, ALICIA\n",
      "✗ P3 | ✓ P5 | LEFTERACHE RAILEANU, NICOLAS ANDRES\n",
      "✗ P3 | ✓ P5 | LENCERO CARRILLO, OSCAR\n",
      "✗ P3 | ✓ P5 | LI, JILING\n",
      "✓ P3 | ✗ P5 | LIN, CRISTIAN\n",
      "✗ P3 | ✗ P5 | LIN, YUSHAN\n",
      "✗ P3 | ✓ P5 | LLORENTE VAQUERO, CARLOS\n",
      "✗ P3 | ✓ P5 | LOPEZ COLMENERO, ROSALIA\n",
      "✗ P3 | ✓ P5 | LOPEZ DE LA MANZANARA GARCIA, PABLO\n",
      "✗ P3 | ✓ P5 | LOPEZ HERNANDEZ, ANDRES\n",
      "✗ P3 | ✗ P5 | LOPEZ SOSA, JORGE\n",
      "✗ P3 | ✓ P5 | LORENZO MORO, ADRIAN\n",
      "✗ P3 | ✓ P5 | LOZANO MARCOS, MARTA\n",
      "✗ P3 | ✗ P5 | LU DONG, LUIS\n",
      "✗ P3 | ✓ P5 | MA, ANNI\n",
      "✗ P3 | ✗ P5 | MADRIDEJOS CHAMORRO, TELLO\n",
      "✗ P3 | ✓ P5 | MAHER FAIQ AL RAWE, MAHMOOD\n",
      "✓ P3 | ✓ P5 | MANZANARO CARABALLO, PABLO\n",
      "✗ P3 | ✓ P5 | MARINA NAVARRO, PAULA\n",
      "✗ P3 | ✓ P5 | MARQUEZ SANTAMARIA, ALVARO\n",
      "✗ P3 | ✓ P5 | MARTIN BALLESTER, DANIEL\n",
      "✗ P3 | ✓ P5 | MARTIN ESPAÑA, ANTONIO\n",
      "✗ P3 | ✓ P5 | MARTIN MARTIN, JORGE\n",
      "✓ P3 | ✓ P5 | MARTIN VERDUGO, CRISTINA\n",
      "✗ P3 | ✓ P5 | MARTINEZ, PAULA\n",
      "✗ P3 | ✗ P5 | MARTINEZ GARCIA, PILAR\n",
      "✗ P3 | ✓ P5 | MARTINEZ LOPEZ TERCERO, JESUS\n",
      "✓ P3 | ✓ P5 | MARTINEZ SEBASTIA, NACHO\n",
      "✓ P3 | ✓ P5 | MATEOS ABAD, HUGO\n",
      "✗ P3 | ✓ P5 | MATHEUS GONCALVEZ, DANIEL ALEJANDRO\n",
      "✓ P3 | ✓ P5 | MEDRANO MORATA, IGNACIO\n",
      "✗ P3 | ✓ P5 | MENOYO PEREZ, ALVARO\n",
      "✗ P3 | ✓ P5 | MERINO FERNANDEZ, SOFIA\n",
      "✗ P3 | ✓ P5 | MOLERO GONZALEZ, SIMON\n",
      "✓ P3 | ✓ P5 | MONEDERO ANGULO, JAVIER\n",
      "✗ P3 | ✓ P5 | MONTARELO PADILLA, ALBERTO\n",
      "✗ P3 | ✗ P5 | MONTES BORJABAD, CLAUDIA\n",
      "✗ P3 | ✗ P5 | MORAIS MANRIQUE, SWAMY\n",
      "✗ P3 | ✓ P5 | MORALEDA SALGUERO, DAVID\n",
      "✗ P3 | ✓ P5 | MORALES DE LUIS, HECTOR\n",
      "✗ P3 | ✗ P5 | MORANT FERRANDO, OSCAR\n",
      "✗ P3 | ✗ P5 | MOREJON CANCHO, ALEJANDRO\n",
      "✗ P3 | ✓ P5 | MORENO VIRUETE, IGNACIO\n",
      "✗ P3 | ✓ P5 | MORENO-PALANCAS CEBALLOS, LUCAS\n",
      "✗ P3 | ✓ P5 | MOYA BLANCO, JESUS FRANCISCO\n",
      "✗ P3 | ✓ P5 | MOYA RIVERA, PABLO\n",
      "✗ P3 | ✗ P5 | MOYONERO ESPINOZA, VALENTINA NICOLLE\n",
      "✗ P3 | ✗ P5 | MOZO DE RIVAS, SARA\n",
      "✗ P3 | ✗ P5 | MUCIENTES CABALLO, ALBERTO\n",
      "✗ P3 | ✓ P5 | MUÑOZ FERNANDEZ, MIGUEL ANGEL\n",
      "✗ P3 | ✓ P5 | NARANJO MUÑOZ, ISMAEL\n",
      "✗ P3 | ✓ P5 | NAUTIYAL BHATT, NINAD\n",
      "✗ P3 | ✓ P5 | NAVARRETE HURTADO, IMANOL\n",
      "✗ P3 | ✓ P5 | NEIRA HERNANDEZ, HECTOR\n",
      "✗ P3 | ✓ P5 | NGOMO NCHAMA, ANTONIO ELA\n",
      "✓ P3 | ✓ P5 | OCAÑA MARTIN, MIGUEL\n",
      "✗ P3 | ✗ P5 | OCHOA GOMEZ, LUIS EMIRO\n",
      "✗ P3 | ✗ P5 | OFICIALDEGUI GONZALEZ-UBEDA, NICOLAS\n",
      "✗ P3 | ✓ P5 | ORTIZ PASAMONTES, MARCOS\n",
      "✓ P3 | ✓ P5 | OTERO MORENO, EKAITZ\n",
      "✗ P3 | ✓ P5 | PANTOJA FIGUEROA, ALEJANDRO\n",
      "✗ P3 | ✓ P5 | PARIS FERNANDEZ, JORGE\n",
      "✗ P3 | ✗ P5 | PASTOR GALINDO, JAVIER\n",
      "✗ P3 | ✓ P5 | PERALTA BARLE, LUCILA\n",
      "✗ P3 | ✗ P5 | PEREZ DIAZ, RODRIGO\n",
      "✗ P3 | ✓ P5 | PEREZ DIMAS, IZAN\n",
      "✗ P3 | ✗ P5 | PEREZ GONZALEZ, AGUEDA\n",
      "✗ P3 | ✓ P5 | PIÑA RODRIGUEZ, RODRIGO\n",
      "✓ P3 | ✗ P5 | PINILLOS ARELLANO, SERGIO\n",
      "✗ P3 | ✓ P5 | POENARU, TIMOTEI LUCIAN\n",
      "✗ P3 | ✓ P5 | PRIETO ALVAREZ, MARIA\n",
      "✓ P3 | ✗ P5 | QUISBERT CHOQUETICLLA, LEONEL\n",
      "✗ P3 | ✓ P5 | RAZZAK AKTER, TARIQUL ISLAM\n",
      "✓ P3 | ✗ P5 | REDONDO GUDE, JUAN JOSE\n",
      "✗ P3 | ✗ P5 | RIPOLL CARMONA, MARCO\n",
      "✗ P3 | ✓ P5 | ROBLES MARTIN, ALEJANDRO\n",
      "✗ P3 | ✓ P5 | ROCHA BENATTI, ENRIQUE\n",
      "✗ P3 | ✓ P5 | RODA ALVAREZ, FERNANDO\n",
      "✗ P3 | ✓ P5 | RODRIGUEZ BARRIO, SANTIAGO\n",
      "✗ P3 | ✗ P5 | RODRIGUEZ FERNANDEZ, VICTOR\n",
      "✗ P3 | ✓ P5 | RODRIGUEZ LOPEZ, DANIEL\n",
      "✗ P3 | ✓ P5 | RODRIGUEZ MARTIN, DAVID\n",
      "✗ P3 | ✓ P5 | RODRIGUEZ ROMAN, DIEGO\n",
      "✓ P3 | ✓ P5 | RODRIGUEZ SANCHEZ, VICTOR\n",
      "✓ P3 | ✓ P5 | ROJAS ILLESCAS, GABRIEL\n",
      "✗ P3 | ✗ P5 | ROMAN ROSALES, JORGE ANDRES\n",
      "✓ P3 | ✓ P5 | ROMEO PEREZ, ALEJANDRO\n",
      "✗ P3 | ✗ P5 | ROZADILLAS VIDAL, JULIAN\n",
      "✗ P3 | ✓ P5 | RUIZ PEREZ, CLAUDIA\n",
      "✓ P3 | ✓ P5 | RUSSO PEREZ, ALEJANDRO ISAAC\n",
      "✗ P3 | ✓ P5 | SAIZ MOLINA, DAVID\n",
      "✓ P3 | ✓ P5 | SAN JUAN FERNANDEZ, MARIO\n",
      "✗ P3 | ✓ P5 | SANCHEZ ALCAZAR, RAUL\n",
      "✗ P3 | ✓ P5 | SANCHEZ DEL CAMPO, HUGO\n",
      "✗ P3 | ✗ P5 | SANCHEZ DONAIRE, MARCOS\n",
      "✗ P3 | ✓ P5 | SANCHEZ HERRERA, ALEJANDRO\n",
      "✓ P3 | ✓ P5 | SANCHEZ LOSA, CARLOS\n",
      "✗ P3 | ✗ P5 | SANCHEZ MARTIN, MARCO\n",
      "✗ P3 | ✓ P5 | SANCHEZ NUÑO, JORGE\n",
      "✓ P3 | ✓ P5 | SANCHEZ PINA, JORGE\n",
      "✗ P3 | ✗ P5 | SANCHEZ RODRIGUEZ, ALVARO\n",
      "✗ P3 | ✓ P5 | SANCHEZ TAPIADOR, PABLO\n",
      "✗ P3 | ✗ P5 | SANTAMARIA VALENZUELA, MARIA INMACULADA\n",
      "✓ P3 | ✓ P5 | SANZ AVILA, DANIEL\n",
      "✗ P3 | ✓ P5 | SEBASTIANI DAMAS, SANTIAGO DANIEL\n",
      "✓ P3 | ✗ P5 | SHU, LIN\n",
      "✗ P3 | ✓ P5 | SICILIA BALAS, DANIELA\n",
      "✗ P3 | ✗ P5 | SILVA CASTRO, JUAN\n",
      "✗ P3 | ✓ P5 | SORET EL HARTI, SARAH\n",
      "✗ P3 | ✓ P5 | SOUTO RUSSO, ALINA SUSANA\n",
      "✗ P3 | ✓ P5 | STRAUS PEÑAFIEL, ALVARO\n",
      "✗ P3 | ✓ P5 | TAIPE TICSE, LUIS IÑAKI\n",
      "✗ P3 | ✓ P5 | TAMAKI MORENO, ALVARO\n",
      "✗ P3 | ✓ P5 | TITUAÑA SOTALIN, BRANDON ALEXIS\n",
      "✗ P3 | ✗ P5 | TRANA, VALENTIN VASILE\n",
      "✗ P3 | ✓ P5 | VALLEJO NYS, JOSE LUIS\n",
      "✗ P3 | ✓ P5 | VAQUEIRO JIMENEZ, DAVID\n",
      "✗ P3 | ✓ P5 | VELARDE ROMERO, ALVARO\n",
      "✓ P3 | ✓ P5 | VELISLAVOVA TSEKOVA, CRISTIANA\n",
      "✗ P3 | ✓ P5 | VERDIN DOMINGUEZ, LARA\n",
      "✗ P3 | ✓ P5 | VICENTE MIGUEL, CELIA\n",
      "✗ P3 | ✓ P5 | VILLA MARTIN, PABLO\n",
      "✗ P3 | ✓ P5 | VINDEL DOMINGUEZ, JORGE\n",
      "✗ P3 | ✓ P5 | YANG, JINXIAN\n",
      "✗ P3 | ✓ P5 | YE, JUNQIN\n",
      "✓ P3 | ✓ P5 | ZHENG, YIFEI\n",
      "✗ P3 | ✓ P5 | ZHOU, YUHANG\n",
      "✗ P3 | ✗ P5 | ZHOU ZHENG, JIA CHENG\n",
      "✓ P3 | ✓ P5 | ZHU, XIANG LE\n",
      "✗ P3 | ✓ P5 | ZODER MENDEZ, ANA\n",
      "✗ P3 | ✓ P5 | ZODER MENDEZ, PABLO JOACHIM\n",
      "✗ P3 | ✓ P5 | AGUIRRIZABAL MARTINEZ, HUGO\n",
      "✗ P3 | ✓ P5 | ALHEJA BERMEJO, ALEJANDRO\n",
      "✗ P3 | ✗ P5 | ALONSO RUIZ, JAIME\n",
      "✓ P3 | ✓ P5 | ALVAREZ CABRERA, LUIS\n",
      "✗ P3 | ✗ P5 | ANCAJIMA QUISPE, FABIOLA\n",
      "✓ P3 | ✓ P5 | ARIAS CASADO, ALBA\n",
      "✗ P3 | ✗ P5 | ARRANZ CAMPINS, SERGIO\n",
      "✗ P3 | ✗ P5 | BALBOA MORILLO, MARCO\n",
      "✗ P3 | ✗ P5 | BARBERO BARRERO, MIGUEL\n",
      "✓ P3 | ✓ P5 | BASSO MARTINEZ, CHRISTIAN\n",
      "✗ P3 | ✗ P5 | BERNARDINO TEBA, DANIEL\n",
      "✗ P3 | ✓ P5 | BERRAL MARTIN, GONZALO\n",
      "✗ P3 | ✗ P5 | BERTOLISSI, LUCIA ESTHER\n",
      "✗ P3 | ✗ P5 | BOATELLA BENITEZ-DONOSO, MARIA\n",
      "✗ P3 | ✗ P5 | BRANDO PARRA, LUIS CARLOS\n",
      "✗ P3 | ✓ P5 | CABELLO MARTIN, BRUNO\n",
      "✗ P3 | ✓ P5 | CAI, ZESHENG\n",
      "✗ P3 | ✓ P5 | CALERO CORRAL, CARLOS\n",
      "✓ P3 | ✓ P5 | CARMONA OCAÑA, DANIEL\n",
      "✗ P3 | ✗ P5 | CARRERAS GONZALEZ, LIDIA\n",
      "✗ P3 | ✓ P5 | CASADO MORCUENDE, PABLO\n",
      "✗ P3 | ✗ P5 | CHAMOSO DE URBIZU, JAVIER\n",
      "✓ P3 | ✓ P5 | CHAVARRIA PALOMO, DAVID\n",
      "✗ P3 | ✓ P5 | CHIFOR, NICOLAS MARIUS\n",
      "✗ P3 | ✗ P5 | CONCHA LOPEZ, MATTEO\n",
      "✗ P3 | ✓ P5 | CRAUS SANTA CATALINA, NICOLAS\n",
      "✗ P3 | ✓ P5 | CRIALES CARRANZA, LUIS MATHIAS\n",
      "✗ P3 | ✓ P5 | CUTOLO SPADARO, ROSANGELA MARIA\n",
      "✓ P3 | ✓ P5 | DE LA IGLESIA NUÑEZ, PEDRO JOSE\n",
      "✗ P3 | ✗ P5 | DE LOMBAS LOPEZ, JAVIER\n",
      "✗ P3 | ✓ P5 | DEL CAMPO GONZALEZ, ALVARO\n",
      "✗ P3 | ✓ P5 | DEL POZUELO ESCALONA, PABLO\n",
      "✗ P3 | ✓ P5 | DUMITRESCU, ALEXANDRU RAZVAN\n",
      "✗ P3 | ✗ P5 | ECIJA SANCHEZ, GONZALO\n",
      "✗ P3 | ✗ P5 | EHLE, AMELIE KATHARINA\n",
      "✗ P3 | ✓ P5 | ESCUDERO MATEOS, JAVIER\n",
      "✗ P3 | ✓ P5 | ESPINOZA ALONSO, JUAN VIDAL\n",
      "✗ P3 | ✓ P5 | ESTEPA ROBLES, ANDREA\n",
      "✗ P3 | ✗ P5 | ESTEVEZ BOSSO, MARIANELA\n",
      "✓ P3 | ✓ P5 | EXPOSITO SONO, HARITZ ENDIKA\n",
      "✗ P3 | ✗ P5 | FAN, ZHIYING\n",
      "✓ P3 | ✓ P5 | FERNANDEZ NIETO, DAVID\n",
      "✗ P3 | ✓ P5 | FERREIRA SOUZA, JHONATAN\n",
      "✓ P3 | ✓ P5 | FILALI BELHADJ CHAQROUNE, YASSIR\n",
      "✓ P3 | ✓ P5 | FORONDA IRAIZOS, PABLO RAMIRO\n",
      "✗ P3 | ✗ P5 | FRUTOS VELASCO, JUAN ALBERTO DE\n",
      "✗ P3 | ✓ P5 | GARCIA CARRETERO, SAMUEL\n",
      "✗ P3 | ✗ P5 | GARCIA CESPEDES, OSCAR\n",
      "✓ P3 | ✓ P5 | GARCIA FERNANDEZ, LORENZO\n",
      "✗ P3 | ✓ P5 | GARCIA GARCIA, MARCOS\n",
      "✓ P3 | ✓ P5 | GARCIA GUZMAN, ADRIAN\n",
      "✓ P3 | ✓ P5 | GARCIA HERNANDEZ, MARCOS\n",
      "✗ P3 | ✗ P5 | GARCIA NIETO, FERNANDO\n",
      "✗ P3 | ✗ P5 | GARCIA SANCHEZ, PAULA\n",
      "✗ P3 | ✓ P5 | GARCIA-PRIETO CASTELLS, MARIA JOSE\n",
      "✓ P3 | ✓ P5 | GOMEZ GONZALEZ, LUCAS MATEO\n",
      "✗ P3 | ✓ P5 | GOMEZ MORENO, CARLOS\n",
      "✗ P3 | ✓ P5 | GOMEZ ROBLEDANO, PABLO\n",
      "✓ P3 | ✓ P5 | GOMEZ ROMERO, MIGUEL\n",
      "✗ P3 | ✗ P5 | GONZALEZ ABUSHAREB, JANO ALI\n",
      "✓ P3 | ✓ P5 | GONZALEZ MONTERO, PABLO\n",
      "✗ P3 | ✗ P5 | GONZALEZ MORENO, DARIO\n",
      "✓ P3 | ✓ P5 | GONZALEZ RODRIGUEZ, RUBEN\n",
      "✗ P3 | ✓ P5 | GONZALEZ SANCHEZ, LUIS\n",
      "✗ P3 | ✓ P5 | GUOZHANG, HAOQI\n",
      "✗ P3 | ✓ P5 | GUTIERREZ MARTIN, ROBERTO\n",
      "✗ P3 | ✓ P5 | HERRERA BAUTISTE, ALVARO\n",
      "✓ P3 | ✓ P5 | HERVAS FERNANDEZ, JOSE\n",
      "✗ P3 | ✓ P5 | HIDALGO POZAS, MIGUEL\n",
      "✓ P3 | ✓ P5 | HUERGA GIL, JAVIER\n",
      "✗ P3 | ✗ P5 | JAREK JAREK, WIOLETTA\n",
      "✗ P3 | ✓ P5 | JIA LIU, ZHENGPENG\n",
      "✗ P3 | ✓ P5 | JIMENEZ DIAZ, MARCOS\n",
      "✗ P3 | ✓ P5 | JIMENEZ SANZ, SERGIO\n",
      "✓ P3 | ✓ P5 | LAZARO DIAZ, MARCOS\n",
      "✗ P3 | ✗ P5 | LIN, CUNXI\n",
      "✓ P3 | ✗ P5 | LIN, JIANTENG\n",
      "✗ P3 | ✓ P5 | LINARES CASTILLO, ALVARO\n",
      "✓ P3 | ✓ P5 | LIU, JIAYI\n",
      "✗ P3 | ✗ P5 | LIZ LOPEZ, HELENA\n",
      "✗ P3 | ✗ P5 | LOPEZ ELBAL, HECTOR\n",
      "✗ P3 | ✓ P5 | LOPEZ GARCIA, ANDRES\n",
      "✗ P3 | ✗ P5 | LOPEZ PEREZ, IGNACIO\n",
      "✗ P3 | ✓ P5 | LOPEZ RODRIGUEZ, NICOLAS\n",
      "✓ P3 | ✓ P5 | LOVICARIO RODRIGUEZ, SEBASTIAN\n",
      "✗ P3 | ✗ P5 | LOZANO FUENTES, JULEN\n",
      "✗ P3 | ✗ P5 | LOZANO JUAREZ, ALVARO\n",
      "✓ P3 | ✓ P5 | LUCERO PRADA, IRENE\n",
      "✗ P3 | ✗ P5 | LUQUE FERNANDEZ, IVAN\n",
      "✓ P3 | ✓ P5 | MAESO BALLANO, ALVARO\n",
      "✗ P3 | ✗ P5 | MAGANTO PABLO, SERGIO\n",
      "✗ P3 | ✓ P5 | MAQUEDA IRUN, HECTOR\n",
      "✓ P3 | ✓ P5 | MARTIN CORCHON, ANTONIO\n",
      "✗ P3 | ✓ P5 | MARTIN OLIVERO, IRENE\n",
      "✗ P3 | ✗ P5 | MARTIN SANCHEZ, SERGIO\n",
      "✗ P3 | ✗ P5 | MARTIN SEPULVEDA, ADRIAN\n",
      "✓ P3 | ✓ P5 | MASSERA SALCEDO, GUILLERMO\n",
      "✓ P3 | ✓ P5 | MATEOS SOLIS, ALVARO\n",
      "✗ P3 | ✓ P5 | MEDINA GONZALEZ, ENRIQUE\n",
      "✗ P3 | ✗ P5 | MELENDEZ PEREYRA, SANDRA CAROLINA\n",
      "✗ P3 | ✓ P5 | MIER DIAZ DE ARCAYA, JUAN\n",
      "✓ P3 | ✓ P5 | MILANES VIDAL, MANUEL ALEJANDRO\n",
      "✗ P3 | ✓ P5 | MILLAN ARRANZ, DAVID\n",
      "✗ P3 | ✗ P5 | MIRANZO HERRAIZ, ALVARO\n",
      "✗ P3 | ✓ P5 | MOLERO RUIZ, MOISES\n",
      "✗ P3 | ✗ P5 | MONTOYA RAMOS, DENIS ORLANDO\n",
      "✗ P3 | ✓ P5 | MORALES DE LUIS, JAVIER\n",
      "✓ P3 | ✓ P5 | MORAN RUIZ, JAIME\n",
      "✗ P3 | ✗ P5 | MORENO GONZALEZ, LUIS\n",
      "✗ P3 | ✗ P5 | MORENO MARTIN, ADRIAN\n",
      "✗ P3 | ✓ P5 | MORENO PULIDO, ADRIAN\n",
      "✗ P3 | ✓ P5 | MORENO SANCHO, SANDRA\n",
      "✗ P3 | ✓ P5 | MUÑOZ FANDIÑO, ALEJANDRA MARIA\n",
      "✗ P3 | ✗ P5 | MUQUINCHE CUMBAL, ANDY RUBEN\n",
      "✗ P3 | ✗ P5 | NAVARRO MUÑOZ, JAVIER\n",
      "✓ P3 | ✓ P5 | NAZARENKO, KSENIA\n",
      "✓ P3 | ✓ P5 | NIETO HERNANDEZ, JAVIER\n",
      "✗ P3 | ✓ P5 | NUÑEZ GONZALEZ, ARANCHA\n",
      "✗ P3 | ✓ P5 | OLIVA RODRIGUEZ, EDUARDO\n",
      "✗ P3 | ✗ P5 | OLMEDO GUERRA, JAVIER\n",
      "✗ P3 | ✗ P5 | ORS RODRIGUEZ, ALEJANDRO\n",
      "✓ P3 | ✓ P5 | ORTEGA RODRIGUEZ, CRISTINA\n",
      "✗ P3 | ✗ P5 | PALOMARES JUNQUERA, JOAN\n",
      "✗ P3 | ✓ P5 | PALOMERA MARTIN, CARLOS\n",
      "✗ P3 | ✓ P5 | PANIS MARAMBA, TRISHALYN\n",
      "✓ P3 | ✓ P5 | PAREJAS LAMBAN, DAVID\n",
      "✓ P3 | ✓ P5 | PARIENTE CARRIAZO, ANTONIO\n",
      "✗ P3 | ✗ P5 | PASTOR GALINDO, JAVIER\n",
      "✗ P3 | ✓ P5 | PAZ MENDEZ, SANTIAGO ALEXANDER\n",
      "✗ P3 | ✗ P5 | PELAEZ RODRIGUEZ, TERESA\n",
      "✗ P3 | ✓ P5 | PEÑAS PIQUERAS, LORENA\n",
      "✗ P3 | ✓ P5 | PEREZ GARCIA, CARLOS\n",
      "✗ P3 | ✓ P5 | PEREZ SALDAÑA, ADRIAN\n",
      "✗ P3 | ✗ P5 | PILLAJO SANCHEZ, VICTOR ADRIAN\n",
      "✗ P3 | ✗ P5 | PINTO NIETO, CARLOS\n",
      "✗ P3 | ✓ P5 | PLAZA GONZALO, PABLO\n",
      "✗ P3 | ✗ P5 | PLAZA PASCUAL, LUCAS\n",
      "✓ P3 | ✓ P5 | POSE COSTA, JUAN FRANCISCO\n",
      "✗ P3 | ✗ P5 | PRIETO HERNANDEZ, MIGUEL\n",
      "✗ P3 | ✗ P5 | PUEBLA LOPEZ, JAVIER\n",
      "✓ P3 | ✓ P5 | PUEBLA MARTINEZ, FELIX\n",
      "✗ P3 | ✓ P5 | QEFALIA PULACI, ALBA\n",
      "✗ P3 | ✗ P5 | QIU, KAIYI\n",
      "✗ P3 | ✓ P5 | REIG GUERRERO, JOSE LUIS\n",
      "✗ P3 | ✗ P5 | REQUENA ARECHABALA, MIGUEL\n",
      "✗ P3 | ✓ P5 | RIESGO MARTIN, JAIME\n",
      "✓ P3 | ✓ P5 | RODRIGUES ARROYO, HECTOR\n",
      "✗ P3 | ✗ P5 | RODRIGUEZ APARICIO, PEDRO\n",
      "✗ P3 | ✗ P5 | RODRIGUEZ DIAZ, HUGO\n",
      "✗ P3 | ✗ P5 | RODRIGUEZ FERNANDEZ, VICTOR\n",
      "✗ P3 | ✗ P5 | RODRIGUEZ GIMENEZ, MARCOS\n",
      "✗ P3 | ✓ P5 | RODRIGUEZ HORCAJO, PAULA\n",
      "✗ P3 | ✗ P5 | RODRIGUEZ MARTIN, MARIO DANIEL\n",
      "✗ P3 | ✓ P5 | RODRIGUEZ MARTIN, RUBEN\n",
      "✓ P3 | ✗ P5 | RODRIGUEZ RAMOS, CARLOS\n",
      "✓ P3 | ✗ P5 | RODRIGUEZ SOGORB, VIRGINIA\n",
      "✓ P3 | ✓ P5 | ROJAS TENA, LUCAS\n",
      "✗ P3 | ✗ P5 | ROMERO KAUSS, ALVARO DANIEL\n",
      "✗ P3 | ✓ P5 | ROMO TAMAME, EVA\n",
      "✓ P3 | ✗ P5 | SAEZ TENORIO, MAURO\n",
      "✓ P3 | ✓ P5 | SALVADOR GARCIA, MARCOS\n",
      "✗ P3 | ✗ P5 | SANCHEZ FERNANDEZ, LUCIA\n",
      "✗ P3 | ✓ P5 | SANCHEZ GONZALEZ, SERGIO\n",
      "✗ P3 | ✗ P5 | SANCHEZ HERRERA, MIGUEL\n",
      "✗ P3 | ✗ P5 | SANCHEZ LUCENA, ANGEL\n",
      "✗ P3 | ✗ P5 | SANCHEZ PRIETO, IVAN\n",
      "✓ P3 | ✓ P5 | SANCHEZ PRUDENCIO, RICARDO\n",
      "✗ P3 | ✓ P5 | SANCHEZ SANTANA, JHON LEUDY\n",
      "✗ P3 | ✗ P5 | SANTAMARIA VALENZUELA, MARIA INMACULADA\n",
      "✓ P3 | ✓ P5 | SANTILLANA VIZCAYA, DIEGO\n",
      "✗ P3 | ✓ P5 | SANZ COLON, ADRIANA\n",
      "✓ P3 | ✓ P5 | SANZ PASTOR, SANTIAGO\n",
      "✗ P3 | ✗ P5 | SAONER PLOMER, ALBERTO\n",
      "✓ P3 | ✓ P5 | SEGOVIA GUTIERREZ, ANGEL\n",
      "✓ P3 | ✓ P5 | SEÑORANS DAVILA, JAVIER\n",
      "✓ P3 | ✓ P5 | SERNA QUINTERO, JUAN JOSE\n",
      "✗ P3 | ✗ P5 | SIMARRO PINES, LUCAS\n",
      "✗ P3 | ✓ P5 | SUAREZ SALGADO, SOFIA MENGYUAN\n",
      "✗ P3 | ✓ P5 | TARRILLO MUNDACA, JORGE AUGUSTO\n",
      "✗ P3 | ✗ P5 | TAYPE MUNDACA, MARIO FERNANDO\n",
      "✗ P3 | ✓ P5 | TERESO SILVA, LUIS\n",
      "✓ P3 | ✓ P5 | TORRES SAN FELIPE, GUILLERMO\n",
      "✗ P3 | ✓ P5 | TRUBITSIN GAVRILOV, ALEX\n",
      "✓ P3 | ✓ P5 | TRULL GONZALEZ, SARA\n",
      "✗ P3 | ✗ P5 | TSUTSUI GEY, KEISHI\n",
      "✗ P3 | ✗ P5 | VARELA SERROUKH, ELIAS\n",
      "✗ P3 | ✗ P5 | VAZQUEZ MASERO, SERGIO\n",
      "✗ P3 | ✓ P5 | VICENTE NAVARRE, MARIO\n",
      "✗ P3 | ✗ P5 | WANG, TIANLE\n",
      "✗ P3 | ✗ P5 | WU, YA-PENG\n",
      "✗ P3 | ✗ P5 | XIA, OSCAR\n",
      "✗ P3 | ✓ P5 | XU, HAOYUAN\n",
      "✓ P3 | ✓ P5 | YE, SHU LAI\n",
      "✗ P3 | ✓ P5 | YIN, JUNJIE\n",
      "✗ P3 | ✗ P5 | ZEGGAF EL MRABET, OMAR\n",
      "✗ P3 | ✗ P5 | ZHANG, HAOQING\n",
      "✓ P3 | ✓ P5 | ZHANG, JIONGHAO\n",
      "✗ P3 | ✓ P5 | ZHANG XIA, STEVEN WEI\n",
      "✗ P3 | ✓ P5 | ZHOU, YI\n",
      "✗ P3 | ✓ P5 | ZOU, XURUI\n",
      "==================================================\n",
      "RESUMEN:\n",
      "Total alumnos verificados: 444\n",
      "Práctica 3 - Entregadas: 92 | No entregadas: 352\n",
      "Práctica 5 - Entregadas: 302 | No entregadas: 142\n",
      "\n",
      "DataFrame con verificación de prácticas:\n",
      "        Nombre       Apellido(s)                   Dirección de correo  \\\n",
      "0        SOFIA   AGAPITO DELGADO              s.agapito@alumnos.upm.es   \n",
      "1  LLOYD DAREN    AGUILAR DESIAR          daren.aguilar@alumnos.upm.es   \n",
      "2       JAVIER   AGUIRRE HERVIAS  javier.aguirrehervias@alumnos.upm.es   \n",
      "3        MATEO          ALBRIZIO         mateo.albrizio@alumnos.upm.es   \n",
      "4      NICOLAS  ALONSO FERNANDEZ              ni.alonso@alumnos.upm.es   \n",
      "\n",
      "    Grupos  Presentada_3 Comentario_3  Presentada_5 Comentario_5  \n",
      "0  IWSIT11             0           NP             1               \n",
      "1  IWSIM12             0           NP             1               \n",
      "2  IWSIM12             0           NP             1               \n",
      "3  IWSIM12             0           NP             1               \n",
      "4  IWSIM12             0           NP             0           NP  \n",
      "\n",
      "Estadísticas por grupo:\n"
     ]
    }
   ],
   "source": [
    "# Load moodle students information\n",
    "import pandas as pd\n",
    "# Cargar el CSV de alumnos y grupos\n",
    "students_info = [\"./../data/courseid_422_participants.csv\", \"./../data/courseid_23101_participants.csv\"]\n",
    "dfs = [ pd.read_csv(filename) for filename in students_info ]\n",
    "df = pd.concat(dfs, ignore_index=True)\n",
    "# Limpiar espacios y convertir a mayúsculas\n",
    "df[\"Nombre\"] = df[\"Nombre\"].str.strip().str.upper()\n",
    "df[\"Apellido(s)\"] = df[\"Apellido(s)\"].str.strip().str.upper()\n",
    "print(\"DataFrame original cargado:\")\n",
    "print(f\"Total alumnos: {len(df)}\")\n",
    "print(df.head())\n",
    "print(\"\\n\")\n",
    "\n",
    "# Verificar prácticas y añadir columnas\n",
    "df_con_practicas = verificar_todas_las_practicas(df)\n",
    "\n",
    "print(\"\\nDataFrame con verificación de prácticas:\")\n",
    "print(df_con_practicas.head())\n",
    "\n",
    "# Mostrar estadísticas por grupo si existe la columna\n",
    "if 'Grupos' in df_con_practicas.columns:\n",
    "    print(\"\\nEstadísticas por grupo:\")\n",
    "    resumen_grupos = df_con_practicas.groupby('Grupos').agg({\n",
    "        'Presentada_3': 'sum',\n",
    "        'Presentada_5': 'sum'\n",
    "    })\n",
    "#    print(resumen_grupos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display(df_con_practicas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_con_practicas.to_csv(\"../data/practicas_3_5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar un grupo en concreto\n",
    "columnas_importantes = ['Nombre', 'Apellido(s)', 'Presentada_5', 'Comentario_5']\n",
    "df_con_practicas[df_con_practicas['Grupos'] == 'CITIT11'][columnas_importantes].to_csv('../data/alumnos_CITIT11.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def renombrar_archivos_en_lotes(ruta=\"../data/raw/\"):\n",
    "\t\"\"\"\n",
    "\tRenombra todos los archivos en la carpeta dada como 'lote_1', 'lote_2', etc.\n",
    "\tConserva la extensión original de cada archivo.\n",
    "\t\"\"\"\n",
    "\tarchivos = sorted([f for f in os.listdir(ruta) if os.path.isfile(os.path.join(ruta, f))])\n",
    "\tfor idx, nombre_original in enumerate(archivos, start=1):\n",
    "\t\textension = os.path.splitext(nombre_original)[1]\n",
    "\t\tnuevo_nombre = f\"lote_{idx}{extension}\"\n",
    "\t\truta_origen = os.path.join(ruta, nombre_original)\n",
    "\t\truta_destino = os.path.join(ruta, nuevo_nombre)\n",
    "\t\tos.rename(ruta_origen, ruta_destino)\n",
    "\tprint(f\"Renombrados {len(archivos)} archivos en '{ruta}'.\")\n",
    "#renombrar_archivos_en_lotes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from pypdf import PdfReader, PdfWriter\n",
    "\n",
    "def crear_carpeta_examenes(base_dir=\"../data\", nombre_base=\"examenes\"):\n",
    "    \"\"\"\n",
    "    Crea una carpeta nueva para los exámenes. Si ya existe, añade un sufijo numérico.\n",
    "    \"\"\"\n",
    "    base_path = Path(base_dir)\n",
    "    carpeta = base_path / nombre_base\n",
    "    contador = 1\n",
    "    while carpeta.exists():\n",
    "        carpeta = base_path / f\"{nombre_base}_{contador}\"\n",
    "        contador += 1\n",
    "    carpeta.mkdir(parents=True)\n",
    "    return carpeta\n",
    "\n",
    "def dividir_pdf_en_examenes(pdf_path, carpeta_destino, nombre_base=\"examen\"):\n",
    "    \"\"\"\n",
    "    Divide un PDF en archivos de 2 páginas cada uno y los guarda en la carpeta destino.\n",
    "    \"\"\"\n",
    "    reader = PdfReader(pdf_path)\n",
    "    num_paginas = len(reader.pages)\n",
    "    examen_idx = 1\n",
    "    for i in range(0, num_paginas, 2):\n",
    "        writer = PdfWriter()\n",
    "        writer.add_page(reader.pages[i])\n",
    "        if i+1 < num_paginas:\n",
    "            writer.add_page(reader.pages[i+1])\n",
    "        nombre_examen = f\"{nombre_base}_{examen_idx}.pdf\"\n",
    "        ruta_examen = carpeta_destino / nombre_examen\n",
    "        with open(ruta_examen, \"wb\") as f_out:\n",
    "            writer.write(f_out)\n",
    "        examen_idx += 1\n",
    "\n",
    "def procesar_lotes_y_generar_examenes(ruta_lotes=\"../data/raw/\", base_dir=\"../data\", nombre_carpeta=\"examenes\"):\n",
    "    \"\"\"\n",
    "    Busca todos los archivos PDF en la carpeta de lotes, los divide de 2 en 2 páginas y los guarda en una carpeta nueva.\n",
    "    \"\"\"\n",
    "    carpeta_destino = crear_carpeta_examenes(base_dir, nombre_carpeta)\n",
    "    archivos_lote = sorted([f for f in os.listdir(ruta_lotes) if f.lower().endswith(\".pdf\")])\n",
    "    examen_global_idx = 1\n",
    "    for archivo in archivos_lote:\n",
    "        ruta_pdf = Path(ruta_lotes) / archivo\n",
    "        reader = PdfReader(ruta_pdf)\n",
    "        num_paginas = len(reader.pages)\n",
    "        for i in range(0, num_paginas, 2):\n",
    "            writer = PdfWriter()\n",
    "            writer.add_page(reader.pages[i])\n",
    "            if i+1 < num_paginas:\n",
    "                writer.add_page(reader.pages[i+1])\n",
    "            nombre_examen = f\"examen_{examen_global_idx}.pdf\"\n",
    "            ruta_examen = carpeta_destino / nombre_examen\n",
    "            with open(ruta_examen, \"wb\") as f_out:\n",
    "                writer.write(f_out)\n",
    "            examen_global_idx += 1\n",
    "    print(f\"Exámenes generados en: {carpeta_destino}\")\n",
    "\n",
    "# Ejemplo de uso:\n",
    "#procesar_lotes_y_generar_examenes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from pdf2image import convert_from_path\n",
    "from pypdf import PdfReader, PdfWriter\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import Button, HBox, VBox, Output, Layout, Label, Dropdown\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "class JupyterPDFReviewer:\n",
    "    def __init__(self, pdf_path):\n",
    "        self.pdf_path = pdf_path\n",
    "        self.reader = PdfReader(pdf_path)\n",
    "        self.total_pages = len(self.reader.pages)\n",
    "        self.current_index = 0\n",
    "        self.images = {}\n",
    "        self.output_dir = Path(\"../data/saved\")\n",
    "        self.output_dir.mkdir(parents=True, exist_ok=True)\n",
    "        self.out = Output()\n",
    "        self.status = Label(value=\"\")  # Estado visual\n",
    "        self._setup_widgets()\n",
    "        self._show_pages()\n",
    "\n",
    "    def _setup_widgets(self):\n",
    "        self.btn_save1 = Button(description='Save Page 1', layout=Layout(width='120px'))\n",
    "        self.btn_save12 = Button(description='Save Pages 1&2', layout=Layout(width='120px'))\n",
    "        self.btn_save123 = Button(description='Save Pages 1-3', layout=Layout(width='120px'))\n",
    "        self.btn_next = Button(description='Next (Skip 1)', layout=Layout(width='120px'))\n",
    "        self.btn_prev = Button(description='Previous', layout=Layout(width='120px'))\n",
    "\n",
    "        self.btn_save1.on_click(lambda x: self._save_pages([0]))\n",
    "        self.btn_save12.on_click(lambda x: self._save_pages([0, 1]))\n",
    "        self.btn_save123.on_click(lambda x: self._save_pages([0, 1, 2]))\n",
    "        self.btn_next.on_click(lambda x: self._next_page())\n",
    "        self.btn_prev.on_click(lambda x: self._prev_page())\n",
    "\n",
    "        display(VBox([\n",
    "            HBox([self.btn_prev, self.btn_save1, self.btn_save12, self.btn_save123, self.btn_next]),\n",
    "            self.status,\n",
    "            self.out\n",
    "        ]))\n",
    "\n",
    "    def _get_page_image(self, idx):\n",
    "        if idx not in self.images and idx < self.total_pages:\n",
    "            self.status.value = f\"Cargando página {idx+1}...\"\n",
    "            try:\n",
    "                img = convert_from_path(\n",
    "                    self.pdf_path,\n",
    "                    first_page=idx + 1,\n",
    "                    last_page=idx + 1,\n",
    "                    dpi=50,\n",
    "                    fmt='jpeg',\n",
    "                    thread_count=1\n",
    "                )[0]\n",
    "                self.images[idx] = img\n",
    "            except Exception as e:\n",
    "                self.status.value = f\"Error cargando página {idx+1}\"\n",
    "                print(f\"Error converting page {idx+1}: {e}\")\n",
    "                return None\n",
    "        self.status.value = \"\"\n",
    "        return self.images.get(idx)\n",
    "\n",
    "    def _show_pages(self):\n",
    "        with self.out:\n",
    "            clear_output(wait=True)\n",
    "            fig, axes = plt.subplots(1, 3, figsize=(15, 8))\n",
    "            for i in range(3):\n",
    "                page_idx = self.current_index + i\n",
    "                axes[i].axis('off')\n",
    "                if page_idx < self.total_pages:\n",
    "                    img = self._get_page_image(page_idx)\n",
    "                    if img is not None:\n",
    "                        axes[i].imshow(img)\n",
    "                        axes[i].set_title(f\"Page {page_idx+1}\")\n",
    "                    else:\n",
    "                        axes[i].set_title(f\"Page {page_idx+1} (error)\")\n",
    "                else:\n",
    "                    axes[i].set_title(\"No Page\")\n",
    "            plt.show()\n",
    "\n",
    "    def _next_page(self):\n",
    "        if self.current_index + 1 < self.total_pages:\n",
    "            self.current_index += 1\n",
    "            self._show_pages()\n",
    "\n",
    "    def _prev_page(self):\n",
    "        if self.current_index >= 1:\n",
    "            self.current_index -= 1\n",
    "            self._show_pages()\n",
    "\n",
    "    def _save_pages(self, rel_indices):\n",
    "        abs_indices = [self.current_index + i for i in rel_indices if self.current_index + i < self.total_pages]\n",
    "        if not abs_indices:\n",
    "            self.status.value = \"No valid pages to save\"\n",
    "            return\n",
    "\n",
    "        base_name = Path(self.pdf_path).stem  # Ejemplo: 'lote_1'\n",
    "        lote = base_name\n",
    "        examen_n = abs_indices[0] + 1  # Primer índice de página + 1\n",
    "        output_path = self.output_dir / f\"{lote}_examen_{examen_n}.pdf\"\n",
    "\n",
    "        writer = PdfWriter()\n",
    "        for idx in abs_indices:\n",
    "            writer.add_page(self.reader.pages[idx])\n",
    "        with open(output_path, \"wb\") as f:\n",
    "            writer.write(f)\n",
    "        self.status.value = f\"Guardado: {output_path.name}\"\n",
    "\n",
    "        # Avanzar tantas páginas como se han guardado\n",
    "        avance = len(abs_indices)\n",
    "        if self.current_index + avance < self.total_pages:\n",
    "            self.current_index += avance\n",
    "            self._show_pages()\n",
    "\n",
    "def revisar_todos_los_lotes(ruta_lotes=\"../data/raw/\"):\n",
    "    archivos = sorted([f for f in os.listdir(ruta_lotes) if f.lower().endswith(\".pdf\")])\n",
    "    if not archivos:\n",
    "        print(\"No se encontraron lotes PDF en la carpeta.\")\n",
    "        return\n",
    "    dropdown = Dropdown(options=archivos, description='Lote:', layout=Layout(width='50%'))\n",
    "    out = Output()\n",
    "\n",
    "    def on_select(change):\n",
    "        with out:\n",
    "            clear_output(wait=True)\n",
    "            print(f\"Revisando: {dropdown.value}\")\n",
    "            JupyterPDFReviewer(os.path.join(ruta_lotes, dropdown.value))\n",
    "\n",
    "    dropdown.observe(on_select, names='value')\n",
    "    display(VBox([dropdown, out]))\n",
    "    # Mostrar el primero por defecto\n",
    "    on_select({'new': archivos[0]})\n",
    "\n",
    "# Ejemplo de uso:\n",
    "# revisar_todos_los_lotes(\"../data/raw/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#revisar_todos_los_lotes(\"../data/raw/\") # --> solo cuando necesites procesar los lotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import base64\n",
    "from pathlib import Path\n",
    "from pdf2image import convert_from_path\n",
    "from pypdf import PdfReader\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import io\n",
    "import requests\n",
    "\n",
    "def procesar_examenes_completo(carpeta_examenes=\"../data/saved/\", output_dir=\"../data/examenes_procesados/\"):\n",
    "    \"\"\"\n",
    "    Procesa todos los exámenes de la carpeta, extrae información con OpenAI,\n",
    "    los organiza por grupo y práctica, y genera un DataFrame de seguimiento.\n",
    "    \"\"\"\n",
    "    # Crear directorio de salida\n",
    "    output_path = Path(output_dir)\n",
    "    output_path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Lista para almacenar información de exámenes procesados\n",
    "    examenes_info = []\n",
    "    \n",
    "    # Obtener todos los archivos PDF\n",
    "    pdf_files = list(Path(carpeta_examenes).glob(\"*.pdf\"))\n",
    "    \n",
    "    print(f\"Procesando {len(pdf_files)} exámenes...\")\n",
    "    \n",
    "    # Variables necesarias para la API\n",
    "    api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {api_key}\"\n",
    "    }\n",
    "    \n",
    "    for pdf_file in pdf_files:\n",
    "        print(f\"\\nProcesando: {pdf_file.name}\")\n",
    "        \n",
    "        try:\n",
    "            # Procesar cada página del PDF\n",
    "            reader = PdfReader(pdf_file)\n",
    "            num_pages = len(reader.pages)\n",
    "            \n",
    "            for page_num in range(min(2, num_pages)):  # Solo primeras 2 páginas\n",
    "                # Convertir página a imagen\n",
    "                images = convert_from_path(\n",
    "                    pdf_file, \n",
    "                    first_page=page_num + 1, \n",
    "                    last_page=page_num + 1, \n",
    "                    dpi=150,\n",
    "                    fmt='jpeg'\n",
    "                )\n",
    "                \n",
    "                if not images:\n",
    "                    continue\n",
    "                    \n",
    "                # Convertir imagen a base64\n",
    "                buffered = io.BytesIO()\n",
    "                images[0].save(buffered, format=\"JPEG\")\n",
    "                base64_image = base64.b64encode(buffered.getvalue()).decode('utf-8')\n",
    "                \n",
    "                # Llamar a OpenAI\n",
    "                info = extraer_info_con_openai(base64_image, headers)\n",
    "                \n",
    "                if info and info.get('Apellidos') and info.get('Nombre'):\n",
    "                    info['archivo_original'] = pdf_file.name\n",
    "                    info['pagina'] = page_num + 1\n",
    "                    \n",
    "                    # Organizar archivo por grupo y práctica\n",
    "                    mover_archivo_organizado(pdf_file, info, output_path)\n",
    "                    \n",
    "                    examenes_info.append(info)\n",
    "                    practica = info.get('practica_detectada', 'desconocida')\n",
    "                    print(f\"✓ Extraído: {info['Nombre']} {info['Apellidos']} - Grupo: {info['Grupo']} - Práctica: {practica}\")\n",
    "                    break  # Si encontramos info en una página, no procesar más páginas\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"✗ Error procesando {pdf_file.name}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    # Crear DataFrame de seguimiento\n",
    "    df_examenes = crear_dataframe_examenes(examenes_info)\n",
    "    \n",
    "    # Guardar DataFrame\n",
    "    df_examenes.to_csv(output_path / \"seguimiento_examenes.csv\", index=False)\n",
    "    \n",
    "    print(f\"\\n📊 Procesamiento completado:\")\n",
    "    print(f\"- Exámenes procesados: {len(examenes_info)}\")\n",
    "    print(f\"- Archivo de seguimiento guardado en: {output_path / 'seguimiento_examenes.csv'}\")\n",
    "    \n",
    "    return df_examenes\n",
    "\n",
    "def extraer_info_con_openai(base64_image, headers):\n",
    "    \"\"\"Extrae información del examen usando OpenAI\"\"\"\n",
    "    try:\n",
    "        prompt_completo = f\"\"\"Extract the last name (Apellidos in Spanish), the first name (Nombre in Spanish) and the group (Grupo in Spanish)\n",
    "         from the top of the image. You will find them handwritten after the labels `Apellidos`,  `Nombre` and `Grupo` respectively. \n",
    "         The fields of your JSON output will have those exact same label names.\n",
    "         Also determine if this is a \"Práctica de Listas\" (practice 3) or \"Práctica de Grafos\" (practice 5) based on the content.\n",
    "         Add a field called \"practica_detectada\" with value 3 for listas or 5 for grafos.\n",
    "         Here is a list of expected students and their groups as a reference: \n",
    "         {guia_texto}\n",
    "         \"\"\"\n",
    "        \n",
    "        payload = {\n",
    "            \"model\": \"gpt-4o\",\n",
    "            \"response_format\": {\"type\": \"json_object\"},\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"system\", \n",
    "                    \"content\": \"You are a helpful assistant designed to see an exam and output JSON with the extracted information. The default group in case of empty string is extraviado\",   \n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\n",
    "                            \"type\": \"text\",\n",
    "                            \"text\": prompt_completo\n",
    "                        },\n",
    "                        {\n",
    "                            \"type\": \"image_url\",\n",
    "                            \"image_url\": {\n",
    "                                \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "                            }\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "            ],\n",
    "            \"max_tokens\": 300\n",
    "        }\n",
    "        \n",
    "        response = requests.post(\n",
    "            \"https://api.openai.com/v1/chat/completions\", \n",
    "            headers=headers, \n",
    "            json=payload\n",
    "        )\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            info_str = response.json()['choices'][0]['message']['content']\n",
    "            info = json.loads(info_str)\n",
    "            \n",
    "            # Si el grupo está vacío, marcarlo como \"extraviado\"\n",
    "            if not info.get(\"Grupo\"):\n",
    "                info[\"Grupo\"] = \"extraviado\"\n",
    "                \n",
    "            return info\n",
    "        else:\n",
    "            print(f\"Error en API OpenAI: {response.status_code}\")\n",
    "            return None\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error extrayendo información: {e}\")\n",
    "        return None\n",
    "\n",
    "def mover_archivo_organizado(archivo_original, info, output_path):\n",
    "    \"\"\"Organiza el archivo en carpetas por GRUPO y luego por PRÁCTICA\"\"\"\n",
    "    try:\n",
    "        practica = info.get('practica_detectada', 'desconocida')\n",
    "        grupo = info.get('Grupo', 'extraviado')\n",
    "        \n",
    "        # Crear estructura de carpetas: GRUPO -> PRÁCTICA\n",
    "        carpeta_grupo = output_path / grupo\n",
    "        carpeta_practica = carpeta_grupo / f\"Practica_{practica}\"\n",
    "        carpeta_practica.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Generar nombre de archivo\n",
    "        apellidos = info.get('Apellidos', 'SinApellidos').replace(' ', '_')\n",
    "        nombre = info.get('Nombre', 'SinNombre').replace(' ', '_')\n",
    "        \n",
    "        nombre_base = f\"{apellidos}_{nombre}\"\n",
    "        extension = archivo_original.suffix\n",
    "        nuevo_archivo = carpeta_practica / f\"{nombre_base}{extension}\"\n",
    "        \n",
    "        # Si ya existe, añadir sufijo numérico\n",
    "        contador = 2\n",
    "        while nuevo_archivo.exists():\n",
    "            nuevo_archivo = carpeta_practica / f\"{nombre_base}_{contador}{extension}\"\n",
    "            contador += 1\n",
    "        \n",
    "        # Copiar archivo\n",
    "        shutil.copy2(archivo_original, nuevo_archivo)\n",
    "        print(f\"  → Guardado en: {carpeta_grupo.name}/{carpeta_practica.name}/{nuevo_archivo.name}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error organizando archivo {archivo_original.name}: {e}\")\n",
    "\n",
    "def crear_dataframe_examenes(examenes_info):\n",
    "    \"\"\"Crea DataFrame de seguimiento de exámenes\"\"\"\n",
    "    # Crear DataFrame base con todos los estudiantes\n",
    "    df_base = df[['Nombre', 'Apellido(s)', 'Grupos']].copy()\n",
    "    \n",
    "    # Inicializar columnas de exámenes\n",
    "    df_base['Examen_3'] = 0\n",
    "    df_base['Comentario_Examen_3'] = 'PNP'  # PNP = No Presentado\n",
    "    df_base['Examen_5'] = 0\n",
    "    df_base['Comentario_Examen_5'] = 'PNP'  # PNP = No Presentado\n",
    "    \n",
    "    # Procesar información de exámenes\n",
    "    for examen in examenes_info:\n",
    "        practica = examen.get('practica_detectada')\n",
    "        if practica in [3, 5, '3', '5']:\n",
    "            practica = str(practica)\n",
    "            \n",
    "            # Buscar estudiante en el DataFrame\n",
    "            apellidos = examen.get('Apellidos', '').upper().strip()\n",
    "            nombre = examen.get('Nombre', '').upper().strip()\n",
    "            \n",
    "            # Buscar coincidencia (más flexible)\n",
    "            mask = df_base['Apellido(s)'].str.upper().str.contains(apellidos[:5] if len(apellidos) > 5 else apellidos, na=False, regex=False) & \\\n",
    "                   df_base['Nombre'].str.upper().str.contains(nombre[:5] if len(nombre) > 5 else nombre, na=False, regex=False)\n",
    "            \n",
    "            if mask.any():\n",
    "                df_base.loc[mask, f'Examen_{practica}'] = 1\n",
    "                df_base.loc[mask, f'Comentario_Examen_{practica}'] = ''  # Limpiar PNP\n",
    "                print(f\"  → Marcado como presentado: {nombre} {apellidos} - Práctica {practica}\")\n",
    "    \n",
    "    return df_base\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import base64\n",
    "from pathlib import Path\n",
    "from pdf2image import convert_from_path\n",
    "from pypdf import PdfReader\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import io\n",
    "import requests\n",
    "from rapidfuzz import fuzz\n",
    "import re\n",
    "import unicodedata\n",
    "\n",
    "def limpiar_texto(texto):\n",
    "    \"\"\"Elimina acentos, símbolos y deja solo letras/números/espacios en mayúsculas\"\"\"\n",
    "    if not texto:\n",
    "        return \"\"\n",
    "    texto = unicodedata.normalize('NFD', texto)\n",
    "    texto = ''.join(c for c in texto if unicodedata.category(c) != 'Mn')\n",
    "    texto = texto.upper()\n",
    "    texto = re.sub(r'[^A-Z0-9\\s]', '', texto)\n",
    "    texto = texto.strip()\n",
    "    return texto\n",
    "\n",
    "def buscar_grupo_flexible(nombre, apellidos, df, texto_ocr=None, umbral=90):\n",
    "    \"\"\"\n",
    "    Busca el grupo del alumno en el DataFrame por nombre y apellidos usando fuzzy.\n",
    "    Si no encuentra por el umbral, devuelve el grupo más parecido aunque el score sea bajo (mínimo 20%).\n",
    "    \"\"\"\n",
    "    nombre = limpiar_texto(nombre)\n",
    "    apellidos = limpiar_texto(apellidos)\n",
    "    mejor_score = -1\n",
    "    mejor_grupo = None\n",
    "    mejor_nombre = \"\"\n",
    "    mejor_apellidos = \"\"\n",
    "    for _, row in df.iterrows():\n",
    "        nombre_df = limpiar_texto(str(row[\"Nombre\"]))\n",
    "        apellidos_df = limpiar_texto(str(row[\"Apellido(s)\"]))\n",
    "        score_nombre = fuzz.ratio(nombre, nombre_df)\n",
    "        score_apellidos = fuzz.ratio(apellidos, apellidos_df)\n",
    "        score = (score_nombre + score_apellidos) / 2\n",
    "        if score > mejor_score:\n",
    "            mejor_score = score\n",
    "            mejor_grupo = row[\"Grupos\"]\n",
    "            mejor_nombre = row[\"Nombre\"]\n",
    "            mejor_apellidos = row[\"Apellido(s)\"]\n",
    "    # Si supera el umbral, devuelve el grupo y nombre exactos\n",
    "    if mejor_score >= umbral:\n",
    "        return mejor_grupo, mejor_nombre, mejor_apellidos\n",
    "    # Si no supera el umbral pero hay algún match > 20%, devuelve el más parecido\n",
    "    if mejor_score >= 20:\n",
    "        return mejor_grupo, mejor_nombre, mejor_apellidos\n",
    "    # Si no hay nada ni con 20%, busca patrón OCR\n",
    "    if texto_ocr:\n",
    "        texto_ocr = texto_ocr.upper()\n",
    "        patrones = [\n",
    "            r\"CITI[TM][1][12]\", r\"IWSI[TM][1][12]\", r\"IWSIT[1][12]\", r\"CITIT[1][12]\", r\"IWSIM[1][12]\"\n",
    "        ]\n",
    "        for patron in patrones:\n",
    "            match = re.search(patron, texto_ocr)\n",
    "            if match:\n",
    "                return match.group(0), \"\", \"\"\n",
    "    return \"extraviado\", \"\", \"\"\n",
    "\n",
    "def extraer_info_con_openai(base64_image, headers, df):\n",
    "    try:\n",
    "        prompt_completo = (\n",
    "            \"Extract the last name (Apellidos in Spanish), \"\n",
    "            \"the first name (Nombre in Spanish) from the top of the image. \"\n",
    "            \"Extract also the group (Grupo in Spanish) from the top of the image. \"\n",
    "            \"You will find them handwritten after the labels `Apellidos` and `Nombre` and `Group` respectively. \"\n",
    "            \"The fields of your JSON output will have those exact same label names. \"\n",
    "            \"Also determine if this is a \\\"Práctica de Listas\\\" (practice 3) or \\\"Práctica de Grafos\\\" (practice 5) based on the content. \"\n",
    "            \"Add a field called \\\"practica_detectada\\\" with value 3 for listas or 5 for grafos. \"\n",
    "            \"If you see a group label like CITIM11, CITIM12, IWSIM11, IWSIM12, CITIT11, IWSIT11, IWSIT12, include it as the field 'Grupo'.\"\n",
    "        )\n",
    "        payload = {\n",
    "            \"model\": \"gpt-4o\",\n",
    "            \"response_format\": {\"type\": \"json_object\"},\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": \"You are a helpful assistant designed to see an exam and output JSON with the extracted information.\"\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\"type\": \"text\", \"text\": prompt_completo},\n",
    "                        {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{base64_image}\"}}\n",
    "                    ]\n",
    "                }\n",
    "            ],\n",
    "            \"max_tokens\": 300\n",
    "        }\n",
    "        try:\n",
    "            response = requests.post(\n",
    "                \"https://api.openai.com/v1/chat/completions\",\n",
    "                headers=headers,\n",
    "                json=payload,\n",
    "                timeout=10\n",
    "            )\n",
    "        except requests.exceptions.Timeout:\n",
    "            return None, \"Timeout: La petición a OpenAI tardó más de 10 segundos.\"\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            return None, f\"Error de conexión con OpenAI: {e}\"\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            info_str = response.json()['choices'][0]['message']['content']\n",
    "            try:\n",
    "                info = json.loads(info_str)\n",
    "                nombre_ocr = info.get(\"Nombre\", \"\")\n",
    "                apellidos_ocr = info.get(\"Apellidos\", \"\")\n",
    "                grupo_ocr = info.get(\"Grupo\", \"\")\n",
    "                grupo, nombre, apellidos = buscar_grupo_flexible(nombre_ocr, apellidos_ocr, df, texto_ocr=grupo_ocr)\n",
    "                info[\"Grupo\"] = grupo\n",
    "                # Si se encontró en el excel, usa los nombres del excel (más limpios)\n",
    "                if grupo != \"extraviado\" and nombre and apellidos:\n",
    "                    info[\"Nombre\"] = nombre\n",
    "                    info[\"Apellidos\"] = apellidos\n",
    "                else:\n",
    "                    # Si no, limpia los nombres extraídos por OCR\n",
    "                    info[\"Nombre\"] = limpiar_texto(nombre_ocr)\n",
    "                    info[\"Apellidos\"] = limpiar_texto(apellidos_ocr)\n",
    "                if grupo == \"extraviado\" and grupo_ocr:\n",
    "                    info[\"Grupo_detectado\"] = grupo_ocr\n",
    "                return info, None\n",
    "            except json.JSONDecodeError as e:\n",
    "                return None, f\"Error parseando JSON: {e}\\nRespuesta recibida: {info_str}\"\n",
    "        else:\n",
    "            return None, f\"Error en API OpenAI: {response.status_code} - {response.text}\"\n",
    "    except Exception as e:\n",
    "        return None, f\"Error extrayendo información: {e}\"\n",
    "\n",
    "def extraer_solo_practica(base64_image, headers):\n",
    "    try:\n",
    "        prompt_practica = (\n",
    "            \"Look at this exam image and determine if this is a \\\"Práctica de Listas\\\" (practice 3) \"\n",
    "            \"or \\\"Práctica de Grafos\\\" (practice 5) based on the content. \"\n",
    "            \"Return JSON with fields: \\\"Apellidos\\\": \\\"\\\", \\\"Nombre\\\": \\\"\\\", \\\"Grupo\\\": \\\"extraviado\\\", \\\"practica_detectada\\\": 3 or 5\"\n",
    "        )\n",
    "        payload = {\n",
    "            \"model\": \"gpt-4o\",\n",
    "            \"response_format\": {\"type\": \"json_object\"},\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": \"You are a helpful assistant that identifies exam types and outputs JSON.\",\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\"type\": \"text\", \"text\": prompt_practica},\n",
    "                        {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{base64_image}\"}}\n",
    "                    ]\n",
    "                }\n",
    "            ],\n",
    "            \"max_tokens\": 150\n",
    "        }\n",
    "        try:\n",
    "            response = requests.post(\n",
    "                \"https://api.openai.com/v1/chat/completions\",\n",
    "                headers=headers,\n",
    "                json=payload,\n",
    "                timeout=10\n",
    "            )\n",
    "        except requests.exceptions.Timeout:\n",
    "            return None, \"Timeout: La petición a OpenAI tardó más de 10 segundos (solo práctica).\"\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            return None, f\"Error de conexión con OpenAI (solo práctica): {e}\"\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            info_str = response.json()['choices'][0]['message']['content']\n",
    "            try:\n",
    "                info = json.loads(info_str)\n",
    "                return info, None\n",
    "            except json.JSONDecodeError:\n",
    "                return None, f\"Error parseando JSON (solo práctica): {info_str}\"\n",
    "        else:\n",
    "            return None, f\"Error en API OpenAI (solo práctica): {response.status_code} - {response.text}\"\n",
    "    except Exception as e:\n",
    "        return None, f\"Error en retry de práctica: {e}\"\n",
    "\n",
    "def extraer_numero_lote(nombre):\n",
    "    match = re.search(r\"lote_(\\d+)\", nombre)\n",
    "    return int(match.group(1)) if match else 0\n",
    "\n",
    "def mover_archivo_organizado(archivo_original, info, output_path):\n",
    "    try:\n",
    "        practica = info.get('practica_detectada', 'desconocida')\n",
    "        grupo = info.get('Grupo', 'extraviado')\n",
    "        carpeta_grupo = output_path / grupo\n",
    "        carpeta_practica = carpeta_grupo / f\"Practica_{practica}\"\n",
    "        carpeta_practica.mkdir(parents=True, exist_ok=True)\n",
    "        apellidos = info.get('Apellidos', '').strip()\n",
    "        nombre = info.get('Nombre', '').strip()\n",
    "        if grupo == \"extraviado\" and not apellidos and not nombre:\n",
    "            nombre_base = Path(info.get('archivo_original', archivo_original.name)).stem\n",
    "        else:\n",
    "            apellidos = apellidos if apellidos else 'SinApellidos'\n",
    "            nombre = nombre if nombre else 'SinNombre'\n",
    "            nombre_base = f\"{apellidos.replace(' ', '_')}_{nombre.replace(' ', '_')}\"\n",
    "            if grupo == \"extraviado\" and info.get('Grupo_detectado'):\n",
    "                nombre_base += f\"_{info['Grupo_detectado']}\"\n",
    "        extension = archivo_original.suffix\n",
    "        nuevo_archivo = carpeta_practica / f\"{nombre_base}{extension}\"\n",
    "        contador = 2\n",
    "        while nuevo_archivo.exists():\n",
    "            nuevo_archivo = carpeta_practica / f\"{nombre_base}_{contador}{extension}\"\n",
    "            contador += 1\n",
    "        shutil.copy2(archivo_original, nuevo_archivo)\n",
    "        print(f\"  → Guardado en: {carpeta_grupo.name}/{carpeta_practica.name}/{nuevo_archivo.name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error organizando archivo {archivo_original.name}: {e}\")\n",
    "\n",
    "def crear_dataframe_examenes(examenes_info, df):\n",
    "    df_base = df[['Nombre', 'Apellido(s)', 'Grupos']].copy()\n",
    "    df_base['Examen_3'] = 0\n",
    "    df_base['Comentario_Examen_3'] = 'PNP'\n",
    "    df_base['Examen_5'] = 0\n",
    "    df_base['Comentario_Examen_5'] = 'PNP'\n",
    "    for examen in examenes_info:\n",
    "        practica = examen.get('practica_detectada')\n",
    "        if practica in [3, 5, '3', '5']:\n",
    "            practica = str(practica)\n",
    "            apellidos = examen.get('Apellidos', '').upper().strip()\n",
    "            nombre = examen.get('Nombre', '').upper().strip()\n",
    "            if apellidos and nombre:\n",
    "                mask = df_base['Apellido(s)'].str.upper().str.strip() == apellidos\n",
    "                mask &= df_base['Nombre'].str.upper().str.strip() == nombre\n",
    "                if mask.any():\n",
    "                    df_base.loc[mask, f'Examen_{practica}'] = 1\n",
    "                    df_base.loc[mask, f'Comentario_Examen_{practica}'] = ''\n",
    "                    print(f\"  → Marcado como presentado: {nombre} {apellidos} - Práctica {practica}\")\n",
    "    return df_base\n",
    "\n",
    "def procesar_examenes_completo(carpeta_examenes=\"../data/saved/\", output_dir=\"../data/examenes_procesados/\"):\n",
    "    output_path = Path(output_dir)\n",
    "    output_path.mkdir(parents=True, exist_ok=True)\n",
    "    extraviados_path = output_path / \"extraviados\"\n",
    "    extraviados_path.mkdir(parents=True, exist_ok=True)\n",
    "    examenes_info = []\n",
    "    errores_openai = []\n",
    "    # Ordenar por número de lote, no alfabéticamente\n",
    "    pdf_files = sorted(Path(carpeta_examenes).glob(\"*.pdf\"), key=lambda x: extraer_numero_lote(x.name))\n",
    "    print(f\"Procesando {len(pdf_files)} exámenes...\")\n",
    "    api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {api_key}\"\n",
    "    }\n",
    "    # Cargar DataFrame de alumnos\n",
    "    students_info = [\"./../data/courseid_422_participants.csv\", \"./../data/courseid_23101_participants.csv\"]\n",
    "    dfs = [ pd.read_csv(filename) for filename in students_info ]\n",
    "    df = pd.concat(dfs, ignore_index=True)\n",
    "    df[\"Nombre\"] = df[\"Nombre\"].str.strip().str.upper()\n",
    "    df[\"Apellido(s)\"] = df[\"Apellido(s)\"].str.strip().str.upper()\n",
    "    for pdf_file in pdf_files:\n",
    "        print(f\"\\nProcesando: {pdf_file.name}\")\n",
    "        try:\n",
    "            reader = PdfReader(pdf_file)\n",
    "            num_pages = len(reader.pages)\n",
    "            info_extraida = None\n",
    "            error_detalle = None\n",
    "            for page_num in range(min(2, num_pages)):\n",
    "                images = convert_from_path(\n",
    "                    pdf_file,\n",
    "                    first_page=page_num + 1,\n",
    "                    last_page=page_num + 1,\n",
    "                    dpi=150,\n",
    "                    fmt='jpeg'\n",
    "                )\n",
    "                if not images:\n",
    "                    continue\n",
    "                buffered = io.BytesIO()\n",
    "                images[0].save(buffered, format=\"JPEG\")\n",
    "                base64_image = base64.b64encode(buffered.getvalue()).decode('utf-8')\n",
    "                info, error = extraer_info_con_openai(base64_image, headers, df)\n",
    "                if info and info.get('Apellidos') and info.get('Nombre'):\n",
    "                    info['archivo_original'] = pdf_file.name\n",
    "                    info['pagina'] = page_num + 1\n",
    "                    info_extraida = info\n",
    "                    break\n",
    "                elif info and not info.get('Apellidos'):\n",
    "                    info_retry, error_retry = extraer_solo_practica(base64_image, headers)\n",
    "                    if info_retry:\n",
    "                        info_extraida = info_retry\n",
    "                        info_extraida['archivo_original'] = pdf_file.name\n",
    "                        info_extraida['pagina'] = page_num + 1\n",
    "                        break\n",
    "                    elif error_retry:\n",
    "                        error_detalle = error_retry\n",
    "                elif error:\n",
    "                    error_detalle = error\n",
    "            if info_extraida:\n",
    "                mover_archivo_organizado(pdf_file, info_extraida, output_path)\n",
    "                examenes_info.append(info_extraida)\n",
    "                practica = info_extraida.get('practica_detectada', 'desconocida')\n",
    "                print(f\"✓ Extraído: {info_extraida.get('Nombre', 'Sin nombre')} {info_extraida.get('Apellidos', 'Sin apellidos')} - Grupo: {info_extraida.get('Grupo', 'extraviado')} - Práctica: {practica}\")\n",
    "            else:\n",
    "                shutil.copy2(pdf_file, extraviados_path / pdf_file.name)\n",
    "                print(f\"✗ No se pudo extraer información - Copiado a extraviados: {pdf_file.name}\")\n",
    "                errores_openai.append({\n",
    "                    \"archivo\": pdf_file.name,\n",
    "                    \"error\": error_detalle or \"No se pudo extraer información ni con retry\",\n",
    "                })\n",
    "        except Exception as e:\n",
    "            print(f\"✗ Error procesando {pdf_file.name}: {e}\")\n",
    "            try:\n",
    "                shutil.copy2(pdf_file, extraviados_path / pdf_file.name)\n",
    "                print(f\"  → Copiado a extraviados por error\")\n",
    "            except:\n",
    "                pass\n",
    "            errores_openai.append({\n",
    "                \"archivo\": pdf_file.name,\n",
    "                \"error\": str(e),\n",
    "            })\n",
    "            continue\n",
    "    df_examenes = crear_dataframe_examenes(examenes_info, df)\n",
    "    df_examenes.to_csv(output_path / \"seguimiento_examenes.csv\", index=False)\n",
    "    print(f\"\\n📊 Procesamiento completado:\")\n",
    "    print(f\"- Exámenes procesados: {len(examenes_info)}\")\n",
    "    print(f\"- Archivos en extraviados: {len(list(extraviados_path.glob('*.pdf')))}\")\n",
    "    print(f\"- Archivo de seguimiento guardado en: {output_path / 'seguimiento_examenes.csv'}\")\n",
    "    # Crear DataFrame de errores y mostrarlo\n",
    "    if errores_openai:\n",
    "        df_errores = pd.DataFrame(errores_openai)\n",
    "        df_errores.to_csv(output_path / \"errores_openai.csv\", index=False)\n",
    "        print(f\"\\n❗ Casos fallidos por OpenAI guardados en: {output_path / 'errores_openai.csv'}\")\n",
    "        print(df_errores)\n",
    "    else:\n",
    "        print(\"\\n✅ No hubo errores de extracción con OpenAI.\")\n",
    "    return df_examenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Resumen de exámenes procesados por grupo:\n"
     ]
    }
   ],
   "source": [
    "# Ejecutar el procesamiento\n",
    "#df_examenes_procesados = procesar_examenes_completo()\n",
    "print(\"\\n📊 Resumen de exámenes procesados por grupo:\")\n",
    "#print(df_examenes_procesados.groupby('Grupos')[['Examen_3', 'Examen_5']].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from pdf2image import convert_from_path\n",
    "from pypdf import PdfReader\n",
    "from ipywidgets import Button, HBox, VBox, Output, Layout, Label, Text, Dropdown, Checkbox\n",
    "from IPython.display import display, clear_output\n",
    "from tqdm.notebook import tqdm\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class JupyterExamReviewer:\n",
    "    def __init__(self, examenes_dir=\"../data/examenes_procesados/\"):\n",
    "        self.examenes_dir = Path(examenes_dir)\n",
    "        self.current_index = 0\n",
    "        self.exam_files = []\n",
    "        self.changes_pending = {}  # Diccionario para almacenar cambios pendientes\n",
    "        self.out = Output()\n",
    "        self.status = Label(value=\"Cargando exámenes...\")\n",
    "        \n",
    "        # Cargar todos los archivos PDF\n",
    "        self._load_exam_files()\n",
    "        \n",
    "        if not self.exam_files:\n",
    "            self.status.value = \"No se encontraron exámenes para revisar\"\n",
    "            return\n",
    "            \n",
    "        # Configurar widgets\n",
    "        self._setup_widgets()\n",
    "        self._show_current_exam()\n",
    "\n",
    "    def _load_exam_files(self):\n",
    "        \"\"\"Carga todos los archivos PDF de todas las carpetas de grupos y prácticas\"\"\"\n",
    "        print(\"🔍 Escaneando carpetas de exámenes...\")\n",
    "        \n",
    "        for grupo_dir in self.examenes_dir.iterdir():\n",
    "            if grupo_dir.is_dir() and grupo_dir.name not in [\"extraviados\", \"problemático\"]:\n",
    "                for practica_dir in grupo_dir.iterdir():\n",
    "                    if practica_dir.is_dir() and practica_dir.name.startswith(\"Practica_\"):\n",
    "                        for pdf_file in practica_dir.glob(\"*.pdf\"):\n",
    "                            self.exam_files.append({\n",
    "                                'file_path': pdf_file,\n",
    "                                'grupo_actual': grupo_dir.name,\n",
    "                                'practica': practica_dir.name,\n",
    "                                'nombre_archivo': pdf_file.stem\n",
    "                            })\n",
    "        \n",
    "        # Ordenar por grupo y luego por nombre\n",
    "        self.exam_files.sort(key=lambda x: (x['grupo_actual'], x['nombre_archivo']))\n",
    "        print(f\"📁 Total de exámenes encontrados: {len(self.exam_files)}\")\n",
    "\n",
    "    def _setup_widgets(self):\n",
    "        \"\"\"Configura todos los widgets de la interfaz\"\"\"\n",
    "        # Botones de navegación\n",
    "        self.btn_prev = Button(description='← Anterior', layout=Layout(width='120px'))\n",
    "        self.btn_next = Button(description='Siguiente →', layout=Layout(width='120px'))\n",
    "        \n",
    "        # Campos de edición\n",
    "        self.txt_nombre = Text(description='Nombre:', layout=Layout(width='300px'))\n",
    "        self.txt_apellidos = Text(description='Apellidos:', layout=Layout(width='300px'))\n",
    "        \n",
    "        # Dropdown para cambiar grupo\n",
    "        grupos_disponibles = [d.name for d in self.examenes_dir.iterdir() \n",
    "                             if d.is_dir() and d.name not in [\"extraviados\", \"problemático\"]]\n",
    "        grupos_disponibles.extend([\"extraviados\", \"problemático\"])  # Añadir opciones especiales\n",
    "        \n",
    "        self.dropdown_grupo = Dropdown(\n",
    "            options=grupos_disponibles,\n",
    "            description='Grupo:',\n",
    "            layout=Layout(width='200px')\n",
    "        )\n",
    "        \n",
    "        # Checkboxes para confirmar carpetas correctas\n",
    "        self.check_nombre_ok = Checkbox(description='Nombre correcto', value=True)\n",
    "        self.check_grupo_ok = Checkbox(description='Grupo correcto', value=True)\n",
    "        \n",
    "        # Botón para aplicar cambios\n",
    "        self.btn_apply = Button(\n",
    "            description='✓ Aplicar Cambios',\n",
    "            button_style='success',\n",
    "            layout=Layout(width='150px')\n",
    "        )\n",
    "        \n",
    "        # Contador de progreso\n",
    "        self.progress_label = Label(value=\"\")\n",
    "        \n",
    "        # Conectar eventos\n",
    "        self.btn_prev.on_click(lambda x: self._navigate(-1))\n",
    "        self.btn_next.on_click(lambda x: self._navigate(1))\n",
    "        self.btn_apply.on_click(lambda x: self._apply_changes())\n",
    "        \n",
    "        # Layout de la interfaz\n",
    "        controls_row1 = HBox([\n",
    "            self.btn_prev, \n",
    "            self.progress_label,\n",
    "            self.btn_next\n",
    "        ])\n",
    "        \n",
    "        edit_row = HBox([\n",
    "            self.txt_nombre,\n",
    "            self.txt_apellidos,\n",
    "            self.dropdown_grupo\n",
    "        ])\n",
    "        \n",
    "        check_row = HBox([\n",
    "            self.check_nombre_ok,\n",
    "            self.check_grupo_ok,\n",
    "            self.btn_apply\n",
    "        ])\n",
    "        \n",
    "        self.interface = VBox([\n",
    "            controls_row1,\n",
    "            edit_row,\n",
    "            check_row,\n",
    "            self.status,\n",
    "            self.out\n",
    "        ])\n",
    "        \n",
    "        display(self.interface)\n",
    "\n",
    "    def _show_current_exam(self):\n",
    "        \"\"\"Muestra el examen actual\"\"\"\n",
    "        if not self.exam_files:\n",
    "            return\n",
    "            \n",
    "        current_exam = self.exam_files[self.current_index]\n",
    "        \n",
    "        # Actualizar contador de progreso\n",
    "        self.progress_label.value = f\"Examen {self.current_index + 1} de {len(self.exam_files)}\"\n",
    "        \n",
    "        # Actualizar campos con información actual\n",
    "        nombre_completo = current_exam['nombre_archivo']\n",
    "        partes = nombre_completo.replace('_', ' ').split()\n",
    "        \n",
    "        if len(partes) >= 2:\n",
    "            self.txt_apellidos.value = ' '.join(partes[:-1])\n",
    "            self.txt_nombre.value = partes[-1]\n",
    "        else:\n",
    "            self.txt_apellidos.value = nombre_completo\n",
    "            self.txt_nombre.value = \"\"\n",
    "            \n",
    "        self.dropdown_grupo.value = current_exam['grupo_actual']\n",
    "        \n",
    "        # Resetear checkboxes\n",
    "        self.check_nombre_ok.value = True\n",
    "        self.check_grupo_ok.value = True\n",
    "        \n",
    "        # Mostrar información del archivo\n",
    "        self.status.value = f\"📁 {current_exam['grupo_actual']} / {current_exam['practica']} / {current_exam['nombre_archivo']}.pdf\"\n",
    "        \n",
    "        # Mostrar imagen del examen\n",
    "        self._show_exam_image(current_exam['file_path'])\n",
    "\n",
    "    def _show_exam_image(self, pdf_path):\n",
    "        \"\"\"Muestra las páginas del PDF (hasta 2 páginas)\"\"\"\n",
    "        with self.out:\n",
    "            clear_output(wait=True)\n",
    "            try:\n",
    "                # Contar páginas primero\n",
    "                reader = PdfReader(pdf_path)\n",
    "                num_pages = len(reader.pages)\n",
    "                \n",
    "                # Si el PDF no tiene exactamente 2 páginas, ofrecer opción \"problemático\"\n",
    "                if num_pages != 2:\n",
    "                    print(f\"⚠️ El PDF tiene {num_pages} página(s) en lugar de 2\")\n",
    "                    print(\"💡 Considera moverlo a la carpeta 'problemático'\")\n",
    "                    # Actualizar dropdown para mostrar \"problemático\" como opción sugerida\n",
    "                    if \"problemático\" not in [opt for opt in self.dropdown_grupo.options]:\n",
    "                        self.dropdown_grupo.value = \"problemático\"\n",
    "                \n",
    "                # Convertir hasta 2 páginas\n",
    "                pages_to_show = min(2, num_pages)\n",
    "                images = convert_from_path(\n",
    "                    pdf_path,\n",
    "                    first_page=1,\n",
    "                    last_page=pages_to_show,\n",
    "                    dpi=150,\n",
    "                    fmt='jpeg'\n",
    "                )\n",
    "                \n",
    "                if images:\n",
    "                    # Configurar subplots según el número de imágenes\n",
    "                    if len(images) == 1:\n",
    "                        fig, ax = plt.subplots(1, 1, figsize=(12, 8))\n",
    "                        axes = [ax]\n",
    "                    else:\n",
    "                        fig, axes = plt.subplots(1, 2, figsize=(20, 10))\n",
    "                    \n",
    "                    for i, image in enumerate(images):\n",
    "                        # Recortar la parte superior (donde están los datos del estudiante)\n",
    "                        if i == 0:  # Primera página - cabecera\n",
    "                            cropped = image.crop((0, 0, image.width, min(600, image.height // 3)))\n",
    "                            title = f\"Página {i+1} - Cabecera\"\n",
    "                        else:  # Segunda página - completa pero más pequeña\n",
    "                            cropped = image.crop((0, 0, image.width, image.height))\n",
    "                            title = f\"Página {i+1} - Completa\"\n",
    "                        \n",
    "                        axes[i].imshow(cropped)\n",
    "                        axes[i].axis('off')\n",
    "                        axes[i].set_title(title)\n",
    "                    \n",
    "                    plt.suptitle(f\"Examen: {pdf_path.name} ({num_pages} página(s))\")\n",
    "                    plt.tight_layout()\n",
    "                    plt.show()\n",
    "                else:\n",
    "                    print(\"❌ No se pudo cargar la imagen del PDF\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"❌ Error cargando imagen: {e}\")\n",
    "\n",
    "    def _navigate(self, direction):\n",
    "        \"\"\"Navega al examen anterior o siguiente\"\"\"\n",
    "        # Aplicar cambios pendientes si los hay\n",
    "        if self._has_pending_changes():\n",
    "            self._apply_changes()\n",
    "        \n",
    "        # Cambiar índice\n",
    "        new_index = self.current_index + direction\n",
    "        \n",
    "        if 0 <= new_index < len(self.exam_files):\n",
    "            self.current_index = new_index\n",
    "            self._show_current_exam()\n",
    "        elif new_index >= len(self.exam_files):\n",
    "            self.status.value = \"🎉 ¡Revisión completada! Has llegado al final.\"\n",
    "        elif new_index < 0:\n",
    "            self.status.value = \"📍 Ya estás en el primer examen.\"\n",
    "\n",
    "    def _has_pending_changes(self):\n",
    "        \"\"\"Verifica si hay cambios pendientes\"\"\"\n",
    "        if not self.exam_files:\n",
    "            return False\n",
    "            \n",
    "        current_exam = self.exam_files[self.current_index]\n",
    "        \n",
    "        # Verificar cambios en nombre/apellidos\n",
    "        nombre_actual = self.txt_nombre.value.strip().upper()\n",
    "        apellidos_actual = self.txt_apellidos.value.strip().upper()\n",
    "        nuevo_nombre = f\"{apellidos_actual}_{nombre_actual}\".replace(' ', '_')\n",
    "        \n",
    "        nombre_archivo_actual = current_exam['nombre_archivo']\n",
    "        \n",
    "        # Verificar cambio de grupo\n",
    "        grupo_cambio = self.dropdown_grupo.value != current_exam['grupo_actual']\n",
    "        nombre_cambio = nuevo_nombre != nombre_archivo_actual\n",
    "        \n",
    "        return grupo_cambio or nombre_cambio or not self.check_nombre_ok.value or not self.check_grupo_ok.value\n",
    "\n",
    "    def _apply_changes(self):\n",
    "        \"\"\"Aplica los cambios al archivo actual\"\"\"\n",
    "        if not self.exam_files:\n",
    "            return\n",
    "            \n",
    "        current_exam = self.exam_files[self.current_index]\n",
    "        old_path = current_exam['file_path']\n",
    "        \n",
    "        try:\n",
    "            # Preparar nuevo nombre de archivo\n",
    "            nombre_nuevo = self.txt_nombre.value.strip().replace(' ', '_')\n",
    "            apellidos_nuevo = self.txt_apellidos.value.strip().replace(' ', '_')\n",
    "            nuevo_nombre_archivo = f\"{apellidos_nuevo}_{nombre_nuevo}\"\n",
    "            \n",
    "            # Preparar nueva ubicación\n",
    "            nuevo_grupo = self.dropdown_grupo.value\n",
    "            practica_actual = current_exam['practica']\n",
    "            \n",
    "            nueva_carpeta = self.examenes_dir / nuevo_grupo\n",
    "            if nuevo_grupo not in [\"extraviados\", \"problemático\"]:\n",
    "                nueva_carpeta = nueva_carpeta / practica_actual\n",
    "            \n",
    "            # Crear carpeta si no existe\n",
    "            nueva_carpeta.mkdir(parents=True, exist_ok=True)\n",
    "            \n",
    "            # Nuevo path completo\n",
    "            nuevo_path = nueva_carpeta / f\"{nuevo_nombre_archivo}.pdf\"\n",
    "            \n",
    "            # Evitar conflictos de nombres\n",
    "            contador = 2\n",
    "            while nuevo_path.exists() and nuevo_path != old_path:\n",
    "                nuevo_path = nueva_carpeta / f\"{nuevo_nombre_archivo}_{contador}.pdf\"\n",
    "                contador += 1\n",
    "            \n",
    "            # Mover archivo si es necesario\n",
    "            if nuevo_path != old_path:\n",
    "                shutil.move(str(old_path), str(nuevo_path))\n",
    "                \n",
    "                # Actualizar información en la lista\n",
    "                current_exam['file_path'] = nuevo_path\n",
    "                current_exam['grupo_actual'] = nuevo_grupo\n",
    "                current_exam['nombre_archivo'] = nuevo_path.stem\n",
    "                \n",
    "                self.status.value = f\"✅ Movido a: {nuevo_grupo}/{nuevo_path.name}\"\n",
    "            else:\n",
    "                self.status.value = \"ℹ️ Sin cambios necesarios\"\n",
    "                \n",
    "        except Exception as e:\n",
    "            self.status.value = f\"❌ Error aplicando cambios: {e}\"\n",
    "\n",
    "def iniciar_revision_examenes(examenes_dir=\"../data/examenes_procesados/\"):\n",
    "    \"\"\"Inicia la interfaz de revisión de exámenes\"\"\"\n",
    "    print(\"🚀 Iniciando revisor de exámenes...\")\n",
    "    reviewer = JupyterExamReviewer(examenes_dir)\n",
    "    return reviewer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reviewer = iniciar_revision_examenes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from pdf2image import convert_from_path\n",
    "from pypdf import PdfReader\n",
    "from ipywidgets import Button, HBox, VBox, Output, Layout, Label, Text, Dropdown, Checkbox\n",
    "from IPython.display import display, clear_output\n",
    "from tqdm.notebook import tqdm\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class JupyterExamReviewer:\n",
    "    def __init__(self, examenes_dir=\"../data/examenes_procesados/\"):\n",
    "        self.examenes_dir = Path(examenes_dir)\n",
    "        self.current_index = 0\n",
    "        self.exam_files = []\n",
    "        self.changes_pending = {}  # Diccionario para almacenar cambios pendientes\n",
    "        self.out = Output()\n",
    "        self.status = Label(value=\"Cargando exámenes...\")\n",
    "        \n",
    "        # Cargar todos los archivos PDF\n",
    "        self._load_exam_files()\n",
    "        \n",
    "        if not self.exam_files:\n",
    "            self.status.value = \"No se encontraron exámenes para revisar\"\n",
    "            return\n",
    "            \n",
    "        # Configurar widgets\n",
    "        self._setup_widgets()\n",
    "        self._show_current_exam()\n",
    "\n",
    "    def _load_exam_files(self):\n",
    "        \"\"\"Carga todos los archivos PDF de todas las carpetas de grupos y prácticas\"\"\"\n",
    "        print(\"🔍 Escaneando carpetas de exámenes...\")\n",
    "        \n",
    "        for grupo_dir in self.examenes_dir.iterdir():\n",
    "            if grupo_dir.is_dir() and grupo_dir.name not in [\"extraviados\", \"problemático\"]:\n",
    "                for practica_dir in grupo_dir.iterdir():\n",
    "                    if practica_dir.is_dir() and practica_dir.name.startswith(\"Practica_\"):\n",
    "                        for pdf_file in practica_dir.glob(\"*.pdf\"):\n",
    "                            self.exam_files.append({\n",
    "                                'file_path': pdf_file,\n",
    "                                'grupo_actual': grupo_dir.name,\n",
    "                                'practica': practica_dir.name,\n",
    "                                'nombre_archivo': pdf_file.stem\n",
    "                            })\n",
    "        \n",
    "        # También cargar archivos de carpetas especiales\n",
    "        for special_dir in [\"extraviados\", \"problemático\"]:\n",
    "            special_path = self.examenes_dir / special_dir\n",
    "            if special_path.exists():\n",
    "                for pdf_file in special_path.glob(\"*.pdf\"):\n",
    "                    self.exam_files.append({\n",
    "                        'file_path': pdf_file,\n",
    "                        'grupo_actual': special_dir,\n",
    "                        'practica': \"\",  # Sin práctica para carpetas especiales\n",
    "                        'nombre_archivo': pdf_file.stem\n",
    "                    })\n",
    "        \n",
    "        # Ordenar por grupo y luego por nombre\n",
    "        self.exam_files.sort(key=lambda x: (x['grupo_actual'], x['nombre_archivo']))\n",
    "        print(f\"📁 Total de exámenes encontrados: {len(self.exam_files)}\")\n",
    "\n",
    "    def _setup_widgets(self):\n",
    "        \"\"\"Configura todos los widgets de la interfaz\"\"\"\n",
    "        # Botones de navegación\n",
    "        self.btn_prev = Button(description='← Anterior', layout=Layout(width='120px'))\n",
    "        self.btn_next = Button(description='Siguiente →', layout=Layout(width='120px'))\n",
    "        \n",
    "        # Campos de edición\n",
    "        self.txt_nombre = Text(description='Nombre:', layout=Layout(width='300px'))\n",
    "        self.txt_apellidos = Text(description='Apellidos:', layout=Layout(width='300px'))\n",
    "        \n",
    "        # Dropdown para cambiar grupo\n",
    "        grupos_disponibles = [d.name for d in self.examenes_dir.iterdir() \n",
    "                             if d.is_dir() and d.name not in [\"extraviados\", \"problemático\"]]\n",
    "        grupos_disponibles.extend([\"extraviados\", \"problemático\"])  # Añadir opciones especiales\n",
    "        \n",
    "        self.dropdown_grupo = Dropdown(\n",
    "            options=grupos_disponibles,\n",
    "            description='Grupo:',\n",
    "            layout=Layout(width='200px')\n",
    "        )\n",
    "        \n",
    "        # Dropdown para cambiar práctica\n",
    "        self.dropdown_practica = Dropdown(\n",
    "            options=['2', '3', '4', '5'],\n",
    "            description='Práctica:',\n",
    "            layout=Layout(width='150px')\n",
    "        )\n",
    "        \n",
    "        # Checkboxes para confirmar carpetas correctas\n",
    "        self.check_nombre_ok = Checkbox(description='Nombre correcto', value=True)\n",
    "        self.check_grupo_ok = Checkbox(description='Grupo correcto', value=True)\n",
    "        \n",
    "        # Botón para aplicar cambios\n",
    "        self.btn_apply = Button(\n",
    "            description='✓ Aplicar Cambios',\n",
    "            button_style='success',\n",
    "            layout=Layout(width='150px')\n",
    "        )\n",
    "        \n",
    "        # Contador de progreso\n",
    "        self.progress_label = Label(value=\"\")\n",
    "        \n",
    "        # Conectar eventos\n",
    "        self.btn_prev.on_click(lambda x: self._navigate(-1))\n",
    "        self.btn_next.on_click(lambda x: self._navigate(1))\n",
    "        self.btn_apply.on_click(lambda x: self._apply_changes())\n",
    "        self.dropdown_grupo.observe(self._on_grupo_change, names='value')\n",
    "        \n",
    "        # Layout de la interfaz\n",
    "        controls_row1 = HBox([\n",
    "            self.btn_prev, \n",
    "            self.progress_label,\n",
    "            self.btn_next\n",
    "        ])\n",
    "        \n",
    "        edit_row = HBox([\n",
    "            self.txt_nombre,\n",
    "            self.txt_apellidos,\n",
    "            self.dropdown_grupo,\n",
    "            self.dropdown_practica\n",
    "        ])\n",
    "        \n",
    "        check_row = HBox([\n",
    "            self.check_nombre_ok,\n",
    "            self.check_grupo_ok,\n",
    "            self.btn_apply\n",
    "        ])\n",
    "        \n",
    "        self.interface = VBox([\n",
    "            controls_row1,\n",
    "            edit_row,\n",
    "            check_row,\n",
    "            self.status,\n",
    "            self.out\n",
    "        ])\n",
    "        \n",
    "        display(self.interface)\n",
    "\n",
    "    def _on_grupo_change(self, change):\n",
    "        \"\"\"Maneja el cambio de grupo para habilitar/deshabilitar dropdown de práctica\"\"\"\n",
    "        if change['new'] in [\"extraviados\", \"problemático\"]:\n",
    "            self.dropdown_practica.disabled = True\n",
    "        else:\n",
    "            self.dropdown_practica.disabled = False\n",
    "\n",
    "    def _show_current_exam(self):\n",
    "        \"\"\"Muestra el examen actual\"\"\"\n",
    "        if not self.exam_files:\n",
    "            return\n",
    "            \n",
    "        current_exam = self.exam_files[self.current_index]\n",
    "        \n",
    "        # Actualizar contador de progreso\n",
    "        self.progress_label.value = f\"Examen {self.current_index + 1} de {len(self.exam_files)}\"\n",
    "        \n",
    "        # Actualizar campos con información actual\n",
    "        nombre_completo = current_exam['nombre_archivo']\n",
    "        partes = nombre_completo.replace('_', ' ').split()\n",
    "        \n",
    "        if len(partes) >= 2:\n",
    "            self.txt_apellidos.value = ' '.join(partes[:-1])\n",
    "            self.txt_nombre.value = partes[-1]\n",
    "        else:\n",
    "            self.txt_apellidos.value = nombre_completo\n",
    "            self.txt_nombre.value = \"\"\n",
    "            \n",
    "        self.dropdown_grupo.value = current_exam['grupo_actual']\n",
    "        \n",
    "        # Extraer número de práctica actual\n",
    "        if current_exam['practica']:\n",
    "            practica_num = current_exam['practica'].replace('Practica_', '')\n",
    "            if practica_num in ['2', '3', '4', '5']:\n",
    "                self.dropdown_practica.value = practica_num\n",
    "            else:\n",
    "                self.dropdown_practica.value = '3'  # valor por defecto\n",
    "        else:\n",
    "            self.dropdown_practica.value = '3'  # valor por defecto para carpetas especiales\n",
    "        \n",
    "        # Habilitar/deshabilitar dropdown de práctica\n",
    "        if current_exam['grupo_actual'] in [\"extraviados\", \"problemático\"]:\n",
    "            self.dropdown_practica.disabled = True\n",
    "        else:\n",
    "            self.dropdown_practica.disabled = False\n",
    "        \n",
    "        # Resetear checkboxes\n",
    "        self.check_nombre_ok.value = True\n",
    "        self.check_grupo_ok.value = True\n",
    "        \n",
    "        # Mostrar información del archivo\n",
    "        if current_exam['practica']:\n",
    "            self.status.value = f\"📁 {current_exam['grupo_actual']} / {current_exam['practica']} / {current_exam['nombre_archivo']}.pdf\"\n",
    "        else:\n",
    "            self.status.value = f\"📁 {current_exam['grupo_actual']} / {current_exam['nombre_archivo']}.pdf\"\n",
    "        \n",
    "        # Mostrar imagen del examen\n",
    "        self._show_exam_image(current_exam['file_path'])\n",
    "\n",
    "    def _show_exam_image(self, pdf_path):\n",
    "        \"\"\"Muestra las páginas del PDF (hasta 2 páginas)\"\"\"\n",
    "        with self.out:\n",
    "            clear_output(wait=True)\n",
    "            try:\n",
    "                # Contar páginas primero\n",
    "                reader = PdfReader(pdf_path)\n",
    "                num_pages = len(reader.pages)\n",
    "                \n",
    "                # Si el PDF no tiene exactamente 2 páginas, ofrecer opción \"problemático\"\n",
    "                if num_pages != 2:\n",
    "                    print(f\"⚠️ El PDF tiene {num_pages} página(s) en lugar de 2\")\n",
    "                    print(\"💡 Considera moverlo a la carpeta 'problemático'\")\n",
    "                \n",
    "                # Convertir hasta 2 páginas\n",
    "                pages_to_show = min(2, num_pages)\n",
    "                images = convert_from_path(\n",
    "                    pdf_path,\n",
    "                    first_page=1,\n",
    "                    last_page=pages_to_show,\n",
    "                    dpi=150,\n",
    "                    fmt='jpeg'\n",
    "                )\n",
    "                \n",
    "                if images:\n",
    "                    # Configurar subplots según el número de imágenes\n",
    "                    if len(images) == 1:\n",
    "                        fig, ax = plt.subplots(1, 1, figsize=(12, 8))\n",
    "                        axes = [ax]\n",
    "                    else:\n",
    "                        fig, axes = plt.subplots(1, 2, figsize=(20, 10))\n",
    "                    \n",
    "                    for i, image in enumerate(images):\n",
    "                        # Recortar la parte superior (donde están los datos del estudiante)\n",
    "                        if i == 0:  # Primera página - cabecera\n",
    "                            cropped = image.crop((0, 0, image.width, min(600, image.height // 3)))\n",
    "                            title = f\"Página {i+1} - Cabecera\"\n",
    "                        else:  # Segunda página - completa pero más pequeña\n",
    "                            cropped = image.crop((0, 0, image.width, image.height))\n",
    "                            title = f\"Página {i+1} - Completa\"\n",
    "                        \n",
    "                        axes[i].imshow(cropped)\n",
    "                        axes[i].axis('off')\n",
    "                        axes[i].set_title(title)\n",
    "                    \n",
    "                    plt.suptitle(f\"Examen: {pdf_path.name} ({num_pages} página(s))\")\n",
    "                    plt.tight_layout()\n",
    "                    plt.show()\n",
    "                else:\n",
    "                    print(\"❌ No se pudo cargar la imagen del PDF\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"❌ Error cargando imagen: {e}\")\n",
    "\n",
    "    def _navigate(self, direction):\n",
    "        \"\"\"Navega al examen anterior o siguiente\"\"\"\n",
    "        # Aplicar cambios pendientes si los hay\n",
    "        if self._has_pending_changes():\n",
    "            self._apply_changes()\n",
    "        \n",
    "        # Cambiar índice\n",
    "        new_index = self.current_index + direction\n",
    "        \n",
    "        if 0 <= new_index < len(self.exam_files):\n",
    "            self.current_index = new_index\n",
    "            self._show_current_exam()\n",
    "        elif new_index >= len(self.exam_files):\n",
    "            self.status.value = \"🎉 ¡Revisión completada! Has llegado al final.\"\n",
    "        elif new_index < 0:\n",
    "            self.status.value = \"📍 Ya estás en el primer examen.\"\n",
    "\n",
    "    def _has_pending_changes(self):\n",
    "        \"\"\"Verifica si hay cambios pendientes\"\"\"\n",
    "        if not self.exam_files:\n",
    "            return False\n",
    "            \n",
    "        current_exam = self.exam_files[self.current_index]\n",
    "        \n",
    "        # Verificar cambios en nombre/apellidos\n",
    "        nombre_actual = self.txt_nombre.value.strip().upper()\n",
    "        apellidos_actual = self.txt_apellidos.value.strip().upper()\n",
    "        nuevo_nombre = f\"{apellidos_actual}_{nombre_actual}\".replace(' ', '_')\n",
    "        \n",
    "        nombre_archivo_actual = current_exam['nombre_archivo']\n",
    "        \n",
    "        # Verificar cambio de grupo\n",
    "        grupo_cambio = self.dropdown_grupo.value != current_exam['grupo_actual']\n",
    "        \n",
    "        # Verificar cambio de práctica\n",
    "        practica_actual = current_exam['practica'].replace('Practica_', '') if current_exam['practica'] else ''\n",
    "        practica_cambio = self.dropdown_practica.value != practica_actual and not self.dropdown_practica.disabled\n",
    "        \n",
    "        nombre_cambio = nuevo_nombre != nombre_archivo_actual\n",
    "        \n",
    "        return grupo_cambio or practica_cambio or nombre_cambio or not self.check_nombre_ok.value or not self.check_grupo_ok.value\n",
    "\n",
    "    def _apply_changes(self):\n",
    "        \"\"\"Aplica los cambios al archivo actual\"\"\"\n",
    "        if not self.exam_files:\n",
    "            return\n",
    "            \n",
    "        current_exam = self.exam_files[self.current_index]\n",
    "        old_path = current_exam['file_path']\n",
    "        \n",
    "        try:\n",
    "            # Preparar nuevo nombre de archivo\n",
    "            nombre_nuevo = self.txt_nombre.value.strip().replace(' ', '_')\n",
    "            apellidos_nuevo = self.txt_apellidos.value.strip().replace(' ', '_')\n",
    "            nuevo_nombre_archivo = f\"{apellidos_nuevo}_{nombre_nuevo}\"\n",
    "            \n",
    "            # Preparar nueva ubicación\n",
    "            nuevo_grupo = self.dropdown_grupo.value\n",
    "            nueva_practica = self.dropdown_practica.value\n",
    "            \n",
    "            nueva_carpeta = self.examenes_dir / nuevo_grupo\n",
    "            \n",
    "            # Solo añadir carpeta de práctica si no es una carpeta especial\n",
    "            if nuevo_grupo not in [\"extraviados\", \"problemático\"]:\n",
    "                nueva_carpeta = nueva_carpeta / f\"Practica_{nueva_practica}\"\n",
    "            \n",
    "            # Crear carpeta si no existe\n",
    "            nueva_carpeta.mkdir(parents=True, exist_ok=True)\n",
    "            \n",
    "            # Nuevo path completo\n",
    "            nuevo_path = nueva_carpeta / f\"{nuevo_nombre_archivo}.pdf\"\n",
    "            \n",
    "            # Evitar conflictos de nombres\n",
    "            contador = 2\n",
    "            while nuevo_path.exists() and nuevo_path != old_path:\n",
    "                nuevo_path = nueva_carpeta / f\"{nuevo_nombre_archivo}_{contador}.pdf\"\n",
    "                contador += 1\n",
    "            \n",
    "            # Mover archivo si es necesario\n",
    "            if nuevo_path != old_path:\n",
    "                shutil.move(str(old_path), str(nuevo_path))\n",
    "                \n",
    "                # Actualizar información en la lista\n",
    "                current_exam['file_path'] = nuevo_path\n",
    "                current_exam['grupo_actual'] = nuevo_grupo\n",
    "                current_exam['practica'] = f\"Practica_{nueva_practica}\" if nuevo_grupo not in [\"extraviados\", \"problemático\"] else \"\"\n",
    "                current_exam['nombre_archivo'] = nuevo_path.stem\n",
    "                \n",
    "                if nuevo_grupo in [\"extraviados\", \"problemático\"]:\n",
    "                    self.status.value = f\"✅ Movido a: {nuevo_grupo}/{nuevo_path.name}\"\n",
    "                else:\n",
    "                    self.status.value = f\"✅ Movido a: {nuevo_grupo}/Practica_{nueva_practica}/{nuevo_path.name}\"\n",
    "            else:\n",
    "                self.status.value = \"ℹ️ Sin cambios necesarios\"\n",
    "                \n",
    "        except Exception as e:\n",
    "            self.status.value = f\"❌ Error aplicando cambios: {e}\"\n",
    "\n",
    "def iniciar_revision_examenes(examenes_dir=\"../data/examenes_procesados/\"):\n",
    "    \"\"\"Inicia la interfaz de revisión de exámenes\"\"\"\n",
    "    print(\"🚀 Iniciando revisor de exámenes...\")\n",
    "    reviewer = JupyterExamReviewer(examenes_dir)\n",
    "    return reviewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reviewer = iniciar_revision_examenes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from pdf2image import convert_from_path\n",
    "from pypdf import PdfReader\n",
    "from ipywidgets import Button, HBox, VBox, Output, Layout, Label, Combobox, Dropdown, HTML, ToggleButtons\n",
    "from IPython.display import display, clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from difflib import get_close_matches\n",
    "import re\n",
    "\n",
    "# --- Cargar el DataFrame de alumnos (ajusta la ruta si es necesario) ---\n",
    "students_info = [\"./../data/courseid_422_participants.csv\", \"./../data/courseid_23101_participants.csv\"]\n",
    "dfs = [pd.read_csv(filename) for filename in students_info]\n",
    "df = pd.concat(dfs, ignore_index=True)\n",
    "df[\"Nombre\"] = df[\"Nombre\"].str.strip().str.upper()\n",
    "df[\"Apellido(s)\"] = df[\"Apellido(s)\"].str.strip().str.upper()\n",
    "df[\"Grupos\"] = df[\"Grupos\"].astype(str).str.strip()\n",
    "\n",
    "# Lista de nombres completos para autocompletar\n",
    "nombres_completos = [\n",
    "    f\"{row['Apellido(s)']} {row['Nombre']}\" for _, row in df.iterrows()\n",
    "]\n",
    "nombre_a_grupo = {\n",
    "    f\"{row['Apellido(s)']} {row['Nombre']}\": row['Grupos'] for _, row in df.iterrows()\n",
    "}\n",
    "\n",
    "class JupyterExamReviewer:\n",
    "    def __init__(self, examenes_dir=\"../data/examenes_procesados/\"):\n",
    "        self.examenes_dir = Path(examenes_dir)\n",
    "        self.current_index = 0\n",
    "        self.exam_files = []\n",
    "        self.out = Output()\n",
    "        self.status = Label(value=\"Cargando exámenes...\")\n",
    "\n",
    "        # Cargar todos los archivos PDF\n",
    "        self._load_exam_files()\n",
    "\n",
    "        if not self.exam_files:\n",
    "            self.status.value = \"No se encontraron exámenes para revisar\"\n",
    "            return\n",
    "\n",
    "        # Configurar widgets\n",
    "        self._setup_widgets()\n",
    "        self._show_current_exam()\n",
    "\n",
    "    def _load_exam_files(self):\n",
    "        print(\"🔍 Escaneando carpetas de exámenes...\")\n",
    "        for grupo_dir in self.examenes_dir.iterdir():\n",
    "            if grupo_dir.is_dir():\n",
    "                for practica_dir in grupo_dir.iterdir():\n",
    "                    if practica_dir.is_dir():\n",
    "                        for pdf_file in practica_dir.glob(\"*.pdf\"):\n",
    "                            self.exam_files.append({\n",
    "                                'file_path': pdf_file,\n",
    "                                'carpeta_actual': grupo_dir.name,\n",
    "                                'practica': practica_dir.name if practica_dir.name.startswith(\"Practica_\") else \"\",\n",
    "                                'nombre_archivo': pdf_file.stem\n",
    "                            })\n",
    "                # También incluir PDFs sueltos en la carpeta (por si acaso)\n",
    "                for pdf_file in grupo_dir.glob(\"*.pdf\"):\n",
    "                    self.exam_files.append({\n",
    "                        'file_path': pdf_file,\n",
    "                        'carpeta_actual': grupo_dir.name,\n",
    "                        'practica': \"\",\n",
    "                        'nombre_archivo': pdf_file.stem\n",
    "                    })\n",
    "        self.exam_files.sort(key=lambda x: (x['carpeta_actual'], x['nombre_archivo']))\n",
    "        print(f\"📁 Total de exámenes encontrados: {len(self.exam_files)}\")\n",
    "\n",
    "    def _setup_widgets(self):\n",
    "        # Status (ruta de archivo) - arriba\n",
    "        self.status.layout = Layout(width='100%')\n",
    "        \n",
    "        # Nombre del alumno (principal)\n",
    "        self.combo_nombre = Combobox(\n",
    "            placeholder='Escribe o selecciona...',\n",
    "            options=nombres_completos,\n",
    "            description='Alumno:',\n",
    "            layout=Layout(width='450px')\n",
    "        )\n",
    "        self.combo_nombre.observe(self._on_nombre_change, names='value')\n",
    "\n",
    "        # Botón de aplicar cambios\n",
    "        self.btn_apply = Button(\n",
    "            description='✓ Aplicar',\n",
    "            button_style='success',\n",
    "            layout=Layout(width='80px')\n",
    "        )\n",
    "        \n",
    "        # Botón para eliminar archivo (NUEVO)\n",
    "        self.btn_delete = Button(\n",
    "            description='🗑️ Eliminar',\n",
    "            button_style='danger',\n",
    "            layout=Layout(width='90px')\n",
    "        )\n",
    "        \n",
    "        # Contador de progreso\n",
    "        self.progress_label = Label(value=\"\", layout=Layout(width='140px'))\n",
    "\n",
    "        # Widgets de grupo, práctica y carpeta\n",
    "        grupos_unicos = sorted(df[\"Grupos\"].unique())\n",
    "        self.dropdown_grupo = Dropdown(\n",
    "            options=grupos_unicos,\n",
    "            description='Grupo:',\n",
    "            layout=Layout(width='280px')  # Más ancho para que se vea bien\n",
    "        )\n",
    "\n",
    "        self.dropdown_practica = Dropdown(\n",
    "            options=['2', '3', '4', '5'],\n",
    "            description='Práctica:',\n",
    "            layout=Layout(width='180px')\n",
    "        )\n",
    "\n",
    "        # Selector de carpeta destino\n",
    "        carpetas_disponibles = [d.name for d in self.examenes_dir.iterdir() if d.is_dir()]\n",
    "        self.dropdown_carpeta = Dropdown(\n",
    "            options=carpetas_disponibles,\n",
    "            description='Carpeta:',\n",
    "            layout=Layout(width='170px')\n",
    "        )\n",
    "        self.dropdown_carpeta.observe(self._on_carpeta_change, names='value')\n",
    "\n",
    "        # HTML para mostrar sugerencias de nombres similares (horizontal)\n",
    "        self.similares_html = HTML(value=\"\", layout=Layout(width='100%', max_height='60px'))\n",
    "\n",
    "        # Botones de navegación \n",
    "        self.btn_prev = Button(description='← Anterior', layout=Layout(width='120px'))\n",
    "        self.btn_next = Button(description='Siguiente →', layout=Layout(width='120px'))\n",
    "        \n",
    "        # Selector de página ajustado (botones a la derecha del texto)\n",
    "        self.page_label = Label(value=\"Ver pág:\", layout=Layout(width='50px'))\n",
    "        self.page_selector = ToggleButtons(\n",
    "            options=[('1', 1), ('2', 2)],\n",
    "            value=1,\n",
    "            description='',  # Quitamos la descripción del control y la ponemos separada\n",
    "            style={'button_width': '30px'},\n",
    "            layout=Layout(width='80px')\n",
    "        )\n",
    "        \n",
    "        self.page_selector.observe(self._on_page_change, names='value')\n",
    "\n",
    "        # Conectar eventos\n",
    "        self.btn_prev.on_click(lambda x: self._navigate(-1))\n",
    "        self.btn_next.on_click(lambda x: self._navigate(1))\n",
    "        self.btn_apply.on_click(lambda x: self._apply_changes())\n",
    "        self.btn_delete.on_click(lambda x: self._delete_current_file())  # NUEVO\n",
    "\n",
    "        # REORGANIZACIÓN DE LA INTERFAZ:\n",
    "        \n",
    "        # Fila 1: Path/status (menos importante, arriba)\n",
    "        status_row = HBox([self.status])\n",
    "        \n",
    "        # Fila 2: Nombre + aplicar + eliminar + progreso (MODIFICADO)\n",
    "        nombre_row = HBox([\n",
    "            self.combo_nombre,\n",
    "            self.btn_apply,\n",
    "            self.btn_delete,  # NUEVO\n",
    "            self.progress_label\n",
    "        ])\n",
    "        \n",
    "        # Fila 3: Grupo, práctica, carpeta (más visibles)\n",
    "        opciones_row = HBox([\n",
    "            self.dropdown_grupo,\n",
    "            self.dropdown_practica, \n",
    "            self.dropdown_carpeta\n",
    "        ])\n",
    "        \n",
    "        # Fila 4: Sugerencias similares (a lo ancho)\n",
    "        sugerencias_row = HBox([self.similares_html])\n",
    "        \n",
    "        # Fila 5: Navegación (abajo) + selector de páginas en línea\n",
    "        page_selector_group = HBox([\n",
    "            self.page_label, \n",
    "            self.page_selector\n",
    "            ], \n",
    "            layout=Layout(width='140px')\n",
    "        )\n",
    "        nav_row = HBox([\n",
    "            self.btn_prev,\n",
    "            self.btn_next,\n",
    "            page_selector_group\n",
    "        ])  \n",
    "\n",
    "        # Layout general\n",
    "        self.interface = VBox([\n",
    "            status_row,\n",
    "            nombre_row,\n",
    "            opciones_row,\n",
    "            sugerencias_row,\n",
    "            nav_row,\n",
    "            self.out\n",
    "        ])\n",
    "\n",
    "        display(self.interface)\n",
    "\n",
    "    def _delete_current_file(self):\n",
    "        \"\"\"Elimina el archivo actual (NUEVO MÉTODO)\"\"\"\n",
    "        if not self.exam_files:\n",
    "            return\n",
    "            \n",
    "        current_exam = self.exam_files[self.current_index]\n",
    "        file_path = current_exam['file_path']\n",
    "        \n",
    "        try:\n",
    "            # Crear carpeta de eliminados si no existe\n",
    "            deleted_folder = self.examenes_dir / \"eliminados\"\n",
    "            deleted_folder.mkdir(exist_ok=True)\n",
    "            \n",
    "            # Mover a la carpeta de eliminados en lugar de eliminar permanentemente\n",
    "            deleted_path = deleted_folder / file_path.name\n",
    "            \n",
    "            # Si ya existe en eliminados, añadir sufijo numérico\n",
    "            contador = 2\n",
    "            while deleted_path.exists():\n",
    "                deleted_path = deleted_folder / f\"{file_path.stem}_{contador}{file_path.suffix}\"\n",
    "                contador += 1\n",
    "            \n",
    "            # Mover archivo\n",
    "            shutil.move(str(file_path), str(deleted_path))\n",
    "            \n",
    "            # Remover de la lista\n",
    "            self.exam_files.pop(self.current_index)\n",
    "            \n",
    "            # Ajustar índice si es necesario\n",
    "            if self.current_index >= len(self.exam_files):\n",
    "                self.current_index = max(0, len(self.exam_files) - 1)\n",
    "            \n",
    "            self.status.value = f\"🗑️ Eliminado: {file_path.name} → eliminados/{deleted_path.name}\"\n",
    "            \n",
    "            # Mostrar siguiente examen o mensaje si no hay más\n",
    "            if self.exam_files:\n",
    "                self._show_current_exam()\n",
    "            else:\n",
    "                self.status.value = \"🎉 No hay más exámenes para revisar\"\n",
    "                with self.out:\n",
    "                    clear_output(wait=True)\n",
    "                    print(\"No hay más exámenes para revisar\")\n",
    "                    \n",
    "        except Exception as e:\n",
    "            self.status.value = f\"❌ Error eliminando archivo: {e}\"\n",
    "\n",
    "    def _on_carpeta_change(self, change):\n",
    "        # Eliminado: Ya no se deshabilita el dropdown de práctica para ninguna carpeta\n",
    "        pass\n",
    "\n",
    "    def _on_nombre_change(self, change):\n",
    "        valor = change['new']\n",
    "        if valor in nombre_a_grupo:\n",
    "            self.dropdown_grupo.value = nombre_a_grupo[valor]\n",
    "            self.combo_nombre.value = valor\n",
    "        self._update_similares(valor)\n",
    "\n",
    "    def _on_page_change(self, change):\n",
    "        self._show_exam_image(self.exam_files[self.current_index]['file_path'])\n",
    "\n",
    "    def _update_similares(self, valor):\n",
    "        if valor:\n",
    "            matches = get_close_matches(valor, nombres_completos, n=4, cutoff=0)\n",
    "            # Mostrar horizontalmente (una sola fila)\n",
    "            html = \"<b>Sugerencias:</b> \"\n",
    "            if matches:\n",
    "                html += \"<span style='display:inline-block;white-space:nowrap;'>\"\n",
    "                for i, m in enumerate(matches):\n",
    "                    html += f\"<span style='display:inline-block;margin-right:20px;font-size:90%'>{m} <span style='color:#888;font-size:85%'>({nombre_a_grupo.get(m, '-')})</span></span>\"\n",
    "                html += \"</span>\"\n",
    "            else:\n",
    "                html += \"<i>No hay sugerencias</i>\"\n",
    "            self.similares_html.value = html\n",
    "        else:\n",
    "            self.similares_html.value = \"\"\n",
    "\n",
    "    def _show_current_exam(self):\n",
    "        if not self.exam_files:\n",
    "            return\n",
    "\n",
    "        current_exam = self.exam_files[self.current_index]\n",
    "        self.progress_label.value = f\"Examen {self.current_index + 1} de {len(self.exam_files)}\"\n",
    "\n",
    "        nombre_completo = current_exam['nombre_archivo'].replace('_', ' ')\n",
    "        mejor_match = None\n",
    "        for n in nombres_completos:\n",
    "            if nombre_completo.upper() in n.upper():\n",
    "                mejor_match = n\n",
    "                break\n",
    "        if mejor_match:\n",
    "            self.combo_nombre.value = mejor_match\n",
    "            self.dropdown_grupo.value = nombre_a_grupo[mejor_match]\n",
    "        else:\n",
    "            self.combo_nombre.value = nombre_completo\n",
    "            self.dropdown_grupo.value = df[\"Grupos\"].iloc[0]  # valor por defecto\n",
    "\n",
    "        self._update_similares(self.combo_nombre.value)\n",
    "\n",
    "        # Práctica\n",
    "        if current_exam['practica']:\n",
    "            practica_num = current_exam['practica'].replace('Practica_', '')\n",
    "            if practica_num in ['2', '3', '4', '5']:\n",
    "                self.dropdown_practica.value = practica_num\n",
    "            else:\n",
    "                self.dropdown_practica.value = '3'\n",
    "        else:\n",
    "            self.dropdown_practica.value = '3'\n",
    "\n",
    "        # Carpeta actual\n",
    "        self.dropdown_carpeta.value = current_exam['carpeta_actual']\n",
    "\n",
    "        # Mostrar solo la página 1 por defecto\n",
    "        self.page_selector.value = 1\n",
    "\n",
    "        # Ajustar el rango del selector de página según el número de páginas\n",
    "        reader = PdfReader(current_exam['file_path'])\n",
    "        num_pages = len(reader.pages)\n",
    "        if num_pages == 1:\n",
    "            self.dropdown_carpeta.value = \"problemático\"\n",
    "            self.page_selector.disabled = True\n",
    "        else:\n",
    "            self.page_selector.disabled = False\n",
    "\n",
    "        # Eliminado: Ya no se deshabilita el dropdown de práctica\n",
    "\n",
    "        if current_exam['practica']:\n",
    "            self.status.value = f\"📁 {current_exam['carpeta_actual']} / {current_exam['practica']} / {current_exam['nombre_archivo']}.pdf\"\n",
    "        else:\n",
    "            self.status.value = f\"📁 {current_exam['carpeta_actual']} / {current_exam['nombre_archivo']}.pdf\"\n",
    "\n",
    "        self._show_exam_image(current_exam['file_path'])\n",
    "\n",
    "    def _show_exam_image(self, pdf_path):\n",
    "        with self.out:\n",
    "            clear_output(wait=True)\n",
    "            try:\n",
    "                reader = PdfReader(pdf_path)\n",
    "                num_pages = len(reader.pages)\n",
    "                page_num = self.page_selector.value\n",
    "                if num_pages == 1:\n",
    "                    page_num = 1\n",
    "                images = convert_from_path(\n",
    "                    pdf_path,\n",
    "                    first_page=page_num,\n",
    "                    last_page=page_num,\n",
    "                    dpi=150,\n",
    "                    fmt='jpeg'\n",
    "                )\n",
    "                if images:\n",
    "                    image = images[0]\n",
    "                    # Recortar más agresivamente por arriba y por abajo (1/4 de la altura)\n",
    "                    cabecera_altura = int(min(450, image.height // 4))\n",
    "                    # Recortar un poco desde arriba también (20 píxeles)\n",
    "                    top_offset = 20\n",
    "                    cropped = image.crop((0, top_offset, image.width, cabecera_altura))\n",
    "                    plt.figure(figsize=(10, 6))  # Altura reducida\n",
    "                    plt.imshow(cropped)\n",
    "                    plt.axis('off')\n",
    "                    plt.tight_layout()\n",
    "                    plt.show()\n",
    "                else:\n",
    "                    print(\"❌ No se pudo cargar la imagen del PDF\")\n",
    "            except Exception as e:\n",
    "                print(f\"❌ Error cargando imagen: {e}\")\n",
    "\n",
    "    def _navigate(self, direction):\n",
    "        if self._has_pending_changes():\n",
    "            self._apply_changes()\n",
    "        new_index = self.current_index + direction\n",
    "        if 0 <= new_index < len(self.exam_files):\n",
    "            self.current_index = new_index\n",
    "            self._show_current_exam()\n",
    "        elif new_index >= len(self.exam_files):\n",
    "            self.status.value = \"🎉 ¡Revisión completada! Has llegado al final.\"\n",
    "        elif new_index < 0:\n",
    "            self.status.value = \"📍 Ya estás en el primer examen.\"\n",
    "\n",
    "    def _has_pending_changes(self):\n",
    "        if not self.exam_files:\n",
    "            return False\n",
    "        current_exam = self.exam_files[self.current_index]\n",
    "        nombre_actual = self.combo_nombre.value.strip().upper().replace(' ', '_')\n",
    "        nombre_archivo_actual = current_exam['nombre_archivo'].upper()\n",
    "        carpeta_cambio = self.dropdown_carpeta.value != current_exam['carpeta_actual']\n",
    "        practica_actual = current_exam['practica'].replace('Practica_', '') if current_exam['practica'] else ''\n",
    "        # Eliminado: \"and not self.dropdown_practica.disabled\" ya que nunca se deshabilita\n",
    "        practica_cambio = self.dropdown_practica.value != practica_actual\n",
    "        grupo_cambio = self.dropdown_grupo.value != nombre_a_grupo.get(self.combo_nombre.value, self.dropdown_grupo.value)\n",
    "        nombre_cambio = nombre_actual != nombre_archivo_actual\n",
    "        return carpeta_cambio or practica_cambio or grupo_cambio or nombre_cambio\n",
    "\n",
    "    def _apply_changes(self):\n",
    "        if not self.exam_files:\n",
    "            return\n",
    "        current_exam = self.exam_files[self.current_index]\n",
    "        old_path = current_exam['file_path']\n",
    "        try:\n",
    "            nombre_nuevo = self.combo_nombre.value.strip().replace(' ', '_')\n",
    "            grupo_para_nombre = self.dropdown_grupo.value\n",
    "            nueva_practica = self.dropdown_practica.value\n",
    "            carpeta_destino = self.dropdown_carpeta.value\n",
    "\n",
    "            # Nombre base: APELLIDOS_NOMBRE_P<num practica>_<Grupo>.pdf\n",
    "            nombre_base = f\"{nombre_nuevo}_P{nueva_practica}_{grupo_para_nombre}\"\n",
    "            nueva_carpeta = self.examenes_dir / carpeta_destino\n",
    "            if carpeta_destino not in [\"extraviados\", \"problemático\"]:\n",
    "                nueva_carpeta = nueva_carpeta / f\"Practica_{nueva_practica}\"\n",
    "            nueva_carpeta.mkdir(parents=True, exist_ok=True)\n",
    "            \n",
    "            # COMPROBACIÓN MEJORADA DE ARCHIVOS EXISTENTES\n",
    "            nuevo_path = nueva_carpeta / f\"{nombre_base}.pdf\"\n",
    "            \n",
    "            # Si el archivo destino es el mismo que el origen, no hacer nada\n",
    "            if nuevo_path == old_path:\n",
    "                self.status.value = \"ℹ️ Sin cambios necesarios\"\n",
    "                return\n",
    "            \n",
    "            # Si existe otro archivo con el mismo nombre, buscar sufijo disponible\n",
    "            contador = 2\n",
    "            while nuevo_path.exists():\n",
    "                # Extraer cualquier sufijo numérico existente del nombre base\n",
    "                match = re.search(r'_(\\d+)$', nombre_base)\n",
    "                if match:\n",
    "                    # Ya tiene sufijo numérico, incrementarlo\n",
    "                    numero_actual = int(match.group(1))\n",
    "                    nombre_sin_sufijo = nombre_base[:match.start()]\n",
    "                    nuevo_nombre_base = f\"{nombre_sin_sufijo}_{numero_actual + contador - 1}\"\n",
    "                else:\n",
    "                    # No tiene sufijo, añadir uno\n",
    "                    nuevo_nombre_base = f\"{nombre_base}_{contador}\"\n",
    "                \n",
    "                nuevo_path = nueva_carpeta / f\"{nuevo_nombre_base}.pdf\"\n",
    "                contador += 1\n",
    "                \n",
    "                # Seguridad: evitar bucle infinito\n",
    "                if contador > 100:\n",
    "                    self.status.value = \"❌ Error: Demasiados archivos duplicados\"\n",
    "                    return\n",
    "            \n",
    "            # Realizar el movimiento de archivo\n",
    "            try:\n",
    "                shutil.move(str(old_path), str(nuevo_path))\n",
    "                \n",
    "                # Actualizar información en la lista\n",
    "                current_exam['file_path'] = nuevo_path\n",
    "                current_exam['carpeta_actual'] = carpeta_destino\n",
    "                current_exam['practica'] = f\"Practica_{nueva_practica}\" if carpeta_destino not in [\"extraviados\", \"problemático\"] else \"\"\n",
    "                current_exam['nombre_archivo'] = nuevo_path.stem\n",
    "                \n",
    "                # Mensaje de confirmación\n",
    "                if carpeta_destino in [\"extraviados\", \"problemático\"]:\n",
    "                    self.status.value = f\"✅ Movido a: {carpeta_destino}/{nuevo_path.name}\"\n",
    "                else:\n",
    "                    self.status.value = f\"✅ Movido a: {carpeta_destino}/Practica_{nueva_practica}/{nuevo_path.name}\"\n",
    "                    \n",
    "                # Si se añadió un sufijo, avisar\n",
    "                if contador > 2:\n",
    "                    self.status.value += f\" (duplicado evitado con sufijo _{contador-2})\"\n",
    "                    \n",
    "            except PermissionError:\n",
    "                self.status.value = \"❌ Error: Archivo en uso o sin permisos\"\n",
    "            except FileNotFoundError:\n",
    "                self.status.value = \"❌ Error: Archivo origen no encontrado\"\n",
    "            except Exception as move_error:\n",
    "                self.status.value = f\"❌ Error moviendo archivo: {move_error}\"\n",
    "                \n",
    "        except Exception as e:\n",
    "            self.status.value = f\"❌ Error aplicando cambios: {e}\"\n",
    "\n",
    "def iniciar_revision_examenes(examenes_dir=\"../data/examenes_procesados/\"):\n",
    "    print(\"🚀 Iniciando revisor de exámenes...\")\n",
    "    reviewer = JupyterExamReviewer(examenes_dir)\n",
    "    return reviewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para lanzar la interfaz:\n",
    "#reviewer = iniciar_revision_examenes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "from datetime import datetime  # AÑADIR ESTE IMPORT\n",
    "\n",
    "def crear_backup_examenes(carpeta_examenes=\"../data/examenes_procesados/\", carpeta_backup=\"../data/\"):\n",
    "    \"\"\"\n",
    "    Crea un backup completo de la carpeta de exámenes procesados\n",
    "    \"\"\"\n",
    "    carpeta_examenes = Path(carpeta_examenes)\n",
    "    carpeta_backup = Path(carpeta_backup)\n",
    "    \n",
    "    # Crear nombre del backup con timestamp\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    nombre_backup = f\"examenes_procesados_backup_{timestamp}.zip\"\n",
    "    ruta_backup = carpeta_backup / nombre_backup\n",
    "    \n",
    "    print(f\"🔄 Creando backup de: {carpeta_examenes}\")\n",
    "    print(f\"📦 Archivo de backup: {ruta_backup}\")\n",
    "    \n",
    "    try:\n",
    "        # Crear el archivo ZIP\n",
    "        with zipfile.ZipFile(ruta_backup, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "            # Recorrer todos los archivos y carpetas\n",
    "            for root, dirs, files in os.walk(carpeta_examenes):\n",
    "                for file in files:\n",
    "                    file_path = Path(root) / file\n",
    "                    # Calcular la ruta relativa para mantener la estructura\n",
    "                    arcname = file_path.relative_to(carpeta_examenes.parent)\n",
    "                    zipf.write(file_path, arcname)\n",
    "                    print(f\"  ✓ Añadido: {arcname}\")\n",
    "        \n",
    "        print(f\"\\n✅ Backup completado exitosamente!\")\n",
    "        print(f\"📁 Tamaño del backup: {ruta_backup.stat().st_size / (1024*1024):.2f} MB\")\n",
    "        print(f\"💾 Ubicación: {ruta_backup}\")\n",
    "        \n",
    "        return str(ruta_backup)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error creando backup: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Creando backup de: ..\\data\\examenes_procesados\n",
      "📦 Archivo de backup: ..\\data\\examenes_procesados_backup_20250611_144747.zip\n",
      "  ✓ Añadido: examenes_procesados\\errores_openai.csv\n",
      "  ✓ Añadido: examenes_procesados\\seguimiento_examenes.csv\n",
      "  ✓ Añadido: examenes_procesados\\CITIM11\\Practica_2\\PARIENTE_CARRIAZO_ANTONIO_P2_CITIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\CITIM11\\Practica_3\\ARIAS_CASADO_ALBA_P3_CITIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\CITIM11\\Practica_3\\CARMONA_OCAÑA_DANIEL_P3_CITIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\CITIM11\\Practica_3\\DE_LA_IGLESIA_NUÑEZ_PEDRO_JOSE_P3_CITIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\CITIM11\\Practica_3\\EXPOSITO_SONO_HARITZ_ENDIKA_P3_CITIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\CITIM11\\Practica_3\\FERNANDEZ_NIETO_DAVID_P3_CITIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\CITIM11\\Practica_3\\GARCIA_FERNANDEZ_LORENZO_P3_CITIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\CITIM11\\Practica_3\\HUERGA_GIL_JAVIER_P3_CITIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\CITIM11\\Practica_3\\LUCERO_PRADA_IRENE_P3_CITIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\CITIM11\\Practica_3\\MARTIN_VERDUGO_CRISTINA_P3_CITIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\CITIM11\\Practica_3\\MASSERA_SALCEDO_GUILLERMO_P3_CITIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\CITIM11\\Practica_3\\MORAN_RUIZ_JAIME_P3_CITIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\CITIM11\\Practica_3\\NAZARENKO_KSENIA_P3_CITIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\CITIM11\\Practica_3\\NIETO_HERNANDEZ_JAVIER_P3_CITIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\CITIM11\\Practica_3\\PLAZA_PASCUAL_LUCAS_P3_CITIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\CITIM11\\Practica_3\\RODRIGUEZ_RAMOS_CARLOS_P3_CITIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\CITIM11\\Practica_3\\TRULL_GONZALEZ_SARA_P3_CITIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\CITIM11\\Practica_5\\AGUIRRIZABAL_MARTINEZ_HUGO_P5_CITIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\CITIM11\\Practica_5\\ARIAS_CASADO_ALBA_P5_CITIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\CITIM11\\Practica_5\\CARMONA_OCAÑA_DANIEL_P5_CITIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\CITIM11\\Practica_5\\CRAUS_SANTA_CATALINA_NICOLAS_P5_CITIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\CITIM11\\Practica_5\\CUTOLO_SPADARO_ROSANGELA_MARIA_P5_CITIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\CITIM11\\Practica_5\\DEL_CAMPO_GONZALEZ_ALVARO_P5_CITIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\CITIM11\\Practica_5\\DE_LA_IGLESIA_NUÑEZ_PEDRO_JOSÉ_P5_CITIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\CITIM11\\Practica_5\\EXPOSITO_SONO_HARITZ_ENDIKA_P5_CITIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\CITIM11\\Practica_5\\FERNANDEZ_NIETO_DAVID_P5_CITIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\CITIM11\\Practica_5\\FERREIRA_SOUZA_JHONATAN_P5_CITIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\CITIM11\\Practica_5\\GARCIA_FERNANDEZ_LORENZO_P5_CITIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\CITIM11\\Practica_5\\GARCIA_GARCIA_MARCOS_P5_CITIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\CITIM11\\Practica_5\\GONZALEZ_RODRIGUEZ_RUBEN_P5_CITIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\CITIM11\\Practica_5\\HIDALGO_POZAS_MIGUEL_P5_CITIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\CITIM11\\Practica_5\\HUERGA_GIL_JAVIER_P5_CITIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\CITIM11\\Practica_5\\JIA_LIU_ZHENGPENG_P5_CITIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\CITIM11\\Practica_5\\JIMENEZ_DIAZ_MARCOS_P5_CITIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\CITIM11\\Practica_5\\LOPEZ_GARCIA_ANDRES_P5_CITIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\CITIM11\\Practica_5\\LOPEZ_RODRIGUEZ_NICOLAS_P5_CITIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\CITIM11\\Practica_5\\LUCERO_PRADA_IRENE_P5_CITIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\CITIM11\\Practica_5\\MAQUEDA_IRUN_HECTOR_P5_CITIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\CITIM11\\Practica_5\\MASSERA_SALCEDO_GUILLERMO_P5_CITIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\CITIM11\\Practica_5\\MIER_DIAZ_DE_ARCAYA_JUAN_P5_CITIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\CITIM11\\Practica_5\\MILLAN_ARRANZ_DAVID_P5_CITIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\CITIM11\\Practica_5\\MORALES_DE_LUIS_JAVIER_P5_CITIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\CITIM11\\Practica_5\\MORAN_RUIZ_JAIME_P5_CITIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\CITIM11\\Practica_5\\MORENO_PULIDO_ADRIAN_P5_CITIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\CITIM11\\Practica_5\\MORENO_SANCHO_SANDRA_P5_CITIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\CITIM11\\Practica_5\\MUNOZ_FANDINHO_ALEJANDRA_MARIA_P5_CITIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\CITIM11\\Practica_5\\NAZARENKO_KSENIA_P5_CITIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\CITIM11\\Practica_5\\OLIVA_RODRIGUEZ_EDUARDO_P5_CITIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\CITIM11\\Practica_5\\PARIENTE_CARRIAZO_ANTONIO_CITITIM11_P5_CITIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\CITIM11\\Practica_5\\RODRIGUEZ_MARTIN_RUBEN_P5_CITIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\CITIM11\\Practica_5\\RODRIGUEZ_RAMOS_CARLOS_P5_CITIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\CITIM11\\Practica_5\\TARRILLO_MUNDACA_JORGE_AUGUSTO_P5_CITIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\CITIM11\\Practica_5\\TERESO_SILVA_LUIS_P5_CITIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\CITIM11\\Practica_5\\TRULL_GONZALEZ_SARA_P5_CITIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\CITIM11\\Practica_5\\XU_HAOYUAN_P5_CITIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\CITIM12\\Practica_3\\GONZALEZ_RODRIGUEZ_RUBEN_P3_CITIM12.pdf\n",
      "  ✓ Añadido: examenes_procesados\\CITIM12\\Practica_3\\JIAYI_LIU_P3_CITIM12.pdf\n",
      "  ✓ Añadido: examenes_procesados\\CITIM12\\Practica_3\\LIU_JIAYI_P3_CITIM12.pdf\n",
      "  ✓ Añadido: examenes_procesados\\CITIM12\\Practica_3\\PAREJAS_LAMBAN_DAVID_P3_CITIM12.pdf\n",
      "  ✓ Añadido: examenes_procesados\\CITIM12\\Practica_3\\PLAZA_PASCUAL_LUCAS_P3_CITIM12.pdf\n",
      "  ✓ Añadido: examenes_procesados\\CITIM12\\Practica_3\\POSE_COSTA_JUAN_FRANCISCO_P3_CITIM12.pdf\n",
      "  ✓ Añadido: examenes_procesados\\CITIM12\\Practica_3\\PUEBLA_MARTINEZ_FELIX_P3_CITIM12.pdf\n",
      "  ✓ Añadido: examenes_procesados\\CITIM12\\Practica_3\\RODRIGUES_ARROYO_HECTOR_P3_CITIM12.pdf\n",
      "  ✓ Añadido: examenes_procesados\\CITIM12\\Practica_3\\RODRIGUEZ_ARROYO_HECTOR_P3_CITIM12.pdf\n",
      "  ✓ Añadido: examenes_procesados\\CITIM12\\Practica_3\\SALVADOR_GARCIA_MARCOS_P3_CITIM12.pdf\n",
      "  ✓ Añadido: examenes_procesados\\CITIM12\\Practica_3\\SANZ_PASTOR_SANTIAGO_P3_CITIM12.pdf\n",
      "  ✓ Añadido: examenes_procesados\\CITIM12\\Practica_3\\SEGOVIA_GUTIERREZ_ANGEL_P3_CITIM12.pdf\n",
      "  ✓ Añadido: examenes_procesados\\CITIM12\\Practica_3\\SERNA_QUINTERO_JUAN_JOSE_P3_CITIM12.pdf\n",
      "  ✓ Añadido: examenes_procesados\\CITIM12\\Practica_3\\SEÑORANS_DAVILA_JAVIER_P3_CITIM12.pdf\n",
      "  ✓ Añadido: examenes_procesados\\CITIM12\\Practica_3\\TORRES_SAN_FELIPE_GUILLERMO_P3_CITIM12.pdf\n",
      "  ✓ Añadido: examenes_procesados\\CITIM12\\Practica_5\\CHIFOR_NICOLAS_MARIUS_P5_CITIM12.pdf\n",
      "  ✓ Añadido: examenes_procesados\\CITIM12\\Practica_5\\GARCIA_CARRETERO_SAMUEL_P5_CITIM12.pdf\n",
      "  ✓ Añadido: examenes_procesados\\CITIM12\\Practica_5\\GOMEZ_ROBLEDANO_PABLO_P5_CITIM12.pdf\n",
      "  ✓ Añadido: examenes_procesados\\CITIM12\\Practica_5\\GONZALEZ_RODRIGUEZ_RUBEN_P5_CITIM12.pdf\n",
      "  ✓ Añadido: examenes_procesados\\CITIM12\\Practica_5\\JIAYI_LIU_P5_CITIM12.pdf\n",
      "  ✓ Añadido: examenes_procesados\\CITIM12\\Practica_5\\JIMENEZ_SANZ_SERGIO_P5_CITIM12.pdf\n",
      "  ✓ Añadido: examenes_procesados\\CITIM12\\Practica_5\\LIU_JIAYI_P5_CITIM12.pdf\n",
      "  ✓ Añadido: examenes_procesados\\CITIM12\\Practica_5\\NUÑEZ_GONZALEZ_ARANCHA_P5_CITIM12.pdf\n",
      "  ✓ Añadido: examenes_procesados\\CITIM12\\Practica_5\\PALOMERA_MARTIN_CARLOS_P5_CITIM12.pdf\n",
      "  ✓ Añadido: examenes_procesados\\CITIM12\\Practica_5\\PANIS_MARAMBA_TRISHALYN_P5_CITIM12.pdf\n",
      "  ✓ Añadido: examenes_procesados\\CITIM12\\Practica_5\\PAREJAS_LAMBAN_DAVID_P5_CITIM12.pdf\n",
      "  ✓ Añadido: examenes_procesados\\CITIM12\\Practica_5\\PLAZA_PASCUAL_LUCAS_P5_CITIM12.pdf\n",
      "  ✓ Añadido: examenes_procesados\\CITIM12\\Practica_5\\POSE_COSTA_JUAN_FRANCISCO_P5_CITIM12.pdf\n",
      "  ✓ Añadido: examenes_procesados\\CITIM12\\Practica_5\\PUEBLA_MARTINEZ_FELIX_P5_CITIM12.pdf\n",
      "  ✓ Añadido: examenes_procesados\\CITIM12\\Practica_5\\RODRIGUES_ARROYO_HECTOR_P5_CITIM12.pdf\n",
      "  ✓ Añadido: examenes_procesados\\CITIM12\\Practica_5\\ROMO_TAMAME_EVA_P5_CITIM12.pdf\n",
      "  ✓ Añadido: examenes_procesados\\CITIM12\\Practica_5\\SALVADOR_GARCIA_MARCOS_P5_CITIM12.pdf\n",
      "  ✓ Añadido: examenes_procesados\\CITIM12\\Practica_5\\SANCHEZ_SANTANA_JHON_LEUDY_P5_CITIM12.pdf\n",
      "  ✓ Añadido: examenes_procesados\\CITIM12\\Practica_5\\SANZ_COLON_ADRIANA_P5_CITIM12.pdf\n",
      "  ✓ Añadido: examenes_procesados\\CITIM12\\Practica_5\\SANZ_PASTOR_SANTIAGO_P5_CITIM12.pdf\n",
      "  ✓ Añadido: examenes_procesados\\CITIM12\\Practica_5\\SEGOVIA_GUTIERREZ_ANGEL_P5_CITIM12.pdf\n",
      "  ✓ Añadido: examenes_procesados\\CITIM12\\Practica_5\\SENORANS_DAVILA_JAVIER_P5_CITIM12.pdf\n",
      "  ✓ Añadido: examenes_procesados\\CITIM12\\Practica_5\\SERNA_QUINTERO_JUAN_JOSE_P5_CITIM12.pdf\n",
      "  ✓ Añadido: examenes_procesados\\CITIM12\\Practica_5\\SEÑORANS_DAVILA_JAVIER_P5_CITIM12.pdf\n",
      "  ✓ Añadido: examenes_procesados\\CITIM12\\Practica_5\\TORRES_SAN_FELIPE_GUILLERMO_P5_CITIM12.pdf\n",
      "  ✓ Añadido: examenes_procesados\\CITIM12\\Practica_5\\TRUBITSIN_GAVRILOV_ALEX_P5_CITIM12.pdf\n",
      "  ✓ Añadido: examenes_procesados\\CITIM12\\Practica_5\\XIA_OSCAR_P5_CITIM12.pdf\n",
      "  ✓ Añadido: examenes_procesados\\CITIM12\\Practica_5\\ZHANG_JIONGHAO_P5_CITIM12.pdf\n",
      "  ✓ Añadido: examenes_procesados\\CITIM12\\Practica_5\\ZOU_XURUI_P5_CITIM12.pdf\n",
      "  ✓ Añadido: examenes_procesados\\CITIT11\\Practica_3\\FILALI_BELHADJ_CHAQROUNE_YASSIR_P3_CITIT11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM11\\Practica_3\\BARRERA_VELASQUEZ_ESAU_EZEQUIEL_P3_IWSIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM11\\Practica_3\\BEAUTELL_NAVARRO_HUGO_P3_IWSIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM11\\Practica_3\\CARRASCO_PARDO_SERGIO_P3_IWSIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM11\\Practica_3\\GARCIA_LEON_HUGO_P3_IWSIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM11\\Practica_3\\HEINRICKS_GONZALEZ_BRANDON_P3_IWSIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM11\\Practica_3\\HERNANDEZ_GARNACHO_JOSE_ANGEL_ARBOLES_P3_IWSIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM11\\Practica_3\\LUCERO_PRADA_IRENE_P3_IWSIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM11\\Practica_3\\MARTINEZ_SEBASTIA_NACHO_P3_IWSIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM11\\Practica_3\\MARTIN_BALLESTER_DANIEL_P3_IWSIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM11\\Practica_3\\MARTIN_VERDUGO_CRISTINA_P3_IWSIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM11\\Practica_3\\MONEDERO_ANGULO_JAVIER_P3_IWSIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM11\\Practica_3\\RODRIGUEZ_SANCHEZ_VICTOR_P3_IWSIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM11\\Practica_3\\ROMEO_PEREZ_ALEJANDRO_P3_IWSIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM11\\Practica_4\\HERNANDEZ_GARNACHO_JOSE_ANGEL_P4_IWSIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM11\\Practica_5\\BARRERA_VELASQUEZ_ESAU_EZEQUIEL_P5_IWSIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM11\\Practica_5\\BEAUTELL_NAVARRO_HUGO_P5_IWSIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM11\\Practica_5\\BEAUTEL_NAVARRO_HUGO_P5_IWSIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM11\\Practica_5\\BLANCO_MARCHAL_SIMON_P5_IWSIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM11\\Practica_5\\BRAVO_CUEVA_ALVARO_P5_IWSIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM11\\Practica_5\\CAMARA_VILKOVA_VERONICA_LUISA_P5_IWSIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM11\\Practica_5\\CARRASCO_PARDO_SERGIO_P5_IWSIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM11\\Practica_5\\DEL_POZUELO_ESCALONA_PABLO_P5_IWSIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM11\\Practica_5\\GARCIA_LEON_HUGO_P5_IWSIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM11\\Practica_5\\HERNANDEZ_MONTERO_LUCIA_P5_IWSIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM11\\Practica_5\\HERRERA_GALERA_PEDRO_ALEJANDRO_P5_IWSIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM11\\Practica_5\\HIDALGO_PARIENTE_MARCO_MARCO_P5_IWSIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM11\\Practica_5\\HIDALGO_PARIENTE_MARCO_P5_IWSIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM11\\Practica_5\\IONESCU_SOARE_ALEJANDRO_RAFAEL_P5_IWSIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM11\\Practica_5\\IVASIV_KOSYK_MAXYM_P5_IWSIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM11\\Practica_5\\JIMENEZ_RAMOS_DANIEL_P5_IWSIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM11\\Practica_5\\JUAREZ_GELARDO_TOMAS_P5_IWSIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM11\\Practica_5\\JUSUE_ZAVALA_JOSE_RAMON_P5_IWSIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM11\\Practica_5\\KE_TAILI_P5_IWSIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM11\\Practica_5\\LAFUENTE_SANZ_ALICIA_P5_IWSIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM11\\Practica_5\\LEFTERACHE_RAILEANU_NICOLAS_ANDRES_P5_IWSIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM11\\Practica_5\\LENCERO_CARRILLO_OSCAR_P5_IWSIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM11\\Practica_5\\LI_JILING_P5_IWSIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM11\\Practica_5\\LLORENTE_VAQUERO_CARLOS_P5_IWSIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM11\\Practica_5\\LOPEZ_COLMENERO_ROSALIA_P5_IWSIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM11\\Practica_5\\LOPEZ_DE_LA_MANZANARA_GARCIA_PABLO_P5_IWSIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM11\\Practica_5\\LOPEZ_DE_LA_MANZANARA_GARCI_PABLO_P5_IWSIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM11\\Practica_5\\LOZANO_MARCOS_MARTA_P5_IWSIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM11\\Practica_5\\MAHER_FAIQ_AL_RAWE_MAHMOOD_P5_IWSIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM11\\Practica_5\\MARINA_NAVARRO_PAULA_P5_IWSIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM11\\Practica_5\\MARINA_NAVARRO_PAULA_P5_IWSIM11_3.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM11\\Practica_5\\MARQUEZ_SANTAMARIA_ALVARO_P5_IWSIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM11\\Practica_5\\MARTINEZ_LOPEZ_TERCERO_JESUS_P5_IWSIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM11\\Practica_5\\MARTINEZ_SEBASTIA_NACHO_P5_IWSIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM11\\Practica_5\\MARTIN_BALLESTER_DANIEL_P5_IWSIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM11\\Practica_5\\MARTIN_ESPAÑA_ANTONIO_P5_IWSIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM11\\Practica_5\\MARTIN_MARTIN_JORGE_P5_IWSIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM11\\Practica_5\\MARTIN_OLIVERO_IRENE_P5_IWSIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM11\\Practica_5\\MARTIN_VERDUGO_CRISTINA_P5_IWSIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM11\\Practica_5\\MATHEUS_GONCALVEZ_DANIEL_ALEJANDRO_P5_IWSIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM11\\Practica_5\\MA_ANNI_P5_IWSIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM11\\Practica_5\\MENOYO_PEREZ_ALVARO_P5_IWSIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM11\\Practica_5\\MERINO_FERNANDEZ_SOFIA_P5_IWSIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM11\\Practica_5\\MONEDERO_ANGULO_JAVIER_P5_IWSIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM11\\Practica_5\\MONTARELO_PADILLA_ALBERTO_P5_IWSIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM11\\Practica_5\\MORALEDA_SALGUEDO_DAVID_P5_IWSIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM11\\Practica_5\\MORALEDA_SALGUERO_DAVID_P5_IWSIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM11\\Practica_5\\MORALES_DE_LUIS_HECTOR_P5_IWSIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM11\\Practica_5\\MORENO-PALANCAS_CEBALLOS_LUCAS_P5_IWSIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM11\\Practica_5\\MORENO_VIRUETE_IGNACIO_P5_IWSIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM11\\Practica_5\\MOYA_BLANCO_JESUS_FRANCISCO_P5_IWSIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM11\\Practica_5\\MOYA_RIVERA_PABLO_P5_IWSIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM11\\Practica_5\\MUÑOZ_FERNANDEZ_MIGUEL_ANGEL_P5_IWSIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM11\\Practica_5\\NARANJO_MUÑOZ_ISMAEL_P5_IWSIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM11\\Practica_5\\NAVARRETE_HURTADO_IMANOL_P5_IWSIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM11\\Practica_5\\NGOMO_NCHAMA_ANTONIO_ELA_P5_IWSIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM11\\Practica_5\\PEREZ_DIMAS_IZAN_P5_IWSIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM11\\Practica_5\\RODRIGUEZ_SANCHEZ_VICTOR_P5_IWSIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM11\\Practica_5\\ROMEO_PEREZ_ALEJANDRO_P5_IWSIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM11\\Practica_5\\SICILIA_BALAS_DANIELA_P5_IWSIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM11\\Practica_5\\ZHENG_YIFEI_P5_IWSIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM12\\Practica_3\\ALVAREZ_AREVALO_MIGUEL_P3_IWSIM12.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM12\\Practica_3\\FERNANDEZ_HERRERO_DIEGO_P3_IWSIM12.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM12\\Practica_3\\FUENTE_MARTINEZ_HERNAN_GABRIEL_DE_LA_P3_IWSIM12.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM12\\Practica_3\\GONZALEZ_BENITO_ANDRES_P3_IWSIM12.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM12\\Practica_3\\HEINRICKS_GONZALEZ_BRANDON_P3_IWSIM12.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM12\\Practica_3\\OTERO_MORENO_EKAITZ_P3_IWSIM12.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM12\\Practica_3\\ROJAS_ILLESCAS_GABRIEL_P3_IWSIM12.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM12\\Practica_3\\RUSSO_PEREZ_ALEJANDRO_ISAAC_P3_IWSIM12.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM12\\Practica_3\\SANCHEZ_PINA_JORGE_P3_IWSIM12.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM12\\Practica_3\\SANCHEZ_PIÑA_JORGE_P3_IWSIM12.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM12\\Practica_3\\SANZ_AVILA_DANIEL_P3_IWSIM12.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM12\\Practica_3\\SAN_JUAN_FERNANDEZ_MARIO_P3_IWSIM12.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM12\\Practica_3\\YE_JUNQIN_P3_IWSIM12.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM12\\Practica_3\\ZHU_XIANG_LE_P3_IWSIM12.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM12\\Practica_5\\AGUIRRE_HERVÁS_JAVIER_P5_IWSIM12.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM12\\Practica_5\\ANTONIO_ELA_NGOMO_NCHAMA_P5_IWSIM12.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM12\\Practica_5\\APUNTE_SIERRA_AARON_ALEJANDRO_P5_IWSIM12.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM12\\Practica_5\\AUSIN_MORENO_MARCOS_P5_IWSIM12.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM12\\Practica_5\\AYALA_MAYA_JULIO_P5_IWSIM12.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM12\\Practica_5\\DE_LOS_MOZOS_DE_LA_CRUZ_DIEGO_P5_IWSIM12.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM12\\Practica_5\\DOMINGUEZ_ALVAREZ_JAVIER_P5_IWSIM12.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM12\\Practica_5\\FORONDA_IRAIZOS_PABLO_RAMIRO_P5_IWSIM12.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM12\\Practica_5\\ILIYANOVA_ATANASOVA_ALICIA_P5_IWSIM12.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM12\\Practica_5\\JIMENEZ_GARCIA_ANGELA_P5_IWSIM12.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM12\\Practica_5\\JIMENEZ_JIMENEZ_ANDREA_P5_IWSIM12.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM12\\Practica_5\\LENCERO_CARRILLO_OSCAR_P5_IWSIM12.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM12\\Practica_5\\LOZANO_MARCOS_MARTA_P5_IWSIM12.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM12\\Practica_5\\MARINA_NAVARRO_PAULA_P5_IWSIM12.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM12\\Practica_5\\MARINA_NAVARRO_PAULA_P5_IWSIM12_3.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM12\\Practica_5\\MONTARELO_PADILLA_ALBERTO_P5_IWSIM12.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM12\\Practica_5\\MORENO_VIRUETE_IGNACIO_P5_IWSIM12.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM12\\Practica_5\\NIETO_HERNANDEZ_JAVIER_P5_IWSIM12.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM12\\Practica_5\\ORTIZ_PASAMONTES_MARCOS_P5_IWSIM12.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM12\\Practica_5\\PANTOJA_FIGUEROA_ALEJANDRO_P5_IWSIM12.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM12\\Practica_5\\PIÑA_RODRIGUEZ_RODRIGO_P5_IWSIM12.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM12\\Practica_5\\POENARU_TIMOTEI_LUCIAN_P5_IWSIM12.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM12\\Practica_5\\PRIETO_ALVAREZ_MARIA_P5_IWSIM12.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM12\\Practica_5\\RAZZAK_AKTER_TARIQUL_ISLAM_P5_IWSIM12.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM12\\Practica_5\\ROCHA_BENATTI_ENRIQUE_P5_IWSIM12.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM12\\Practica_5\\RODRIGUEZ_BARRIO_SANTIAGO_P5_IWSIM12.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM12\\Practica_5\\RODRIGUEZ_MARTIN_DAVID_P5_IWSIM12.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM12\\Practica_5\\RODRIGUEZ_ROMAN_DIEGO_P5_IWSIM12.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM12\\Practica_5\\ROJAS_ILLESCAS_GABRIEL_P5_IWSIM12.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM12\\Practica_5\\RUIZ_PEREZ_CLAUDIA_P5_IWSIM12.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM12\\Practica_5\\RUSSO_PEREZ_ALEJANDRO_ISAAC_P5_IWSIM12.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM12\\Practica_5\\SAIZ_MOLINA_DAVID_P5_IWSIM12.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM12\\Practica_5\\SANCHEZ_DEL_CAMPO_HUGO_P5_IWSIM12.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM12\\Practica_5\\SANCHEZ_NUÑO_JORGE_P5_IWSIM12.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM12\\Practica_5\\SANCHEZ_PINA_JORGE_P5_IWSIM12.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM12\\Practica_5\\SANCHEZ_TAPIADOR_PABLO_P5_IWSIM12.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM12\\Practica_5\\SANZ_AVILA_DANIEL_P5_IWSIM12.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM12\\Practica_5\\SAN_JUAN_FERNANDEZ_MARIO_P5_IWSIM12.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM12\\Practica_5\\SEBASTIANI_DAMAS_SANTIAGO_DANIEL_P5_IWSIM12.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM12\\Practica_5\\SILVA_CASTRO_JUAN_P5_IWSIM12.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM12\\Practica_5\\SORET_EL_HARTI_SARAH_P5_IWSIM12.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM12\\Practica_5\\STRAUS_PEÑAFIEL_ALVARO_P5_IWSIM12.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM12\\Practica_5\\TAIPE_TICSE_LUIS_IÑAKI_P5_IWSIM12.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM12\\Practica_5\\TAMAKI_MORENO_ALVARO_P5_IWSIM12.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM12\\Practica_5\\TITUAÑA_SOTALIN_BRANDON_ALEXIS_P5_IWSIM12.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM12\\Practica_5\\VAQUEIRO_JIMENEZ_DAVID_P5_IWSIM12.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM12\\Practica_5\\VERDIN_DOMINGUEZ_LARA_P5_IWSIM12.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM12\\Practica_5\\VICENTE_MIGUEL_CELIA_P5_IWSIM12.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM12\\Practica_5\\VILLA_MARTIN_PABLO_P5_IWSIM12.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM12\\Practica_5\\VINDEL_DOMINGUEZ_JORGE_P5_IWSIM12.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM12\\Practica_5\\YANG_JINXIAN_P5_IWSIM12.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM12\\Practica_5\\YUHANG_ZHOU_P5_IWSIM12.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM12\\Practica_5\\ZHU_XIANG_LE_P5_IWSIM12.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIM12\\Practica_5\\ZODER_MENDEZ_ANA_P5_IWSIM12.pdf\n",
      "  ✓ Añadido: examenes_procesados\\IWSIT12\\FUERIS_FRUTOS_MANUEL_P5_IWSIT12.pdf\n",
      "  ✓ Añadido: examenes_procesados\\problemático\\CAMARA_VILKOVA_VERONICA_LUISA_P3_IWSIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\problemático\\FUENTE_MARTINEZ_HERNAN_GABRIEL_DE_LA_P5_IWSIM12.pdf\n",
      "  ✓ Añadido: examenes_procesados\\problemático\\FUERIS_FRUTOS_MANUEL_P5_IWSIT12.pdf\n",
      "  ✓ Añadido: examenes_procesados\\problemático\\HEINRICKS_GONZALEZ_BRANDON_P3_IWSIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\problemático\\HEINRICKS_GONZALEZ_BRANDON_P5_IWSIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\problemático\\IANCU_IANCU_GEORGIAN_SORIN_P3_IWSIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\problemático\\IANCU_IANCU_GEORGIAN_SORIN_P5_IWSIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\problemático\\NAUTIYAL_BHATT_NINAD_P3_IWSIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\problemático\\NAUTIYAL_BHATT_NINAD_P5_IWSIM11.pdf\n",
      "  ✓ Añadido: examenes_procesados\\problemático\\PRIETO_ALVAREZ_MARIA_P5_IWSIM12.pdf\n",
      "  ✓ Añadido: examenes_procesados\\problemático\\QUISBERT_CHOQUETICLLA_LEONEL_P3_IWSIM12.pdf\n",
      "  ✓ Añadido: examenes_procesados\\problemático\\SANCHEZ_RODRIGUEZ_ALVARO_P3_IWSIM12.pdf\n",
      "  ✓ Añadido: examenes_procesados\\problemático\\SANCHEZ_RODRIGUEZ_ALVARO_P5_IWSIM12.pdf\n",
      "  ✓ Añadido: examenes_procesados\\problemático\\ZHENG_YIFEI_P3_IWSIM12.pdf\n",
      "  ✓ Añadido: examenes_procesados\\problemático\\ZODER_MENDEZ_PABLO_JOACHIM_P5_IWSIM12.pdf\n",
      "\n",
      "✅ Backup completado exitosamente!\n",
      "📁 Tamaño del backup: 39.90 MB\n",
      "💾 Ubicación: ..\\data\\examenes_procesados_backup_20250611_144747.zip\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'..\\\\data\\\\examenes_procesados_backup_20250611_144747.zip'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crear_backup_examenes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def eliminar_carpetas_vacias(ruta_base=\"../data/examenes_procesados/\"):\n",
    "    \"\"\"\n",
    "    Elimina recursivamente todas las carpetas vacías en la ruta especificada\n",
    "    \"\"\"\n",
    "    ruta_base = Path(ruta_base)\n",
    "    \n",
    "    if not ruta_base.exists():\n",
    "        print(f\"❌ La ruta {ruta_base} no existe\")\n",
    "        return\n",
    "    \n",
    "    carpetas_eliminadas = []\n",
    "    \n",
    "    # Función recursiva para eliminar carpetas vacías\n",
    "    def eliminar_vacias_recursivo(directorio):\n",
    "        \"\"\"Elimina carpetas vacías de forma recursiva, empezando por las más profundas\"\"\"\n",
    "        try:\n",
    "            # Primero procesar subdirectorios\n",
    "            for item in directorio.iterdir():\n",
    "                if item.is_dir():\n",
    "                    eliminar_vacias_recursivo(item)\n",
    "            \n",
    "            # Luego verificar si el directorio actual está vacío\n",
    "            if directorio.is_dir() and not any(directorio.iterdir()):\n",
    "                directorio.rmdir()\n",
    "                carpetas_eliminadas.append(str(directorio))\n",
    "                print(f\"🗑️ Eliminada carpeta vacía: {directorio}\")\n",
    "                \n",
    "        except PermissionError:\n",
    "            print(f\"⚠️ Sin permisos para eliminar: {directorio}\")\n",
    "        except OSError as e:\n",
    "            print(f\"⚠️ Error eliminando {directorio}: {e}\")\n",
    "    \n",
    "    print(f\"🔍 Buscando carpetas vacías en: {ruta_base}\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Ejecutar la eliminación recursiva\n",
    "    eliminar_vacias_recursivo(ruta_base)\n",
    "    \n",
    "    print(\"=\" * 50)\n",
    "    print(f\"✅ Proceso completado\")\n",
    "    print(f\"📊 Total de carpetas vacías eliminadas: {len(carpetas_eliminadas)}\")\n",
    "    \n",
    "    if carpetas_eliminadas:\n",
    "        print(\"\\n📋 Carpetas eliminadas:\")\n",
    "        for carpeta in carpetas_eliminadas:\n",
    "            print(f\"  - {carpeta}\")\n",
    "    else:\n",
    "        print(\"ℹ️ No se encontraron carpetas vacías para eliminar\")\n",
    "    \n",
    "    return carpetas_eliminadas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Ejecutar la limpieza\n",
    "#eliminar_carpetas_vacias()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "import unicodedata\n",
    "from rapidfuzz import fuzz\n",
    "\n",
    "def limpiar_texto_busqueda(texto):\n",
    "    \"\"\"Normaliza texto para búsquedas flexibles\"\"\"\n",
    "    if not texto:\n",
    "        return \"\"\n",
    "    texto = unicodedata.normalize('NFD', texto)\n",
    "    texto = ''.join(c for c in texto if unicodedata.category(c) != 'Mn')\n",
    "    texto = texto.upper().strip()\n",
    "    texto = re.sub(r'[^A-Z0-9\\s]', '', texto)\n",
    "    return texto\n",
    "\n",
    "def buscar_examenes_en_carpetas(df_con_practicas, ruta_examenes=\"../data/examenes_procesados/\"):\n",
    "    \"\"\"\n",
    "    Busca exámenes en todas las carpetas (incluyendo problemático) y actualiza el DataFrame\n",
    "    \"\"\"\n",
    "    ruta_examenes = Path(ruta_examenes)\n",
    "    \n",
    "    if not ruta_examenes.exists():\n",
    "        print(f\"❌ La ruta {ruta_examenes} no existe\")\n",
    "        return df_con_practicas\n",
    "    \n",
    "    # Crear copia del DataFrame para no modificar el original\n",
    "    df_resultado = df_con_practicas.copy()\n",
    "    \n",
    "    # Añadir columnas de exámenes si no existen\n",
    "    if 'Examen_3' not in df_resultado.columns:\n",
    "        df_resultado['Examen_3'] = 0\n",
    "        df_resultado['Comentario_Examen_3'] = 'PNP'\n",
    "    if 'Examen_5' not in df_resultado.columns:\n",
    "        df_resultado['Examen_5'] = 0\n",
    "        df_resultado['Comentario_Examen_5'] = 'PNP'\n",
    "    \n",
    "    # Resetear columnas de exámenes\n",
    "    df_resultado['Examen_3'] = 0\n",
    "    df_resultado['Comentario_Examen_3'] = 'PNP'\n",
    "    df_resultado['Examen_5'] = 0\n",
    "    df_resultado['Comentario_Examen_5'] = 'PNP'\n",
    "    \n",
    "    examenes_encontrados = []\n",
    "    \n",
    "    print(\"🔍 Escaneando carpetas de exámenes...\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Recorrer todas las carpetas\n",
    "    for carpeta_grupo in ruta_examenes.iterdir():\n",
    "        if not carpeta_grupo.is_dir():\n",
    "            continue\n",
    "            \n",
    "        print(f\"\\n📁 Revisando carpeta: {carpeta_grupo.name}\")\n",
    "        \n",
    "        # Si es una carpeta de grupo normal (con subcarpetas de prácticas)\n",
    "        if carpeta_grupo.name not in [\"extraviados\", \"problemático\", \"eliminados\"]:\n",
    "            for subcarpeta in carpeta_grupo.iterdir():\n",
    "                if subcarpeta.is_dir() and subcarpeta.name.startswith(\"Practica_\"):\n",
    "                    # Extraer número de práctica\n",
    "                    practica_num = subcarpeta.name.replace(\"Practica_\", \"\")\n",
    "                    if practica_num in ['3', '5']:\n",
    "                        print(f\"  📂 {subcarpeta.name}\")\n",
    "                        procesar_archivos_practica(subcarpeta, practica_num, examenes_encontrados, carpeta_grupo.name)\n",
    "        \n",
    "        # Si es una carpeta especial (problemático, extraviados)\n",
    "        else:\n",
    "            print(f\"  📂 Carpeta especial: {carpeta_grupo.name}\")\n",
    "            procesar_archivos_especiales(carpeta_grupo, examenes_encontrados)\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"🔄 Actualizando DataFrame con exámenes encontrados...\")\n",
    "    \n",
    "    # Actualizar DataFrame con los exámenes encontrados\n",
    "    examenes_marcados = actualizar_dataframe_examenes(df_resultado, examenes_encontrados)\n",
    "    \n",
    "    print(\"\\n📊 RESUMEN FINAL:\")\n",
    "    print(f\"Total de archivos PDF encontrados: {len(examenes_encontrados)}\")\n",
    "    print(f\"Exámenes marcados en DataFrame: {examenes_marcados}\")\n",
    "    \n",
    "    # Mostrar estadísticas por práctica\n",
    "    total_examen_3 = df_resultado['Examen_3'].sum()\n",
    "    total_examen_5 = df_resultado['Examen_5'].sum()\n",
    "    total_alumnos = len(df_resultado)\n",
    "    \n",
    "    print(f\"\\n📈 ESTADÍSTICAS:\")\n",
    "    print(f\"Examen Práctica 3: {total_examen_3}/{total_alumnos} ({total_examen_3/total_alumnos*100:.1f}%)\")\n",
    "    print(f\"Examen Práctica 5: {total_examen_5}/{total_alumnos} ({total_examen_5/total_alumnos*100:.1f}%)\")\n",
    "    \n",
    "    # Mostrar estadísticas por grupo\n",
    "    if 'Grupos' in df_resultado.columns:\n",
    "        print(f\"\\n📋 ESTADÍSTICAS POR GRUPO:\")\n",
    "        resumen_grupos = df_resultado.groupby('Grupos').agg({\n",
    "            'Examen_3': 'sum',\n",
    "            'Examen_5': 'sum'\n",
    "        })\n",
    "        print(resumen_grupos)\n",
    "    \n",
    "    return df_resultado\n",
    "\n",
    "def procesar_archivos_practica(carpeta_practica, practica_num, examenes_encontrados, grupo):\n",
    "    \"\"\"Procesa archivos en una carpeta de práctica específica\"\"\"\n",
    "    for archivo_pdf in carpeta_practica.glob(\"*.pdf\"):\n",
    "        info_examen = extraer_info_nombre_archivo(archivo_pdf, practica_num, grupo)\n",
    "        examenes_encontrados.append(info_examen)\n",
    "        print(f\"    ✓ {archivo_pdf.name} → {info_examen['apellidos']} {info_examen['nombre']}\")\n",
    "\n",
    "def procesar_archivos_especiales(carpeta_especial, examenes_encontrados):\n",
    "    \"\"\"Procesa archivos en carpetas especiales (problemático, extraviados)\"\"\"\n",
    "    for archivo_pdf in carpeta_especial.glob(\"*.pdf\"):\n",
    "        # Intentar detectar práctica del nombre del archivo o contenido\n",
    "        practica_detectada = detectar_practica_archivo(archivo_pdf)\n",
    "        if practica_detectada in ['3', '5']:\n",
    "            info_examen = extraer_info_nombre_archivo(archivo_pdf, practica_detectada, carpeta_especial.name)\n",
    "            examenes_encontrados.append(info_examen)\n",
    "            print(f\"    ⚠️ {archivo_pdf.name} → {info_examen['apellidos']} {info_examen['nombre']} (P{practica_detectada})\")\n",
    "\n",
    "def detectar_practica_archivo(archivo_pdf):\n",
    "    \"\"\"Detecta el número de práctica desde el nombre del archivo\"\"\"\n",
    "    nombre = archivo_pdf.name.upper()\n",
    "    \n",
    "    # Buscar patrones como P3, P5, _3_, _5_, etc.\n",
    "    patrones_practica = [\n",
    "        r'P(\\d)',\n",
    "        r'_(\\d)_',\n",
    "        r'PRACTICA_?(\\d)',\n",
    "        r'LISTA.*3',  # Para práctica de listas\n",
    "        r'GRAFO.*5'   # Para práctica de grafos\n",
    "    ]\n",
    "    \n",
    "    for patron in patrones_practica:\n",
    "        match = re.search(patron, nombre)\n",
    "        if match:\n",
    "            if 'LISTA' in nombre or match.group(1) == '3':\n",
    "                return '3'\n",
    "            elif 'GRAFO' in nombre or match.group(1) == '5':\n",
    "                return '5'\n",
    "    \n",
    "    return 'desconocida'\n",
    "\n",
    "def extraer_info_nombre_archivo(archivo_pdf, practica_num, grupo):\n",
    "    \"\"\"Extrae información del nombre del archivo\"\"\"\n",
    "    nombre_archivo = archivo_pdf.stem\n",
    "    \n",
    "    # Patrones comunes: APELLIDOS_NOMBRE, APELLIDOS_NOMBRE_P3_GRUPO, etc.\n",
    "    partes = nombre_archivo.replace('_', ' ').split()\n",
    "    \n",
    "    # Limpiar partes que no son nombres (números de práctica, grupos, etc.)\n",
    "    partes_limpias = []\n",
    "    for parte in partes:\n",
    "        # Saltar si es un grupo conocido, número de práctica, etc.\n",
    "        if not (parte.startswith('P') and parte[1:].isdigit()) and \\\n",
    "           not parte.isdigit() and \\\n",
    "           not parte in ['CITIM11', 'CITIM12', 'IWSIM11', 'IWSIM12', 'CITIT11', 'IWSIT11', 'IWSIT12']:\n",
    "            partes_limpias.append(parte)\n",
    "    \n",
    "    # Asumir que las primeras partes son apellidos y la última es nombre\n",
    "    if len(partes_limpias) >= 2:\n",
    "        apellidos = ' '.join(partes_limpias[:-1])\n",
    "        nombre = partes_limpias[-1]\n",
    "    elif len(partes_limpias) == 1:\n",
    "        apellidos = partes_limpias[0]\n",
    "        nombre = ''\n",
    "    else:\n",
    "        apellidos = nombre_archivo\n",
    "        nombre = ''\n",
    "    \n",
    "    return {\n",
    "        'archivo': archivo_pdf.name,\n",
    "        'ruta': str(archivo_pdf),\n",
    "        'apellidos': limpiar_texto_busqueda(apellidos),\n",
    "        'nombre': limpiar_texto_busqueda(nombre),\n",
    "        'practica': practica_num,\n",
    "        'grupo_carpeta': grupo\n",
    "    }\n",
    "\n",
    "def actualizar_dataframe_examenes(df_resultado, examenes_encontrados):\n",
    "    \"\"\"Actualiza el DataFrame marcando los exámenes encontrados\"\"\"\n",
    "    examenes_marcados = 0\n",
    "    \n",
    "    for examen in examenes_encontrados:\n",
    "        if examen['practica'] not in ['3', '5']:\n",
    "            continue\n",
    "            \n",
    "        apellidos_examen = examen['apellidos']\n",
    "        nombre_examen = examen['nombre']\n",
    "        practica = examen['practica']\n",
    "        \n",
    "        # Buscar coincidencia en el DataFrame usando fuzzy matching\n",
    "        mejor_coincidencia = None\n",
    "        mejor_score = 0\n",
    "        \n",
    "        for idx, row in df_resultado.iterrows():\n",
    "            apellidos_df = limpiar_texto_busqueda(str(row['Apellido(s)']))\n",
    "            nombre_df = limpiar_texto_busqueda(str(row['Nombre']))\n",
    "            \n",
    "            # Calcular similitud\n",
    "            score_apellidos = fuzz.ratio(apellidos_examen, apellidos_df) if apellidos_examen else 0\n",
    "            score_nombre = fuzz.ratio(nombre_examen, nombre_df) if nombre_examen else 0\n",
    "            \n",
    "            # Score combinado (dar más peso a apellidos)\n",
    "            score_total = (score_apellidos * 0.7 + score_nombre * 0.3)\n",
    "            \n",
    "            if score_total > mejor_score and score_total >= 70:  # Umbral del 70%\n",
    "                mejor_score = score_total\n",
    "                mejor_coincidencia = idx\n",
    "        \n",
    "        # Marcar en el DataFrame si encontramos coincidencia\n",
    "        if mejor_coincidencia is not None:\n",
    "            df_resultado.loc[mejor_coincidencia, f'Examen_{practica}'] = 1\n",
    "            df_resultado.loc[mejor_coincidencia, f'Comentario_Examen_{practica}'] = f'Encontrado ({mejor_score:.1f}%)'\n",
    "            examenes_marcados += 1\n",
    "            \n",
    "            # Mostrar la coincidencia\n",
    "            row_matched = df_resultado.loc[mejor_coincidencia]\n",
    "            print(f\"    ✅ Coincidencia: {apellidos_examen} {nombre_examen} → {row_matched['Apellido(s)']} {row_matched['Nombre']} ({mejor_score:.1f}%)\")\n",
    "        else:\n",
    "            print(f\"    ❌ Sin coincidencia: {apellidos_examen} {nombre_examen}\")\n",
    "    \n",
    "    return examenes_marcados\n",
    "\n",
    "# Cargar DataFrame si no existe\n",
    "if 'df_con_practicas' not in globals():\n",
    "    print(\"📄 Cargando DataFrame de alumnos...\")\n",
    "    students_info = [\"./../data/courseid_422_participants.csv\", \"./../data/courseid_23101_participants.csv\"]\n",
    "    dfs = [pd.read_csv(filename) for filename in students_info]\n",
    "    df = pd.concat(dfs, ignore_index=True)\n",
    "    df[\"Nombre\"] = df[\"Nombre\"].str.strip().str.upper()\n",
    "    df[\"Apellido(s)\"] = df[\"Apellido(s)\"].str.strip().str.upper()\n",
    "    \n",
    "    # Verificar prácticas entregadas primero\n",
    "    from pathlib import Path\n",
    "    import zipfile\n",
    "    import unicodedata\n",
    "    import re\n",
    "\n",
    "    def normalizar_texto(texto):\n",
    "        \"\"\"Normaliza texto eliminando acentos y caracteres especiales\"\"\"\n",
    "        texto = unicodedata.normalize('NFD', texto)\n",
    "        texto = ''.join(char for char in texto if unicodedata.category(char) != 'Mn')\n",
    "        texto = texto.upper().strip()\n",
    "        texto = re.sub(r'[^A-Z0-9\\s]', '', texto)\n",
    "        return texto\n",
    "\n",
    "    def buscar_practica_en_zips(apellidos, nombre, practica_num=3, ruta_data=\"./../data/\"):\n",
    "        \"\"\"Busca si existe una práctica para un alumno en los archivos ZIP\"\"\"\n",
    "        ruta_practica = Path(ruta_data) / f\"Practica{practica_num}\"\n",
    "        \n",
    "        if not ruta_practica.exists():\n",
    "            return False\n",
    "        \n",
    "        apellidos_norm = normalizar_texto(apellidos)\n",
    "        nombre_norm = normalizar_texto(nombre)\n",
    "        \n",
    "        for archivo_zip in ruta_practica.glob(\"*.zip\"):\n",
    "            try:\n",
    "                with zipfile.ZipFile(archivo_zip, 'r') as zip_ref:\n",
    "                    for archivo in zip_ref.namelist():\n",
    "                        archivo_norm = normalizar_texto(archivo)\n",
    "                        if apellidos_norm in archivo_norm and nombre_norm in archivo_norm:\n",
    "                            return True\n",
    "            except Exception as e:\n",
    "                continue\n",
    "        return False\n",
    "\n",
    "    # Crear DataFrame con prácticas\n",
    "    df_con_practicas = df.copy()\n",
    "    df_con_practicas['Presentada_3'] = 0\n",
    "    df_con_practicas['Comentario_3'] = 'NP'\n",
    "    df_con_practicas['Presentada_5'] = 0\n",
    "    df_con_practicas['Comentario_5'] = 'NP'\n",
    "    \n",
    "    for idx, row in df_con_practicas.iterrows():\n",
    "        nombre = str(row['Nombre'])\n",
    "        apellidos = str(row['Apellido(s)'])\n",
    "        \n",
    "        if buscar_practica_en_zips(apellidos, nombre, 3):\n",
    "            df_con_practicas.loc[idx, 'Presentada_3'] = 1\n",
    "            df_con_practicas.loc[idx, 'Comentario_3'] = ''\n",
    "        \n",
    "        if buscar_practica_en_zips(apellidos, nombre, 5):\n",
    "            df_con_practicas.loc[idx, 'Presentada_5'] = 1\n",
    "            df_con_practicas.loc[idx, 'Comentario_5'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Escaneando carpetas de exámenes...\n",
      "============================================================\n",
      "\n",
      "📁 Revisando carpeta: CITIM11\n",
      "  📂 Practica_3\n",
      "    ✓ ARIAS_CASADO_ALBA_P3_CITIM11.pdf → ARIAS CASADO ALBA\n",
      "    ✓ CARMONA_OCAÑA_DANIEL_P3_CITIM11.pdf → CARMONA OCANA DANIEL\n",
      "    ✓ DE_LA_IGLESIA_NUÑEZ_PEDRO_JOSE_P3_CITIM11.pdf → DE LA IGLESIA NUNEZ PEDRO JOSE\n",
      "    ✓ EXPOSITO_SONO_HARITZ_ENDIKA_P3_CITIM11.pdf → EXPOSITO SONO HARITZ ENDIKA\n",
      "    ✓ FERNANDEZ_NIETO_DAVID_P3_CITIM11.pdf → FERNANDEZ NIETO DAVID\n",
      "    ✓ GARCIA_FERNANDEZ_LORENZO_P3_CITIM11.pdf → GARCIA FERNANDEZ LORENZO\n",
      "    ✓ HUERGA_GIL_JAVIER_P3_CITIM11.pdf → HUERGA GIL JAVIER\n",
      "    ✓ LUCERO_PRADA_IRENE_P3_CITIM11.pdf → LUCERO PRADA IRENE\n",
      "    ✓ MARTIN_VERDUGO_CRISTINA_P3_CITIM11.pdf → MARTIN VERDUGO CRISTINA\n",
      "    ✓ MASSERA_SALCEDO_GUILLERMO_P3_CITIM11.pdf → MASSERA SALCEDO GUILLERMO\n",
      "    ✓ MORAN_RUIZ_JAIME_P3_CITIM11.pdf → MORAN RUIZ JAIME\n",
      "    ✓ NAZARENKO_KSENIA_P3_CITIM11.pdf → NAZARENKO KSENIA\n",
      "    ✓ NIETO_HERNANDEZ_JAVIER_P3_CITIM11.pdf → NIETO HERNANDEZ JAVIER\n",
      "    ✓ PLAZA_PASCUAL_LUCAS_P3_CITIM11.pdf → PLAZA PASCUAL LUCAS\n",
      "    ✓ RODRIGUEZ_RAMOS_CARLOS_P3_CITIM11.pdf → RODRIGUEZ RAMOS CARLOS\n",
      "    ✓ TRULL_GONZALEZ_SARA_P3_CITIM11.pdf → TRULL GONZALEZ SARA\n",
      "  📂 Practica_5\n",
      "    ✓ AGUIRRIZABAL_MARTINEZ_HUGO_P5_CITIM11.pdf → AGUIRRIZABAL MARTINEZ HUGO\n",
      "    ✓ ARIAS_CASADO_ALBA_P5_CITIM11.pdf → ARIAS CASADO ALBA\n",
      "    ✓ CARMONA_OCAÑA_DANIEL_P5_CITIM11.pdf → CARMONA OCANA DANIEL\n",
      "    ✓ CRAUS_SANTA_CATALINA_NICOLAS_P5_CITIM11.pdf → CRAUS SANTA CATALINA NICOLAS\n",
      "    ✓ CUTOLO_SPADARO_ROSANGELA_MARIA_P5_CITIM11.pdf → CUTOLO SPADARO ROSANGELA MARIA\n",
      "    ✓ DEL_CAMPO_GONZALEZ_ALVARO_P5_CITIM11.pdf → DEL CAMPO GONZALEZ ALVARO\n",
      "    ✓ DE_LA_IGLESIA_NUÑEZ_PEDRO_JOSÉ_P5_CITIM11.pdf → DE LA IGLESIA NUNEZ PEDRO JOSE\n",
      "    ✓ EXPOSITO_SONO_HARITZ_ENDIKA_P5_CITIM11.pdf → EXPOSITO SONO HARITZ ENDIKA\n",
      "    ✓ FERNANDEZ_NIETO_DAVID_P5_CITIM11.pdf → FERNANDEZ NIETO DAVID\n",
      "    ✓ FERREIRA_SOUZA_JHONATAN_P5_CITIM11.pdf → FERREIRA SOUZA JHONATAN\n",
      "    ✓ GARCIA_FERNANDEZ_LORENZO_P5_CITIM11.pdf → GARCIA FERNANDEZ LORENZO\n",
      "    ✓ GARCIA_GARCIA_MARCOS_P5_CITIM11.pdf → GARCIA GARCIA MARCOS\n",
      "    ✓ GONZALEZ_RODRIGUEZ_RUBEN_P5_CITIM11.pdf → GONZALEZ RODRIGUEZ RUBEN\n",
      "    ✓ HIDALGO_POZAS_MIGUEL_P5_CITIM11.pdf → HIDALGO POZAS MIGUEL\n",
      "    ✓ HUERGA_GIL_JAVIER_P5_CITIM11.pdf → HUERGA GIL JAVIER\n",
      "    ✓ JIA_LIU_ZHENGPENG_P5_CITIM11.pdf → JIA LIU ZHENGPENG\n",
      "    ✓ JIMENEZ_DIAZ_MARCOS_P5_CITIM11.pdf → JIMENEZ DIAZ MARCOS\n",
      "    ✓ LOPEZ_GARCIA_ANDRES_P5_CITIM11.pdf → LOPEZ GARCIA ANDRES\n",
      "    ✓ LOPEZ_RODRIGUEZ_NICOLAS_P5_CITIM11.pdf → LOPEZ RODRIGUEZ NICOLAS\n",
      "    ✓ LUCERO_PRADA_IRENE_P5_CITIM11.pdf → LUCERO PRADA IRENE\n",
      "    ✓ MAQUEDA_IRUN_HECTOR_P5_CITIM11.pdf → MAQUEDA IRUN HECTOR\n",
      "    ✓ MASSERA_SALCEDO_GUILLERMO_P5_CITIM11.pdf → MASSERA SALCEDO GUILLERMO\n",
      "    ✓ MIER_DIAZ_DE_ARCAYA_JUAN_P5_CITIM11.pdf → MIER DIAZ DE ARCAYA JUAN\n",
      "    ✓ MILLAN_ARRANZ_DAVID_P5_CITIM11.pdf → MILLAN ARRANZ DAVID\n",
      "    ✓ MORALES_DE_LUIS_JAVIER_P5_CITIM11.pdf → MORALES DE LUIS JAVIER\n",
      "    ✓ MORAN_RUIZ_JAIME_P5_CITIM11.pdf → MORAN RUIZ JAIME\n",
      "    ✓ MORENO_PULIDO_ADRIAN_P5_CITIM11.pdf → MORENO PULIDO ADRIAN\n",
      "    ✓ MORENO_SANCHO_SANDRA_P5_CITIM11.pdf → MORENO SANCHO SANDRA\n",
      "    ✓ MUNOZ_FANDINHO_ALEJANDRA_MARIA_P5_CITIM11.pdf → MUNOZ FANDINHO ALEJANDRA MARIA\n",
      "    ✓ NAZARENKO_KSENIA_P5_CITIM11.pdf → NAZARENKO KSENIA\n",
      "    ✓ OLIVA_RODRIGUEZ_EDUARDO_P5_CITIM11.pdf → OLIVA RODRIGUEZ EDUARDO\n",
      "    ✓ PARIENTE_CARRIAZO_ANTONIO_CITITIM11_P5_CITIM11.pdf → PARIENTE CARRIAZO ANTONIO CITITIM11\n",
      "    ✓ RODRIGUEZ_MARTIN_RUBEN_P5_CITIM11.pdf → RODRIGUEZ MARTIN RUBEN\n",
      "    ✓ RODRIGUEZ_RAMOS_CARLOS_P5_CITIM11.pdf → RODRIGUEZ RAMOS CARLOS\n",
      "    ✓ TARRILLO_MUNDACA_JORGE_AUGUSTO_P5_CITIM11.pdf → TARRILLO MUNDACA JORGE AUGUSTO\n",
      "    ✓ TERESO_SILVA_LUIS_P5_CITIM11.pdf → TERESO SILVA LUIS\n",
      "    ✓ TRULL_GONZALEZ_SARA_P5_CITIM11.pdf → TRULL GONZALEZ SARA\n",
      "    ✓ XU_HAOYUAN_P5_CITIM11.pdf → XU HAOYUAN\n",
      "\n",
      "📁 Revisando carpeta: CITIM12\n",
      "  📂 Practica_3\n",
      "    ✓ GONZALEZ_RODRIGUEZ_RUBEN_P3_CITIM12.pdf → GONZALEZ RODRIGUEZ RUBEN\n",
      "    ✓ JIAYI_LIU_P3_CITIM12.pdf → JIAYI LIU\n",
      "    ✓ LIU_JIAYI_P3_CITIM12.pdf → LIU JIAYI\n",
      "    ✓ PAREJAS_LAMBAN_DAVID_P3_CITIM12.pdf → PAREJAS LAMBAN DAVID\n",
      "    ✓ PLAZA_PASCUAL_LUCAS_P3_CITIM12.pdf → PLAZA PASCUAL LUCAS\n",
      "    ✓ POSE_COSTA_JUAN_FRANCISCO_P3_CITIM12.pdf → POSE COSTA JUAN FRANCISCO\n",
      "    ✓ PUEBLA_MARTINEZ_FELIX_P3_CITIM12.pdf → PUEBLA MARTINEZ FELIX\n",
      "    ✓ RODRIGUES_ARROYO_HECTOR_P3_CITIM12.pdf → RODRIGUES ARROYO HECTOR\n",
      "    ✓ RODRIGUEZ_ARROYO_HECTOR_P3_CITIM12.pdf → RODRIGUEZ ARROYO HECTOR\n",
      "    ✓ SALVADOR_GARCIA_MARCOS_P3_CITIM12.pdf → SALVADOR GARCIA MARCOS\n",
      "    ✓ SANZ_PASTOR_SANTIAGO_P3_CITIM12.pdf → SANZ PASTOR SANTIAGO\n",
      "    ✓ SEGOVIA_GUTIERREZ_ANGEL_P3_CITIM12.pdf → SEGOVIA GUTIERREZ ANGEL\n",
      "    ✓ SERNA_QUINTERO_JUAN_JOSE_P3_CITIM12.pdf → SERNA QUINTERO JUAN JOSE\n",
      "    ✓ SEÑORANS_DAVILA_JAVIER_P3_CITIM12.pdf → SENORANS DAVILA JAVIER\n",
      "    ✓ TORRES_SAN_FELIPE_GUILLERMO_P3_CITIM12.pdf → TORRES SAN FELIPE GUILLERMO\n",
      "  📂 Practica_5\n",
      "    ✓ CHIFOR_NICOLAS_MARIUS_P5_CITIM12.pdf → CHIFOR NICOLAS MARIUS\n",
      "    ✓ GARCIA_CARRETERO_SAMUEL_P5_CITIM12.pdf → GARCIA CARRETERO SAMUEL\n",
      "    ✓ GOMEZ_ROBLEDANO_PABLO_P5_CITIM12.pdf → GOMEZ ROBLEDANO PABLO\n",
      "    ✓ GONZALEZ_RODRIGUEZ_RUBEN_P5_CITIM12.pdf → GONZALEZ RODRIGUEZ RUBEN\n",
      "    ✓ JIAYI_LIU_P5_CITIM12.pdf → JIAYI LIU\n",
      "    ✓ JIMENEZ_SANZ_SERGIO_P5_CITIM12.pdf → JIMENEZ SANZ SERGIO\n",
      "    ✓ LIU_JIAYI_P5_CITIM12.pdf → LIU JIAYI\n",
      "    ✓ NUÑEZ_GONZALEZ_ARANCHA_P5_CITIM12.pdf → NUNEZ GONZALEZ ARANCHA\n",
      "    ✓ PALOMERA_MARTIN_CARLOS_P5_CITIM12.pdf → PALOMERA MARTIN CARLOS\n",
      "    ✓ PANIS_MARAMBA_TRISHALYN_P5_CITIM12.pdf → PANIS MARAMBA TRISHALYN\n",
      "    ✓ PAREJAS_LAMBAN_DAVID_P5_CITIM12.pdf → PAREJAS LAMBAN DAVID\n",
      "    ✓ PLAZA_PASCUAL_LUCAS_P5_CITIM12.pdf → PLAZA PASCUAL LUCAS\n",
      "    ✓ POSE_COSTA_JUAN_FRANCISCO_P5_CITIM12.pdf → POSE COSTA JUAN FRANCISCO\n",
      "    ✓ PUEBLA_MARTINEZ_FELIX_P5_CITIM12.pdf → PUEBLA MARTINEZ FELIX\n",
      "    ✓ RODRIGUES_ARROYO_HECTOR_P5_CITIM12.pdf → RODRIGUES ARROYO HECTOR\n",
      "    ✓ ROMO_TAMAME_EVA_P5_CITIM12.pdf → ROMO TAMAME EVA\n",
      "    ✓ SALVADOR_GARCIA_MARCOS_P5_CITIM12.pdf → SALVADOR GARCIA MARCOS\n",
      "    ✓ SANCHEZ_SANTANA_JHON_LEUDY_P5_CITIM12.pdf → SANCHEZ SANTANA JHON LEUDY\n",
      "    ✓ SANZ_COLON_ADRIANA_P5_CITIM12.pdf → SANZ COLON ADRIANA\n",
      "    ✓ SANZ_PASTOR_SANTIAGO_P5_CITIM12.pdf → SANZ PASTOR SANTIAGO\n",
      "    ✓ SEGOVIA_GUTIERREZ_ANGEL_P5_CITIM12.pdf → SEGOVIA GUTIERREZ ANGEL\n",
      "    ✓ SENORANS_DAVILA_JAVIER_P5_CITIM12.pdf → SENORANS DAVILA JAVIER\n",
      "    ✓ SERNA_QUINTERO_JUAN_JOSE_P5_CITIM12.pdf → SERNA QUINTERO JUAN JOSE\n",
      "    ✓ SEÑORANS_DAVILA_JAVIER_P5_CITIM12.pdf → SENORANS DAVILA JAVIER\n",
      "    ✓ TORRES_SAN_FELIPE_GUILLERMO_P5_CITIM12.pdf → TORRES SAN FELIPE GUILLERMO\n",
      "    ✓ TRUBITSIN_GAVRILOV_ALEX_P5_CITIM12.pdf → TRUBITSIN GAVRILOV ALEX\n",
      "    ✓ XIA_OSCAR_P5_CITIM12.pdf → XIA OSCAR\n",
      "    ✓ ZHANG_JIONGHAO_P5_CITIM12.pdf → ZHANG JIONGHAO\n",
      "    ✓ ZOU_XURUI_P5_CITIM12.pdf → ZOU XURUI\n",
      "\n",
      "📁 Revisando carpeta: CITIT11\n",
      "  📂 Practica_3\n",
      "    ✓ FILALI_BELHADJ_CHAQROUNE_YASSIR_P3_CITIT11.pdf → FILALI BELHADJ CHAQROUNE YASSIR\n",
      "\n",
      "📁 Revisando carpeta: IWSIM11\n",
      "  📂 Practica_3\n",
      "    ✓ BARRERA_VELASQUEZ_ESAU_EZEQUIEL_P3_IWSIM11.pdf → BARRERA VELASQUEZ ESAU EZEQUIEL\n",
      "    ✓ BEAUTELL_NAVARRO_HUGO_P3_IWSIM11.pdf → BEAUTELL NAVARRO HUGO\n",
      "    ✓ CARRASCO_PARDO_SERGIO_P3_IWSIM11.pdf → CARRASCO PARDO SERGIO\n",
      "    ✓ GARCIA_LEON_HUGO_P3_IWSIM11.pdf → GARCIA LEON HUGO\n",
      "    ✓ HEINRICKS_GONZALEZ_BRANDON_P3_IWSIM11.pdf → HEINRICKS GONZALEZ BRANDON\n",
      "    ✓ HERNANDEZ_GARNACHO_JOSE_ANGEL_ARBOLES_P3_IWSIM11.pdf → HERNANDEZ GARNACHO JOSE ANGEL ARBOLES\n",
      "    ✓ LUCERO_PRADA_IRENE_P3_IWSIM11.pdf → LUCERO PRADA IRENE\n",
      "    ✓ MARTINEZ_SEBASTIA_NACHO_P3_IWSIM11.pdf → MARTINEZ SEBASTIA NACHO\n",
      "    ✓ MARTIN_BALLESTER_DANIEL_P3_IWSIM11.pdf → MARTIN BALLESTER DANIEL\n",
      "    ✓ MARTIN_VERDUGO_CRISTINA_P3_IWSIM11.pdf → MARTIN VERDUGO CRISTINA\n",
      "    ✓ MONEDERO_ANGULO_JAVIER_P3_IWSIM11.pdf → MONEDERO ANGULO JAVIER\n",
      "    ✓ RODRIGUEZ_SANCHEZ_VICTOR_P3_IWSIM11.pdf → RODRIGUEZ SANCHEZ VICTOR\n",
      "    ✓ ROMEO_PEREZ_ALEJANDRO_P3_IWSIM11.pdf → ROMEO PEREZ ALEJANDRO\n",
      "  📂 Practica_5\n",
      "    ✓ BARRERA_VELASQUEZ_ESAU_EZEQUIEL_P5_IWSIM11.pdf → BARRERA VELASQUEZ ESAU EZEQUIEL\n",
      "    ✓ BEAUTELL_NAVARRO_HUGO_P5_IWSIM11.pdf → BEAUTELL NAVARRO HUGO\n",
      "    ✓ BEAUTEL_NAVARRO_HUGO_P5_IWSIM11.pdf → BEAUTEL NAVARRO HUGO\n",
      "    ✓ BLANCO_MARCHAL_SIMON_P5_IWSIM11.pdf → BLANCO MARCHAL SIMON\n",
      "    ✓ BRAVO_CUEVA_ALVARO_P5_IWSIM11.pdf → BRAVO CUEVA ALVARO\n",
      "    ✓ CAMARA_VILKOVA_VERONICA_LUISA_P5_IWSIM11.pdf → CAMARA VILKOVA VERONICA LUISA\n",
      "    ✓ CARRASCO_PARDO_SERGIO_P5_IWSIM11.pdf → CARRASCO PARDO SERGIO\n",
      "    ✓ DEL_POZUELO_ESCALONA_PABLO_P5_IWSIM11.pdf → DEL POZUELO ESCALONA PABLO\n",
      "    ✓ GARCIA_LEON_HUGO_P5_IWSIM11.pdf → GARCIA LEON HUGO\n",
      "    ✓ HERNANDEZ_MONTERO_LUCIA_P5_IWSIM11.pdf → HERNANDEZ MONTERO LUCIA\n",
      "    ✓ HERRERA_GALERA_PEDRO_ALEJANDRO_P5_IWSIM11.pdf → HERRERA GALERA PEDRO ALEJANDRO\n",
      "    ✓ HIDALGO_PARIENTE_MARCO_MARCO_P5_IWSIM11.pdf → HIDALGO PARIENTE MARCO MARCO\n",
      "    ✓ HIDALGO_PARIENTE_MARCO_P5_IWSIM11.pdf → HIDALGO PARIENTE MARCO\n",
      "    ✓ IONESCU_SOARE_ALEJANDRO_RAFAEL_P5_IWSIM11.pdf → IONESCU SOARE ALEJANDRO RAFAEL\n",
      "    ✓ IVASIV_KOSYK_MAXYM_P5_IWSIM11.pdf → IVASIV KOSYK MAXYM\n",
      "    ✓ JIMENEZ_RAMOS_DANIEL_P5_IWSIM11.pdf → JIMENEZ RAMOS DANIEL\n",
      "    ✓ JUAREZ_GELARDO_TOMAS_P5_IWSIM11.pdf → JUAREZ GELARDO TOMAS\n",
      "    ✓ JUSUE_ZAVALA_JOSE_RAMON_P5_IWSIM11.pdf → JUSUE ZAVALA JOSE RAMON\n",
      "    ✓ KE_TAILI_P5_IWSIM11.pdf → KE TAILI\n",
      "    ✓ LAFUENTE_SANZ_ALICIA_P5_IWSIM11.pdf → LAFUENTE SANZ ALICIA\n",
      "    ✓ LEFTERACHE_RAILEANU_NICOLAS_ANDRES_P5_IWSIM11.pdf → LEFTERACHE RAILEANU NICOLAS ANDRES\n",
      "    ✓ LENCERO_CARRILLO_OSCAR_P5_IWSIM11.pdf → LENCERO CARRILLO OSCAR\n",
      "    ✓ LI_JILING_P5_IWSIM11.pdf → LI JILING\n",
      "    ✓ LLORENTE_VAQUERO_CARLOS_P5_IWSIM11.pdf → LLORENTE VAQUERO CARLOS\n",
      "    ✓ LOPEZ_COLMENERO_ROSALIA_P5_IWSIM11.pdf → LOPEZ COLMENERO ROSALIA\n",
      "    ✓ LOPEZ_DE_LA_MANZANARA_GARCIA_PABLO_P5_IWSIM11.pdf → LOPEZ DE LA MANZANARA GARCIA PABLO\n",
      "    ✓ LOPEZ_DE_LA_MANZANARA_GARCI_PABLO_P5_IWSIM11.pdf → LOPEZ DE LA MANZANARA GARCI PABLO\n",
      "    ✓ LOZANO_MARCOS_MARTA_P5_IWSIM11.pdf → LOZANO MARCOS MARTA\n",
      "    ✓ MAHER_FAIQ_AL_RAWE_MAHMOOD_P5_IWSIM11.pdf → MAHER FAIQ AL RAWE MAHMOOD\n",
      "    ✓ MARINA_NAVARRO_PAULA_P5_IWSIM11.pdf → MARINA NAVARRO PAULA\n",
      "    ✓ MARINA_NAVARRO_PAULA_P5_IWSIM11_2.pdf → MARINA NAVARRO PAULA\n",
      "    ✓ MARQUEZ_SANTAMARIA_ALVARO_P5_IWSIM11.pdf → MARQUEZ SANTAMARIA ALVARO\n",
      "    ✓ MARTINEZ_LOPEZ_TERCERO_JESUS_P5_IWSIM11.pdf → MARTINEZ LOPEZ TERCERO JESUS\n",
      "    ✓ MARTINEZ_SEBASTIA_NACHO_P5_IWSIM11.pdf → MARTINEZ SEBASTIA NACHO\n",
      "    ✓ MARTIN_BALLESTER_DANIEL_P5_IWSIM11.pdf → MARTIN BALLESTER DANIEL\n",
      "    ✓ MARTIN_ESPAÑA_ANTONIO_P5_IWSIM11.pdf → MARTIN ESPANA ANTONIO\n",
      "    ✓ MARTIN_MARTIN_JORGE_P5_IWSIM11.pdf → MARTIN MARTIN JORGE\n",
      "    ✓ MARTIN_OLIVERO_IRENE_P5_IWSIM11.pdf → MARTIN OLIVERO IRENE\n",
      "    ✓ MARTIN_VERDUGO_CRISTINA_P5_IWSIM11.pdf → MARTIN VERDUGO CRISTINA\n",
      "    ✓ MATHEUS_GONCALVEZ_DANIEL_ALEJANDRO_P5_IWSIM11.pdf → MATHEUS GONCALVEZ DANIEL ALEJANDRO\n",
      "    ✓ MA_ANNI_P5_IWSIM11.pdf → MA ANNI\n",
      "    ✓ MENOYO_PEREZ_ALVARO_P5_IWSIM11.pdf → MENOYO PEREZ ALVARO\n",
      "    ✓ MERINO_FERNANDEZ_SOFIA_P5_IWSIM11.pdf → MERINO FERNANDEZ SOFIA\n",
      "    ✓ MONEDERO_ANGULO_JAVIER_P5_IWSIM11.pdf → MONEDERO ANGULO JAVIER\n",
      "    ✓ MONTARELO_PADILLA_ALBERTO_P5_IWSIM11.pdf → MONTARELO PADILLA ALBERTO\n",
      "    ✓ MORALEDA_SALGUEDO_DAVID_P5_IWSIM11.pdf → MORALEDA SALGUEDO DAVID\n",
      "    ✓ MORALEDA_SALGUERO_DAVID_P5_IWSIM11.pdf → MORALEDA SALGUERO DAVID\n",
      "    ✓ MORALES_DE_LUIS_HECTOR_P5_IWSIM11.pdf → MORALES DE LUIS HECTOR\n",
      "    ✓ MORENO-PALANCAS_CEBALLOS_LUCAS_P5_IWSIM11.pdf → MORENOPALANCAS CEBALLOS LUCAS\n",
      "    ✓ MORENO_VIRUETE_IGNACIO_P5_IWSIM11.pdf → MORENO VIRUETE IGNACIO\n",
      "    ✓ MOYA_BLANCO_JESUS_FRANCISCO_P5_IWSIM11.pdf → MOYA BLANCO JESUS FRANCISCO\n",
      "    ✓ MOYA_RIVERA_PABLO_P5_IWSIM11.pdf → MOYA RIVERA PABLO\n",
      "    ✓ MUÑOZ_FERNANDEZ_MIGUEL_ANGEL_P5_IWSIM11.pdf → MUNOZ FERNANDEZ MIGUEL ANGEL\n",
      "    ✓ NARANJO_MUÑOZ_ISMAEL_P5_IWSIM11.pdf → NARANJO MUNOZ ISMAEL\n",
      "    ✓ NAVARRETE_HURTADO_IMANOL_P5_IWSIM11.pdf → NAVARRETE HURTADO IMANOL\n",
      "    ✓ NGOMO_NCHAMA_ANTONIO_ELA_P5_IWSIM11.pdf → NGOMO NCHAMA ANTONIO ELA\n",
      "    ✓ PEREZ_DIMAS_IZAN_P5_IWSIM11.pdf → PEREZ DIMAS IZAN\n",
      "    ✓ RODRIGUEZ_SANCHEZ_VICTOR_P5_IWSIM11.pdf → RODRIGUEZ SANCHEZ VICTOR\n",
      "    ✓ ROMEO_PEREZ_ALEJANDRO_P5_IWSIM11.pdf → ROMEO PEREZ ALEJANDRO\n",
      "    ✓ SICILIA_BALAS_DANIELA_P5_IWSIM11.pdf → SICILIA BALAS DANIELA\n",
      "    ✓ ZHENG_YIFEI_P5_IWSIM11.pdf → ZHENG YIFEI\n",
      "\n",
      "📁 Revisando carpeta: IWSIM12\n",
      "  📂 Practica_3\n",
      "    ✓ ALVAREZ_AREVALO_MIGUEL_P3_IWSIM12.pdf → ALVAREZ AREVALO MIGUEL\n",
      "    ✓ FERNANDEZ_HERRERO_DIEGO_P3_IWSIM12.pdf → FERNANDEZ HERRERO DIEGO\n",
      "    ✓ FUENTE_MARTINEZ_HERNAN_GABRIEL_DE_LA_P3_IWSIM12.pdf → FUENTE MARTINEZ HERNAN GABRIEL DE LA\n",
      "    ✓ GONZALEZ_BENITO_ANDRES_P3_IWSIM12.pdf → GONZALEZ BENITO ANDRES\n",
      "    ✓ HEINRICKS_GONZALEZ_BRANDON_P3_IWSIM12.pdf → HEINRICKS GONZALEZ BRANDON\n",
      "    ✓ OTERO_MORENO_EKAITZ_P3_IWSIM12.pdf → OTERO MORENO EKAITZ\n",
      "    ✓ ROJAS_ILLESCAS_GABRIEL_P3_IWSIM12.pdf → ROJAS ILLESCAS GABRIEL\n",
      "    ✓ RUSSO_PEREZ_ALEJANDRO_ISAAC_P3_IWSIM12.pdf → RUSSO PEREZ ALEJANDRO ISAAC\n",
      "    ✓ SANCHEZ_PINA_JORGE_P3_IWSIM12.pdf → SANCHEZ PINA JORGE\n",
      "    ✓ SANCHEZ_PIÑA_JORGE_P3_IWSIM12.pdf → SANCHEZ PINA JORGE\n",
      "    ✓ SANZ_AVILA_DANIEL_P3_IWSIM12.pdf → SANZ AVILA DANIEL\n",
      "    ✓ SAN_JUAN_FERNANDEZ_MARIO_P3_IWSIM12.pdf → SAN JUAN FERNANDEZ MARIO\n",
      "    ✓ YE_JUNQIN_P3_IWSIM12.pdf → YE JUNQIN\n",
      "    ✓ ZHU_XIANG_LE_P3_IWSIM12.pdf → ZHU XIANG LE\n",
      "  📂 Practica_5\n",
      "    ✓ AGUIRRE_HERVÁS_JAVIER_P5_IWSIM12.pdf → AGUIRRE HERVAS JAVIER\n",
      "    ✓ ANTONIO_ELA_NGOMO_NCHAMA_P5_IWSIM12.pdf → ANTONIO ELA NGOMO NCHAMA\n",
      "    ✓ APUNTE_SIERRA_AARON_ALEJANDRO_P5_IWSIM12.pdf → APUNTE SIERRA AARON ALEJANDRO\n",
      "    ✓ AUSIN_MORENO_MARCOS_P5_IWSIM12.pdf → AUSIN MORENO MARCOS\n",
      "    ✓ AYALA_MAYA_JULIO_P5_IWSIM12.pdf → AYALA MAYA JULIO\n",
      "    ✓ DE_LOS_MOZOS_DE_LA_CRUZ_DIEGO_P5_IWSIM12.pdf → DE LOS MOZOS DE LA CRUZ DIEGO\n",
      "    ✓ DOMINGUEZ_ALVAREZ_JAVIER_P5_IWSIM12.pdf → DOMINGUEZ ALVAREZ JAVIER\n",
      "    ✓ FORONDA_IRAIZOS_PABLO_RAMIRO_P5_IWSIM12.pdf → FORONDA IRAIZOS PABLO RAMIRO\n",
      "    ✓ ILIYANOVA_ATANASOVA_ALICIA_P5_IWSIM12.pdf → ILIYANOVA ATANASOVA ALICIA\n",
      "    ✓ JIMENEZ_GARCIA_ANGELA_P5_IWSIM12.pdf → JIMENEZ GARCIA ANGELA\n",
      "    ✓ JIMENEZ_JIMENEZ_ANDREA_P5_IWSIM12.pdf → JIMENEZ JIMENEZ ANDREA\n",
      "    ✓ LENCERO_CARRILLO_OSCAR_P5_IWSIM12.pdf → LENCERO CARRILLO OSCAR\n",
      "    ✓ LOZANO_MARCOS_MARTA_P5_IWSIM12.pdf → LOZANO MARCOS MARTA\n",
      "    ✓ MARINA_NAVARRO_PAULA_P5_IWSIM12.pdf → MARINA NAVARRO PAULA\n",
      "    ✓ MARINA_NAVARRO_PAULA_P5_IWSIM12_2.pdf → MARINA NAVARRO PAULA\n",
      "    ✓ MONTARELO_PADILLA_ALBERTO_P5_IWSIM12.pdf → MONTARELO PADILLA ALBERTO\n",
      "    ✓ MORENO_VIRUETE_IGNACIO_P5_IWSIM12.pdf → MORENO VIRUETE IGNACIO\n",
      "    ✓ NIETO_HERNANDEZ_JAVIER_P5_IWSIM12.pdf → NIETO HERNANDEZ JAVIER\n",
      "    ✓ ORTIZ_PASAMONTES_MARCOS_P5_IWSIM12.pdf → ORTIZ PASAMONTES MARCOS\n",
      "    ✓ PANTOJA_FIGUEROA_ALEJANDRO_P5_IWSIM12.pdf → PANTOJA FIGUEROA ALEJANDRO\n",
      "    ✓ PIÑA_RODRIGUEZ_RODRIGO_P5_IWSIM12.pdf → PINA RODRIGUEZ RODRIGO\n",
      "    ✓ POENARU_TIMOTEI_LUCIAN_P5_IWSIM12.pdf → POENARU TIMOTEI LUCIAN\n",
      "    ✓ PRIETO_ALVAREZ_MARIA_P5_IWSIM12.pdf → PRIETO ALVAREZ MARIA\n",
      "    ✓ RAZZAK_AKTER_TARIQUL_ISLAM_P5_IWSIM12.pdf → RAZZAK AKTER TARIQUL ISLAM\n",
      "    ✓ ROCHA_BENATTI_ENRIQUE_P5_IWSIM12.pdf → ROCHA BENATTI ENRIQUE\n",
      "    ✓ RODRIGUEZ_BARRIO_SANTIAGO_P5_IWSIM12.pdf → RODRIGUEZ BARRIO SANTIAGO\n",
      "    ✓ RODRIGUEZ_MARTIN_DAVID_P5_IWSIM12.pdf → RODRIGUEZ MARTIN DAVID\n",
      "    ✓ RODRIGUEZ_ROMAN_DIEGO_P5_IWSIM12.pdf → RODRIGUEZ ROMAN DIEGO\n",
      "    ✓ ROJAS_ILLESCAS_GABRIEL_P5_IWSIM12.pdf → ROJAS ILLESCAS GABRIEL\n",
      "    ✓ RUIZ_PEREZ_CLAUDIA_P5_IWSIM12.pdf → RUIZ PEREZ CLAUDIA\n",
      "    ✓ RUSSO_PEREZ_ALEJANDRO_ISAAC_P5_IWSIM12.pdf → RUSSO PEREZ ALEJANDRO ISAAC\n",
      "    ✓ SAIZ_MOLINA_DAVID_P5_IWSIM12.pdf → SAIZ MOLINA DAVID\n",
      "    ✓ SANCHEZ_DEL_CAMPO_HUGO_P5_IWSIM12.pdf → SANCHEZ DEL CAMPO HUGO\n",
      "    ✓ SANCHEZ_NUÑO_JORGE_P5_IWSIM12.pdf → SANCHEZ NUNO JORGE\n",
      "    ✓ SANCHEZ_PINA_JORGE_P5_IWSIM12.pdf → SANCHEZ PINA JORGE\n",
      "    ✓ SANCHEZ_TAPIADOR_PABLO_P5_IWSIM12.pdf → SANCHEZ TAPIADOR PABLO\n",
      "    ✓ SANZ_AVILA_DANIEL_P5_IWSIM12.pdf → SANZ AVILA DANIEL\n",
      "    ✓ SAN_JUAN_FERNANDEZ_MARIO_P5_IWSIM12.pdf → SAN JUAN FERNANDEZ MARIO\n",
      "    ✓ SEBASTIANI_DAMAS_SANTIAGO_DANIEL_P5_IWSIM12.pdf → SEBASTIANI DAMAS SANTIAGO DANIEL\n",
      "    ✓ SILVA_CASTRO_JUAN_P5_IWSIM12.pdf → SILVA CASTRO JUAN\n",
      "    ✓ SORET_EL_HARTI_SARAH_P5_IWSIM12.pdf → SORET EL HARTI SARAH\n",
      "    ✓ STRAUS_PEÑAFIEL_ALVARO_P5_IWSIM12.pdf → STRAUS PENAFIEL ALVARO\n",
      "    ✓ TAIPE_TICSE_LUIS_IÑAKI_P5_IWSIM12.pdf → TAIPE TICSE LUIS INAKI\n",
      "    ✓ TAMAKI_MORENO_ALVARO_P5_IWSIM12.pdf → TAMAKI MORENO ALVARO\n",
      "    ✓ TITUAÑA_SOTALIN_BRANDON_ALEXIS_P5_IWSIM12.pdf → TITUANA SOTALIN BRANDON ALEXIS\n",
      "    ✓ VAQUEIRO_JIMENEZ_DAVID_P5_IWSIM12.pdf → VAQUEIRO JIMENEZ DAVID\n",
      "    ✓ VERDIN_DOMINGUEZ_LARA_P5_IWSIM12.pdf → VERDIN DOMINGUEZ LARA\n",
      "    ✓ VICENTE_MIGUEL_CELIA_P5_IWSIM12.pdf → VICENTE MIGUEL CELIA\n",
      "    ✓ VILLA_MARTIN_PABLO_P5_IWSIM12.pdf → VILLA MARTIN PABLO\n",
      "    ✓ VINDEL_DOMINGUEZ_JORGE_P5_IWSIM12.pdf → VINDEL DOMINGUEZ JORGE\n",
      "    ✓ YANG_JINXIAN_P5_IWSIM12.pdf → YANG JINXIAN\n",
      "    ✓ YUHANG_ZHOU_P5_IWSIM12.pdf → YUHANG ZHOU\n",
      "    ✓ ZHU_XIANG_LE_P5_IWSIM12.pdf → ZHU XIANG LE\n",
      "    ✓ ZODER_MENDEZ_ANA_P5_IWSIM12.pdf → ZODER MENDEZ ANA\n",
      "\n",
      "📁 Revisando carpeta: IWSIT12\n",
      "\n",
      "📁 Revisando carpeta: problemático\n",
      "  📂 Carpeta especial: problemático\n",
      "    ⚠️ CAMARA_VILKOVA_VERONICA_LUISA_P3_IWSIM11.pdf → CAMARA VILKOVA VERONICA LUISA (P3)\n",
      "    ⚠️ FUENTE_MARTINEZ_HERNAN_GABRIEL_DE_LA_P5_IWSIM12.pdf → FUENTE MARTINEZ HERNAN GABRIEL DE LA (P5)\n",
      "    ⚠️ FUERIS_FRUTOS_MANUEL_P5_IWSIT12.pdf → FUERIS FRUTOS MANUEL (P5)\n",
      "    ⚠️ HEINRICKS_GONZALEZ_BRANDON_P3_IWSIM11.pdf → HEINRICKS GONZALEZ BRANDON (P3)\n",
      "    ⚠️ HEINRICKS_GONZALEZ_BRANDON_P5_IWSIM11.pdf → HEINRICKS GONZALEZ BRANDON (P5)\n",
      "    ⚠️ IANCU_IANCU_GEORGIAN_SORIN_P3_IWSIM11.pdf → IANCU IANCU GEORGIAN SORIN (P3)\n",
      "    ⚠️ IANCU_IANCU_GEORGIAN_SORIN_P5_IWSIM11.pdf → IANCU IANCU GEORGIAN SORIN (P5)\n",
      "    ⚠️ NAUTIYAL_BHATT_NINAD_P3_IWSIM11.pdf → NAUTIYAL BHATT NINAD (P3)\n",
      "    ⚠️ NAUTIYAL_BHATT_NINAD_P5_IWSIM11.pdf → NAUTIYAL BHATT NINAD (P5)\n",
      "    ⚠️ PRIETO_ALVAREZ_MARIA_P5_IWSIM12.pdf → PRIETO ALVAREZ MARIA (P5)\n",
      "    ⚠️ QUISBERT_CHOQUETICLLA_LEONEL_P3_IWSIM12.pdf → QUISBERT CHOQUETICLLA LEONEL (P3)\n",
      "    ⚠️ SANCHEZ_RODRIGUEZ_ALVARO_P3_IWSIM12.pdf → SANCHEZ RODRIGUEZ ALVARO (P3)\n",
      "    ⚠️ SANCHEZ_RODRIGUEZ_ALVARO_P5_IWSIM12.pdf → SANCHEZ RODRIGUEZ ALVARO (P5)\n",
      "    ⚠️ ZHENG_YIFEI_P3_IWSIM12.pdf → ZHENG YIFEI (P3)\n",
      "    ⚠️ ZODER_MENDEZ_PABLO_JOACHIM_P5_IWSIM12.pdf → ZODER MENDEZ PABLO JOACHIM (P5)\n",
      "\n",
      "============================================================\n",
      "🔄 Actualizando DataFrame con exámenes encontrados...\n",
      "    ✅ Coincidencia: ARIAS CASADO ALBA → ARIAS CASADO ALBA (100.0%)\n",
      "    ✅ Coincidencia: CARMONA OCANA DANIEL → CARMONA OCAÑA DANIEL (100.0%)\n",
      "    ✅ Coincidencia: DE LA IGLESIA NUNEZ PEDRO JOSE → DE LA IGLESIA NUÑEZ PEDRO JOSE (77.6%)\n",
      "    ✅ Coincidencia: EXPOSITO SONO HARITZ ENDIKA → EXPOSITO SONO HARITZ ENDIKA (74.1%)\n",
      "    ✅ Coincidencia: FERNANDEZ NIETO DAVID → FERNANDEZ NIETO DAVID (100.0%)\n",
      "    ✅ Coincidencia: GARCIA FERNANDEZ LORENZO → GARCIA FERNANDEZ LORENZO (100.0%)\n",
      "    ✅ Coincidencia: HUERGA GIL JAVIER → HUERGA GIL JAVIER (100.0%)\n",
      "    ✅ Coincidencia: LUCERO PRADA IRENE → LUCERO PRADA IRENE (100.0%)\n",
      "    ✅ Coincidencia: MARTIN VERDUGO CRISTINA → MARTIN VERDUGO CRISTINA (100.0%)\n",
      "    ✅ Coincidencia: MASSERA SALCEDO GUILLERMO → MASSERA SALCEDO GUILLERMO (100.0%)\n",
      "    ✅ Coincidencia: MORAN RUIZ JAIME → MORAN RUIZ JAIME (100.0%)\n",
      "    ✅ Coincidencia: NAZARENKO KSENIA → NAZARENKO KSENIA (100.0%)\n",
      "    ✅ Coincidencia: NIETO HERNANDEZ JAVIER → NIETO HERNANDEZ JAVIER (100.0%)\n",
      "    ✅ Coincidencia: PLAZA PASCUAL LUCAS → PLAZA PASCUAL LUCAS (100.0%)\n",
      "    ✅ Coincidencia: RODRIGUEZ RAMOS CARLOS → RODRIGUEZ RAMOS CARLOS (100.0%)\n",
      "    ✅ Coincidencia: TRULL GONZALEZ SARA → TRULL GONZALEZ SARA (100.0%)\n",
      "    ✅ Coincidencia: AGUIRRIZABAL MARTINEZ HUGO → AGUIRRIZABAL MARTINEZ HUGO (100.0%)\n",
      "    ✅ Coincidencia: ARIAS CASADO ALBA → ARIAS CASADO ALBA (100.0%)\n",
      "    ✅ Coincidencia: CARMONA OCANA DANIEL → CARMONA OCAÑA DANIEL (100.0%)\n",
      "    ✅ Coincidencia: CRAUS SANTA CATALINA NICOLAS → CRAUS SANTA CATALINA NICOLAS (100.0%)\n",
      "    ❌ Sin coincidencia: CUTOLO SPADARO ROSANGELA MARIA\n",
      "    ✅ Coincidencia: DEL CAMPO GONZALEZ ALVARO → DEL CAMPO GONZALEZ ALVARO (100.0%)\n",
      "    ✅ Coincidencia: DE LA IGLESIA NUNEZ PEDRO JOSE → DE LA IGLESIA NUÑEZ PEDRO JOSE (77.6%)\n",
      "    ✅ Coincidencia: EXPOSITO SONO HARITZ ENDIKA → EXPOSITO SONO HARITZ ENDIKA (74.1%)\n",
      "    ✅ Coincidencia: FERNANDEZ NIETO DAVID → FERNANDEZ NIETO DAVID (100.0%)\n",
      "    ✅ Coincidencia: FERREIRA SOUZA JHONATAN → FERREIRA SOUZA JHONATAN (100.0%)\n",
      "    ✅ Coincidencia: GARCIA FERNANDEZ LORENZO → GARCIA FERNANDEZ LORENZO (100.0%)\n",
      "    ✅ Coincidencia: GARCIA GARCIA MARCOS → GARCIA GARCIA MARCOS (100.0%)\n",
      "    ✅ Coincidencia: GONZALEZ RODRIGUEZ RUBEN → GONZALEZ RODRIGUEZ RUBEN (100.0%)\n",
      "    ✅ Coincidencia: HIDALGO POZAS MIGUEL → HIDALGO POZAS MIGUEL (100.0%)\n",
      "    ✅ Coincidencia: HUERGA GIL JAVIER → HUERGA GIL JAVIER (100.0%)\n",
      "    ✅ Coincidencia: JIA LIU ZHENGPENG → JIA LIU ZHENGPENG (100.0%)\n",
      "    ✅ Coincidencia: JIMENEZ DIAZ MARCOS → JIMENEZ DIAZ MARCOS (100.0%)\n",
      "    ✅ Coincidencia: LOPEZ GARCIA ANDRES → LOPEZ GARCIA ANDRES (100.0%)\n",
      "    ✅ Coincidencia: LOPEZ RODRIGUEZ NICOLAS → LOPEZ RODRIGUEZ NICOLAS (100.0%)\n",
      "    ✅ Coincidencia: LUCERO PRADA IRENE → LUCERO PRADA IRENE (100.0%)\n",
      "    ✅ Coincidencia: MAQUEDA IRUN HECTOR → MAQUEDA IRUN HECTOR (100.0%)\n",
      "    ✅ Coincidencia: MASSERA SALCEDO GUILLERMO → MASSERA SALCEDO GUILLERMO (100.0%)\n",
      "    ✅ Coincidencia: MIER DIAZ DE ARCAYA JUAN → MIER DIAZ DE ARCAYA JUAN (100.0%)\n",
      "    ✅ Coincidencia: MILLAN ARRANZ DAVID → MILLAN ARRANZ DAVID (100.0%)\n",
      "    ✅ Coincidencia: MORALES DE LUIS JAVIER → MORALES DE LUIS JAVIER (100.0%)\n",
      "    ✅ Coincidencia: MORAN RUIZ JAIME → MORAN RUIZ JAIME (100.0%)\n",
      "    ✅ Coincidencia: MORENO PULIDO ADRIAN → MORENO PULIDO ADRIAN (100.0%)\n",
      "    ✅ Coincidencia: MORENO SANCHO SANDRA → MORENO SANCHO SANDRA (100.0%)\n",
      "    ❌ Sin coincidencia: MUNOZ FANDINHO ALEJANDRA MARIA\n",
      "    ✅ Coincidencia: NAZARENKO KSENIA → NAZARENKO KSENIA (100.0%)\n",
      "    ✅ Coincidencia: OLIVA RODRIGUEZ EDUARDO → OLIVA RODRIGUEZ EDUARDO (100.0%)\n",
      "    ❌ Sin coincidencia: PARIENTE CARRIAZO ANTONIO CITITIM11\n",
      "    ✅ Coincidencia: RODRIGUEZ MARTIN RUBEN → RODRIGUEZ MARTIN RUBEN (100.0%)\n",
      "    ✅ Coincidencia: RODRIGUEZ RAMOS CARLOS → RODRIGUEZ RAMOS CARLOS (100.0%)\n",
      "    ✅ Coincidencia: TARRILLO MUNDACA JORGE AUGUSTO → TARRILLO MUNDACA JORGE AUGUSTO (79.9%)\n",
      "    ✅ Coincidencia: TERESO SILVA LUIS → TERESO SILVA LUIS (100.0%)\n",
      "    ✅ Coincidencia: TRULL GONZALEZ SARA → TRULL GONZALEZ SARA (100.0%)\n",
      "    ✅ Coincidencia: XU HAOYUAN → XU HAOYUAN (100.0%)\n",
      "    ✅ Coincidencia: GONZALEZ RODRIGUEZ RUBEN → GONZALEZ RODRIGUEZ RUBEN (100.0%)\n",
      "    ❌ Sin coincidencia: JIAYI LIU\n",
      "    ✅ Coincidencia: LIU JIAYI → LIU JIAYI (100.0%)\n",
      "    ✅ Coincidencia: PAREJAS LAMBAN DAVID → PAREJAS LAMBAN DAVID (100.0%)\n",
      "    ✅ Coincidencia: PLAZA PASCUAL LUCAS → PLAZA PASCUAL LUCAS (100.0%)\n",
      "    ✅ Coincidencia: POSE COSTA JUAN FRANCISCO → POSE COSTA JUAN FRANCISCO (79.5%)\n",
      "    ✅ Coincidencia: PUEBLA MARTINEZ FELIX → PUEBLA MARTINEZ FELIX (100.0%)\n",
      "    ✅ Coincidencia: RODRIGUES ARROYO HECTOR → RODRIGUES ARROYO HECTOR (100.0%)\n",
      "    ✅ Coincidencia: RODRIGUEZ ARROYO HECTOR → RODRIGUES ARROYO HECTOR (95.6%)\n",
      "    ✅ Coincidencia: SALVADOR GARCIA MARCOS → SALVADOR GARCIA MARCOS (100.0%)\n",
      "    ✅ Coincidencia: SANZ PASTOR SANTIAGO → SANZ PASTOR SANTIAGO (100.0%)\n",
      "    ✅ Coincidencia: SEGOVIA GUTIERREZ ANGEL → SEGOVIA GUTIERREZ ANGEL (100.0%)\n",
      "    ✅ Coincidencia: SERNA QUINTERO JUAN JOSE → SERNA QUINTERO JUAN JOSE (77.9%)\n",
      "    ✅ Coincidencia: SENORANS DAVILA JAVIER → SEÑORANS DAVILA JAVIER (100.0%)\n",
      "    ✅ Coincidencia: TORRES SAN FELIPE GUILLERMO → TORRES SAN FELIPE GUILLERMO (100.0%)\n",
      "    ❌ Sin coincidencia: CHIFOR NICOLAS MARIUS\n",
      "    ✅ Coincidencia: GARCIA CARRETERO SAMUEL → GARCIA CARRETERO SAMUEL (100.0%)\n",
      "    ✅ Coincidencia: GOMEZ ROBLEDANO PABLO → GOMEZ ROBLEDANO PABLO (100.0%)\n",
      "    ✅ Coincidencia: GONZALEZ RODRIGUEZ RUBEN → GONZALEZ RODRIGUEZ RUBEN (100.0%)\n",
      "    ❌ Sin coincidencia: JIAYI LIU\n",
      "    ✅ Coincidencia: JIMENEZ SANZ SERGIO → JIMENEZ SANZ SERGIO (100.0%)\n",
      "    ✅ Coincidencia: LIU JIAYI → LIU JIAYI (100.0%)\n",
      "    ✅ Coincidencia: NUNEZ GONZALEZ ARANCHA → NUÑEZ GONZALEZ ARANCHA (100.0%)\n",
      "    ✅ Coincidencia: PALOMERA MARTIN CARLOS → PALOMERA MARTIN CARLOS (100.0%)\n",
      "    ✅ Coincidencia: PANIS MARAMBA TRISHALYN → PANIS MARAMBA TRISHALYN (100.0%)\n",
      "    ✅ Coincidencia: PAREJAS LAMBAN DAVID → PAREJAS LAMBAN DAVID (100.0%)\n",
      "    ✅ Coincidencia: PLAZA PASCUAL LUCAS → PLAZA PASCUAL LUCAS (100.0%)\n",
      "    ✅ Coincidencia: POSE COSTA JUAN FRANCISCO → POSE COSTA JUAN FRANCISCO (79.5%)\n",
      "    ✅ Coincidencia: PUEBLA MARTINEZ FELIX → PUEBLA MARTINEZ FELIX (100.0%)\n",
      "    ✅ Coincidencia: RODRIGUES ARROYO HECTOR → RODRIGUES ARROYO HECTOR (100.0%)\n",
      "    ✅ Coincidencia: ROMO TAMAME EVA → ROMO TAMAME EVA (100.0%)\n",
      "    ✅ Coincidencia: SALVADOR GARCIA MARCOS → SALVADOR GARCIA MARCOS (100.0%)\n",
      "    ✅ Coincidencia: SANCHEZ SANTANA JHON LEUDY → SANCHEZ SANTANA JHON LEUDY (80.0%)\n",
      "    ✅ Coincidencia: SANZ COLON ADRIANA → SANZ COLON ADRIANA (100.0%)\n",
      "    ✅ Coincidencia: SANZ PASTOR SANTIAGO → SANZ PASTOR SANTIAGO (100.0%)\n",
      "    ✅ Coincidencia: SEGOVIA GUTIERREZ ANGEL → SEGOVIA GUTIERREZ ANGEL (100.0%)\n",
      "    ✅ Coincidencia: SENORANS DAVILA JAVIER → SEÑORANS DAVILA JAVIER (100.0%)\n",
      "    ✅ Coincidencia: SERNA QUINTERO JUAN JOSE → SERNA QUINTERO JUAN JOSE (77.9%)\n",
      "    ✅ Coincidencia: SENORANS DAVILA JAVIER → SEÑORANS DAVILA JAVIER (100.0%)\n",
      "    ✅ Coincidencia: TORRES SAN FELIPE GUILLERMO → TORRES SAN FELIPE GUILLERMO (100.0%)\n",
      "    ✅ Coincidencia: TRUBITSIN GAVRILOV ALEX → TRUBITSIN GAVRILOV ALEX (100.0%)\n",
      "    ✅ Coincidencia: XIA OSCAR → XIA OSCAR (100.0%)\n",
      "    ✅ Coincidencia: ZHANG JIONGHAO → ZHANG JIONGHAO (100.0%)\n",
      "    ✅ Coincidencia: ZOU XURUI → ZOU XURUI (100.0%)\n",
      "    ✅ Coincidencia: FILALI BELHADJ CHAQROUNE YASSIR → FILALI BELHADJ CHAQROUNE YASSIR (100.0%)\n",
      "    ✅ Coincidencia: BARRERA VELASQUEZ ESAU EZEQUIEL → BARRERA VELASQUEZ ESAU EZEQUIEL (83.9%)\n",
      "    ✅ Coincidencia: BEAUTELL NAVARRO HUGO → BEAUTELL NAVARRO HUGO (100.0%)\n",
      "    ✅ Coincidencia: CARRASCO PARDO SERGIO → CARRASCO PARDO SERGIO (100.0%)\n",
      "    ✅ Coincidencia: GARCIA LEON HUGO → GARCIA LEON HUGO (100.0%)\n",
      "    ✅ Coincidencia: HEINRICKS GONZALEZ BRANDON → HEINRICKS GONZALEZ BRANDON (100.0%)\n",
      "    ❌ Sin coincidencia: HERNANDEZ GARNACHO JOSE ANGEL ARBOLES\n",
      "    ✅ Coincidencia: LUCERO PRADA IRENE → LUCERO PRADA IRENE (100.0%)\n",
      "    ✅ Coincidencia: MARTINEZ SEBASTIA NACHO → MARTINEZ SEBASTIA NACHO (100.0%)\n",
      "    ✅ Coincidencia: MARTIN BALLESTER DANIEL → MARTIN BALLESTER DANIEL (100.0%)\n",
      "    ✅ Coincidencia: MARTIN VERDUGO CRISTINA → MARTIN VERDUGO CRISTINA (100.0%)\n",
      "    ✅ Coincidencia: MONEDERO ANGULO JAVIER → MONEDERO ANGULO JAVIER (100.0%)\n",
      "    ✅ Coincidencia: RODRIGUEZ SANCHEZ VICTOR → RODRIGUEZ SANCHEZ VICTOR (100.0%)\n",
      "    ✅ Coincidencia: ROMEO PEREZ ALEJANDRO → ROMEO PEREZ ALEJANDRO (100.0%)\n",
      "    ✅ Coincidencia: BARRERA VELASQUEZ ESAU EZEQUIEL → BARRERA VELASQUEZ ESAU EZEQUIEL (83.9%)\n",
      "    ✅ Coincidencia: BEAUTELL NAVARRO HUGO → BEAUTELL NAVARRO HUGO (100.0%)\n",
      "    ✅ Coincidencia: BEAUTEL NAVARRO HUGO → BEAUTELL NAVARRO HUGO (97.7%)\n",
      "    ✅ Coincidencia: BLANCO MARCHAL SIMON → BLANCO MARCHAL SIMON (100.0%)\n",
      "    ✅ Coincidencia: BRAVO CUEVA ALVARO → BRAVO CUEVA ALVARO (100.0%)\n",
      "    ❌ Sin coincidencia: CAMARA VILKOVA VERONICA LUISA\n",
      "    ✅ Coincidencia: CARRASCO PARDO SERGIO → CARRASCO PARDO SERGIO (100.0%)\n",
      "    ✅ Coincidencia: DEL POZUELO ESCALONA PABLO → DEL POZUELO ESCALONA PABLO (100.0%)\n",
      "    ✅ Coincidencia: GARCIA LEON HUGO → GARCIA LEON HUGO (100.0%)\n",
      "    ✅ Coincidencia: HERNANDEZ MONTERO LUCIA → HERNANDEZ MONTERO LUCIA (100.0%)\n",
      "    ✅ Coincidencia: HERRERA GALERA PEDRO ALEJANDRO → HERRERA GALERA PEDRO ALEJANDRO (80.1%)\n",
      "    ✅ Coincidencia: HIDALGO PARIENTE MARCO MARCO → HIDALGO PARIENTE MARCO (88.9%)\n",
      "    ✅ Coincidencia: HIDALGO PARIENTE MARCO → HIDALGO PARIENTE MARCO (100.0%)\n",
      "    ❌ Sin coincidencia: IONESCU SOARE ALEJANDRO RAFAEL\n",
      "    ✅ Coincidencia: IVASIV KOSYK MAXYM → IVASIV KOSYK MAXYM (100.0%)\n",
      "    ✅ Coincidencia: JIMENEZ RAMOS DANIEL → JIMENEZ RAMOS DANIEL (100.0%)\n",
      "    ✅ Coincidencia: JUAREZ GELARDO TOMAS → JUAREZ GELARDO TOMAS (100.0%)\n",
      "    ✅ Coincidencia: JUSUE ZAVALA JOSE RAMON → JUSUE ZAVALA JOSE RAMON (77.9%)\n",
      "    ✅ Coincidencia: KE TAILI → KE TAILI (100.0%)\n",
      "    ✅ Coincidencia: LAFUENTE SANZ ALICIA → LAFUENTE SANZ ALICIA (100.0%)\n",
      "    ✅ Coincidencia: LEFTERACHE RAILEANU NICOLAS ANDRES → LEFTERACHE RAILEANU NICOLAS ANDRES (75.8%)\n",
      "    ✅ Coincidencia: LENCERO CARRILLO OSCAR → LENCERO CARRILLO OSCAR (100.0%)\n",
      "    ✅ Coincidencia: LI JILING → LI JILING (100.0%)\n",
      "    ✅ Coincidencia: LLORENTE VAQUERO CARLOS → LLORENTE VAQUERO CARLOS (100.0%)\n",
      "    ✅ Coincidencia: LOPEZ COLMENERO ROSALIA → LOPEZ COLMENERO ROSALIA (100.0%)\n",
      "    ✅ Coincidencia: LOPEZ DE LA MANZANARA GARCIA PABLO → LOPEZ DE LA MANZANARA GARCIA PABLO (100.0%)\n",
      "    ✅ Coincidencia: LOPEZ DE LA MANZANARA GARCI PABLO → LOPEZ DE LA MANZANARA GARCIA PABLO (98.7%)\n",
      "    ✅ Coincidencia: LOZANO MARCOS MARTA → LOZANO MARCOS MARTA (100.0%)\n",
      "    ✅ Coincidencia: MAHER FAIQ AL RAWE MAHMOOD → MAHER FAIQ AL RAWE MAHMOOD (100.0%)\n",
      "    ✅ Coincidencia: MARINA NAVARRO PAULA → MARINA NAVARRO PAULA (100.0%)\n",
      "    ✅ Coincidencia: MARINA NAVARRO PAULA → MARINA NAVARRO PAULA (100.0%)\n",
      "    ✅ Coincidencia: MARQUEZ SANTAMARIA ALVARO → MARQUEZ SANTAMARIA ALVARO (100.0%)\n",
      "    ✅ Coincidencia: MARTINEZ LOPEZ TERCERO JESUS → MARTINEZ LOPEZ TERCERO JESUS (100.0%)\n",
      "    ✅ Coincidencia: MARTINEZ SEBASTIA NACHO → MARTINEZ SEBASTIA NACHO (100.0%)\n",
      "    ✅ Coincidencia: MARTIN BALLESTER DANIEL → MARTIN BALLESTER DANIEL (100.0%)\n",
      "    ✅ Coincidencia: MARTIN ESPANA ANTONIO → MARTIN ESPAÑA ANTONIO (100.0%)\n",
      "    ✅ Coincidencia: MARTIN MARTIN JORGE → MARTIN MARTIN JORGE (100.0%)\n",
      "    ✅ Coincidencia: MARTIN OLIVERO IRENE → MARTIN OLIVERO IRENE (100.0%)\n",
      "    ✅ Coincidencia: MARTIN VERDUGO CRISTINA → MARTIN VERDUGO CRISTINA (100.0%)\n",
      "    ✅ Coincidencia: MATHEUS GONCALVEZ DANIEL ALEJANDRO → MATHEUS GONCALVEZ DANIEL ALEJANDRO (79.6%)\n",
      "    ✅ Coincidencia: MA ANNI → MA ANNI (100.0%)\n",
      "    ✅ Coincidencia: MENOYO PEREZ ALVARO → MENOYO PEREZ ALVARO (100.0%)\n",
      "    ✅ Coincidencia: MERINO FERNANDEZ SOFIA → MERINO FERNANDEZ SOFIA (100.0%)\n",
      "    ✅ Coincidencia: MONEDERO ANGULO JAVIER → MONEDERO ANGULO JAVIER (100.0%)\n",
      "    ✅ Coincidencia: MONTARELO PADILLA ALBERTO → MONTARELO PADILLA ALBERTO (100.0%)\n",
      "    ✅ Coincidencia: MORALEDA SALGUEDO DAVID → MORALEDA SALGUERO DAVID (95.9%)\n",
      "    ✅ Coincidencia: MORALEDA SALGUERO DAVID → MORALEDA SALGUERO DAVID (100.0%)\n",
      "    ✅ Coincidencia: MORALES DE LUIS HECTOR → MORALES DE LUIS HECTOR (100.0%)\n",
      "    ✅ Coincidencia: MORENOPALANCAS CEBALLOS LUCAS → MORENO-PALANCAS CEBALLOS LUCAS (100.0%)\n",
      "    ✅ Coincidencia: MORENO VIRUETE IGNACIO → MORENO VIRUETE IGNACIO (100.0%)\n",
      "    ✅ Coincidencia: MOYA BLANCO JESUS FRANCISCO → MOYA BLANCO JESUS FRANCISCO (77.5%)\n",
      "    ✅ Coincidencia: MOYA RIVERA PABLO → MOYA RIVERA PABLO (100.0%)\n",
      "    ✅ Coincidencia: MUNOZ FERNANDEZ MIGUEL ANGEL → MUÑOZ FERNANDEZ MIGUEL ANGEL (74.4%)\n",
      "    ✅ Coincidencia: NARANJO MUNOZ ISMAEL → NARANJO MUÑOZ ISMAEL (100.0%)\n",
      "    ✅ Coincidencia: NAVARRETE HURTADO IMANOL → NAVARRETE HURTADO IMANOL (100.0%)\n",
      "    ❌ Sin coincidencia: NGOMO NCHAMA ANTONIO ELA\n",
      "    ✅ Coincidencia: PEREZ DIMAS IZAN → PEREZ DIMAS IZAN (100.0%)\n",
      "    ✅ Coincidencia: RODRIGUEZ SANCHEZ VICTOR → RODRIGUEZ SANCHEZ VICTOR (100.0%)\n",
      "    ✅ Coincidencia: ROMEO PEREZ ALEJANDRO → ROMEO PEREZ ALEJANDRO (100.0%)\n",
      "    ✅ Coincidencia: SICILIA BALAS DANIELA → SICILIA BALAS DANIELA (100.0%)\n",
      "    ✅ Coincidencia: ZHENG YIFEI → ZHENG YIFEI (100.0%)\n",
      "    ✅ Coincidencia: ALVAREZ AREVALO MIGUEL → ALVAREZ AREVALO MIGUEL (100.0%)\n",
      "    ✅ Coincidencia: FERNANDEZ HERRERO DIEGO → FERNANDEZ HERRERO DIEGO (100.0%)\n",
      "    ❌ Sin coincidencia: FUENTE MARTINEZ HERNAN GABRIEL DE LA\n",
      "    ✅ Coincidencia: GONZALEZ BENITO ANDRES → GONZALEZ BENITO ANDRES (100.0%)\n",
      "    ✅ Coincidencia: HEINRICKS GONZALEZ BRANDON → HEINRICKS GONZALEZ BRANDON (100.0%)\n",
      "    ✅ Coincidencia: OTERO MORENO EKAITZ → OTERO MORENO EKAITZ (100.0%)\n",
      "    ✅ Coincidencia: ROJAS ILLESCAS GABRIEL → ROJAS ILLESCAS GABRIEL (100.0%)\n",
      "    ❌ Sin coincidencia: RUSSO PEREZ ALEJANDRO ISAAC\n",
      "    ✅ Coincidencia: SANCHEZ PINA JORGE → SANCHEZ PINA JORGE (100.0%)\n",
      "    ✅ Coincidencia: SANCHEZ PINA JORGE → SANCHEZ PINA JORGE (100.0%)\n",
      "    ✅ Coincidencia: SANZ AVILA DANIEL → SANZ AVILA DANIEL (100.0%)\n",
      "    ✅ Coincidencia: SAN JUAN FERNANDEZ MARIO → SAN JUAN FERNANDEZ MARIO (100.0%)\n",
      "    ✅ Coincidencia: YE JUNQIN → YE JUNQIN (100.0%)\n",
      "    ❌ Sin coincidencia: ZHU XIANG LE\n",
      "    ✅ Coincidencia: AGUIRRE HERVAS JAVIER → AGUIRRE HERVIAS JAVIER (97.6%)\n",
      "    ❌ Sin coincidencia: ANTONIO ELA NGOMO NCHAMA\n",
      "    ✅ Coincidencia: APUNTE SIERRA AARON ALEJANDRO → APUNTE SIERRA AARON ALEJANDRO (79.4%)\n",
      "    ✅ Coincidencia: AUSIN MORENO MARCOS → AUSIN MORENO MARCOS (100.0%)\n",
      "    ✅ Coincidencia: AYALA MAYA JULIO → AYALA MAYA JULIO (100.0%)\n",
      "    ✅ Coincidencia: DE LOS MOZOS DE LA CRUZ DIEGO → DE LOS MOZOS DE LA CRUZ DIEGO (100.0%)\n",
      "    ✅ Coincidencia: DOMINGUEZ ALVAREZ JAVIER → DOMINGUEZ ALVAREZ JAVIER (100.0%)\n",
      "    ✅ Coincidencia: FORONDA IRAIZOS PABLO RAMIRO → FORONDA IRAIZOS PABLO RAMIRO (78.3%)\n",
      "    ✅ Coincidencia: ILIYANOVA ATANASOVA ALICIA → ILIYANOVA ATANASOVA ALICIA (100.0%)\n",
      "    ✅ Coincidencia: JIMENEZ GARCIA ANGELA → JIMENEZ GARCIA ANGELA (100.0%)\n",
      "    ✅ Coincidencia: JIMENEZ JIMENEZ ANDREA → JIMENEZ JIMENEZ ANDREA (100.0%)\n",
      "    ✅ Coincidencia: LENCERO CARRILLO OSCAR → LENCERO CARRILLO OSCAR (100.0%)\n",
      "    ✅ Coincidencia: LOZANO MARCOS MARTA → LOZANO MARCOS MARTA (100.0%)\n",
      "    ✅ Coincidencia: MARINA NAVARRO PAULA → MARINA NAVARRO PAULA (100.0%)\n",
      "    ✅ Coincidencia: MARINA NAVARRO PAULA → MARINA NAVARRO PAULA (100.0%)\n",
      "    ✅ Coincidencia: MONTARELO PADILLA ALBERTO → MONTARELO PADILLA ALBERTO (100.0%)\n",
      "    ✅ Coincidencia: MORENO VIRUETE IGNACIO → MORENO VIRUETE IGNACIO (100.0%)\n",
      "    ✅ Coincidencia: NIETO HERNANDEZ JAVIER → NIETO HERNANDEZ JAVIER (100.0%)\n",
      "    ✅ Coincidencia: ORTIZ PASAMONTES MARCOS → ORTIZ PASAMONTES MARCOS (100.0%)\n",
      "    ✅ Coincidencia: PANTOJA FIGUEROA ALEJANDRO → PANTOJA FIGUEROA ALEJANDRO (100.0%)\n",
      "    ✅ Coincidencia: PINA RODRIGUEZ RODRIGO → PIÑA RODRIGUEZ RODRIGO (100.0%)\n",
      "    ❌ Sin coincidencia: POENARU TIMOTEI LUCIAN\n",
      "    ✅ Coincidencia: PRIETO ALVAREZ MARIA → PRIETO ALVAREZ MARIA (100.0%)\n",
      "    ❌ Sin coincidencia: RAZZAK AKTER TARIQUL ISLAM\n",
      "    ✅ Coincidencia: ROCHA BENATTI ENRIQUE → ROCHA BENATTI ENRIQUE (100.0%)\n",
      "    ✅ Coincidencia: RODRIGUEZ BARRIO SANTIAGO → RODRIGUEZ BARRIO SANTIAGO (100.0%)\n",
      "    ✅ Coincidencia: RODRIGUEZ MARTIN DAVID → RODRIGUEZ MARTIN DAVID (100.0%)\n",
      "    ✅ Coincidencia: RODRIGUEZ ROMAN DIEGO → RODRIGUEZ ROMAN DIEGO (100.0%)\n",
      "    ✅ Coincidencia: ROJAS ILLESCAS GABRIEL → ROJAS ILLESCAS GABRIEL (100.0%)\n",
      "    ✅ Coincidencia: RUIZ PEREZ CLAUDIA → RUIZ PEREZ CLAUDIA (100.0%)\n",
      "    ❌ Sin coincidencia: RUSSO PEREZ ALEJANDRO ISAAC\n",
      "    ✅ Coincidencia: SAIZ MOLINA DAVID → SAIZ MOLINA DAVID (100.0%)\n",
      "    ✅ Coincidencia: SANCHEZ DEL CAMPO HUGO → SANCHEZ DEL CAMPO HUGO (100.0%)\n",
      "    ✅ Coincidencia: SANCHEZ NUNO JORGE → SANCHEZ NUÑO JORGE (100.0%)\n",
      "    ✅ Coincidencia: SANCHEZ PINA JORGE → SANCHEZ PINA JORGE (100.0%)\n",
      "    ✅ Coincidencia: SANCHEZ TAPIADOR PABLO → SANCHEZ TAPIADOR PABLO (100.0%)\n",
      "    ✅ Coincidencia: SANZ AVILA DANIEL → SANZ AVILA DANIEL (100.0%)\n",
      "    ✅ Coincidencia: SAN JUAN FERNANDEZ MARIO → SAN JUAN FERNANDEZ MARIO (100.0%)\n",
      "    ✅ Coincidencia: SEBASTIANI DAMAS SANTIAGO DANIEL → SEBASTIANI DAMAS SANTIAGO DANIEL (71.8%)\n",
      "    ✅ Coincidencia: SILVA CASTRO JUAN → SILVA CASTRO JUAN (100.0%)\n",
      "    ✅ Coincidencia: SORET EL HARTI SARAH → SORET EL HARTI SARAH (100.0%)\n",
      "    ✅ Coincidencia: STRAUS PENAFIEL ALVARO → STRAUS PEÑAFIEL ALVARO (100.0%)\n",
      "    ✅ Coincidencia: TAIPE TICSE LUIS INAKI → TAIPE TICSE LUIS IÑAKI (77.0%)\n",
      "    ✅ Coincidencia: TAMAKI MORENO ALVARO → TAMAKI MORENO ALVARO (100.0%)\n",
      "    ✅ Coincidencia: TITUANA SOTALIN BRANDON ALEXIS → TITUAÑA SOTALIN BRANDON ALEXIS (73.3%)\n",
      "    ✅ Coincidencia: VAQUEIRO JIMENEZ DAVID → VAQUEIRO JIMENEZ DAVID (100.0%)\n",
      "    ✅ Coincidencia: VERDIN DOMINGUEZ LARA → VERDIN DOMINGUEZ LARA (100.0%)\n",
      "    ✅ Coincidencia: VICENTE MIGUEL CELIA → VICENTE MIGUEL CELIA (100.0%)\n",
      "    ✅ Coincidencia: VILLA MARTIN PABLO → VILLA MARTIN PABLO (100.0%)\n",
      "    ✅ Coincidencia: VINDEL DOMINGUEZ JORGE → VINDEL DOMINGUEZ JORGE (100.0%)\n",
      "    ✅ Coincidencia: YANG JINXIAN → YANG JINXIAN (100.0%)\n",
      "    ❌ Sin coincidencia: YUHANG ZHOU\n",
      "    ❌ Sin coincidencia: ZHU XIANG LE\n",
      "    ✅ Coincidencia: ZODER MENDEZ ANA → ZODER MENDEZ ANA (100.0%)\n",
      "    ❌ Sin coincidencia: CAMARA VILKOVA VERONICA LUISA\n",
      "    ❌ Sin coincidencia: FUENTE MARTINEZ HERNAN GABRIEL DE LA\n",
      "    ✅ Coincidencia: FUERIS FRUTOS MANUEL → FUERIS FRUTOS MANUEL (100.0%)\n",
      "    ✅ Coincidencia: HEINRICKS GONZALEZ BRANDON → HEINRICKS GONZALEZ BRANDON (100.0%)\n",
      "    ✅ Coincidencia: HEINRICKS GONZALEZ BRANDON → HEINRICKS GONZALEZ BRANDON (100.0%)\n",
      "    ❌ Sin coincidencia: IANCU IANCU GEORGIAN SORIN\n",
      "    ❌ Sin coincidencia: IANCU IANCU GEORGIAN SORIN\n",
      "    ✅ Coincidencia: NAUTIYAL BHATT NINAD → NAUTIYAL BHATT NINAD (100.0%)\n",
      "    ✅ Coincidencia: NAUTIYAL BHATT NINAD → NAUTIYAL BHATT NINAD (100.0%)\n",
      "    ✅ Coincidencia: PRIETO ALVAREZ MARIA → PRIETO ALVAREZ MARIA (100.0%)\n",
      "    ✅ Coincidencia: QUISBERT CHOQUETICLLA LEONEL → QUISBERT CHOQUETICLLA LEONEL (100.0%)\n",
      "    ✅ Coincidencia: SANCHEZ RODRIGUEZ ALVARO → SANCHEZ RODRIGUEZ ALVARO (100.0%)\n",
      "    ✅ Coincidencia: SANCHEZ RODRIGUEZ ALVARO → SANCHEZ RODRIGUEZ ALVARO (100.0%)\n",
      "    ✅ Coincidencia: ZHENG YIFEI → ZHENG YIFEI (100.0%)\n",
      "    ✅ Coincidencia: ZODER MENDEZ PABLO JOACHIM → ZODER MENDEZ PABLO JOACHIM (77.0%)\n",
      "\n",
      "📊 RESUMEN FINAL:\n",
      "Total de archivos PDF encontrados: 256\n",
      "Exámenes marcados en DataFrame: 233\n",
      "\n",
      "📈 ESTADÍSTICAS:\n",
      "Examen Práctica 3: 52/444 (11.7%)\n",
      "Examen Práctica 5: 160/444 (36.0%)\n",
      "\n",
      "📋 ESTADÍSTICAS POR GRUPO:\n",
      "                              Examen_3  Examen_5\n",
      "Grupos                                          \n",
      "CITIM11                             14        39\n",
      "CITIM11, CITIM12, Profesores         0         0\n",
      "CITIM11, Profesores                  0         0\n",
      "CITIM12                             13        25\n",
      "CITIM12, Profesores                  0         0\n",
      "CITIT11                              1         0\n",
      "CITIT11, Profesores                  0         0\n",
      "IWSIM11                             12        51\n",
      "IWSIM12                             12        44\n",
      "IWSIT11                              0         0\n",
      "IWSIT12                              0         1\n",
      "Profesores                           0         0\n",
      "DataFrame actualizado con información de prácticas entregadas Y exámenes realizados\n"
     ]
    }
   ],
   "source": [
    "# Ejecutar la búsqueda de exámenes\n",
    "df_con_practicas_y_examenes = buscar_examenes_en_carpetas(df_con_practicas)\n",
    "\n",
    "#print(\"\\n🎯 PROCESO COMPLETADO\")\n",
    "print(\"DataFrame actualizado con información de prácticas entregadas Y exámenes realizados\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display(df_con_practicas_y_examenes.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Verificando nombres de archivos en carpetas de exámenes...\n",
      "================================================================================\n",
      "\n",
      "📁 Procesando carpeta: CITIM11\n",
      "  📂 Practica_2\n",
      "    ✅ PARIENTE_CARRIAZO_ANTONIO_P2_CITIM11.pdf (ya tiene formato correcto)\n",
      "  📂 Practica_3\n",
      "    ✅ ARIAS_CASADO_ALBA_P3_CITIM11.pdf (ya tiene formato correcto)\n",
      "    ✅ CARMONA_OCAÑA_DANIEL_P3_CITIM11.pdf (ya tiene formato correcto)\n",
      "    ✅ DE_LA_IGLESIA_NUÑEZ_PEDRO_JOSE_P3_CITIM11.pdf (ya tiene formato correcto)\n",
      "    ✅ EXPOSITO_SONO_HARITZ_ENDIKA_P3_CITIM11.pdf (ya tiene formato correcto)\n",
      "    ✅ FERNANDEZ_NIETO_DAVID_P3_CITIM11.pdf (ya tiene formato correcto)\n",
      "    ✅ GARCIA_FERNANDEZ_LORENZO_P3_CITIM11.pdf (ya tiene formato correcto)\n",
      "    ✅ HUERGA_GIL_JAVIER_P3_CITIM11.pdf (ya tiene formato correcto)\n",
      "    ✅ LUCERO_PRADA_IRENE_P3_CITIM11.pdf (ya tiene formato correcto)\n",
      "    ✅ MARTIN_VERDUGO_CRISTINA_P3_CITIM11.pdf (ya tiene formato correcto)\n",
      "    ✅ MASSERA_SALCEDO_GUILLERMO_P3_CITIM11.pdf (ya tiene formato correcto)\n",
      "    ✅ MORAN_RUIZ_JAIME_P3_CITIM11.pdf (ya tiene formato correcto)\n",
      "    ✅ NAZARENKO_KSENIA_P3_CITIM11.pdf (ya tiene formato correcto)\n",
      "    ✅ NIETO_HERNANDEZ_JAVIER_P3_CITIM11.pdf (ya tiene formato correcto)\n",
      "    ✅ PLAZA_PASCUAL_LUCAS_P3_CITIM11.pdf (ya tiene formato correcto)\n",
      "    ✅ RODRIGUEZ_RAMOS_CARLOS_P3_CITIM11.pdf (ya tiene formato correcto)\n",
      "    ✅ TRULL_GONZALEZ_SARA_P3_CITIM11.pdf (ya tiene formato correcto)\n",
      "  📂 Practica_5\n",
      "    ✅ AGUIRRIZABAL_MARTINEZ_HUGO_P5_CITIM11.pdf (ya tiene formato correcto)\n",
      "    ✅ ARIAS_CASADO_ALBA_P5_CITIM11.pdf (ya tiene formato correcto)\n",
      "    ✅ CARMONA_OCAÑA_DANIEL_P5_CITIM11.pdf (ya tiene formato correcto)\n",
      "    ✅ CRAUS_SANTA_CATALINA_NICOLAS_P5_CITIM11.pdf (ya tiene formato correcto)\n",
      "    ✅ CUTOLO_SPADARO_ROSANGELA_MARIA_P5_CITIM11.pdf (ya tiene formato correcto)\n",
      "    ✅ DEL_CAMPO_GONZALEZ_ALVARO_P5_CITIM11.pdf (ya tiene formato correcto)\n",
      "    ✅ DE_LA_IGLESIA_NUÑEZ_PEDRO_JOSÉ_P5_CITIM11.pdf (ya tiene formato correcto)\n",
      "    ✅ EXPOSITO_SONO_HARITZ_ENDIKA_P5_CITIM11.pdf (ya tiene formato correcto)\n",
      "    ✅ FERNANDEZ_NIETO_DAVID_P5_CITIM11.pdf (ya tiene formato correcto)\n",
      "    ✅ FERREIRA_SOUZA_JHONATAN_P5_CITIM11.pdf (ya tiene formato correcto)\n",
      "    ✅ GARCIA_FERNANDEZ_LORENZO_P5_CITIM11.pdf (ya tiene formato correcto)\n",
      "    ✅ GARCIA_GARCIA_MARCOS_P5_CITIM11.pdf (ya tiene formato correcto)\n",
      "    ✅ GONZALEZ_RODRIGUEZ_RUBEN_P5_CITIM11.pdf (ya tiene formato correcto)\n",
      "    ✅ HIDALGO_POZAS_MIGUEL_P5_CITIM11.pdf (ya tiene formato correcto)\n",
      "    ✅ HUERGA_GIL_JAVIER_P5_CITIM11.pdf (ya tiene formato correcto)\n",
      "    ✅ JIA_LIU_ZHENGPENG_P5_CITIM11.pdf (ya tiene formato correcto)\n",
      "    ✅ JIMENEZ_DIAZ_MARCOS_P5_CITIM11.pdf (ya tiene formato correcto)\n",
      "    ✅ LOPEZ_GARCIA_ANDRES_P5_CITIM11.pdf (ya tiene formato correcto)\n",
      "    ✅ LOPEZ_RODRIGUEZ_NICOLAS_P5_CITIM11.pdf (ya tiene formato correcto)\n",
      "    ✅ LUCERO_PRADA_IRENE_P5_CITIM11.pdf (ya tiene formato correcto)\n",
      "    ✅ MAQUEDA_IRUN_HECTOR_P5_CITIM11.pdf (ya tiene formato correcto)\n",
      "    ✅ MASSERA_SALCEDO_GUILLERMO_P5_CITIM11.pdf (ya tiene formato correcto)\n",
      "    ✅ MIER_DIAZ_DE_ARCAYA_JUAN_P5_CITIM11.pdf (ya tiene formato correcto)\n",
      "    ✅ MILLAN_ARRANZ_DAVID_P5_CITIM11.pdf (ya tiene formato correcto)\n",
      "    ✅ MORALES_DE_LUIS_JAVIER_P5_CITIM11.pdf (ya tiene formato correcto)\n",
      "    ✅ MORAN_RUIZ_JAIME_P5_CITIM11.pdf (ya tiene formato correcto)\n",
      "    ✅ MORENO_PULIDO_ADRIAN_P5_CITIM11.pdf (ya tiene formato correcto)\n",
      "    ✅ MORENO_SANCHO_SANDRA_P5_CITIM11.pdf (ya tiene formato correcto)\n",
      "    ✅ MUNOZ_FANDINHO_ALEJANDRA_MARIA_P5_CITIM11.pdf (ya tiene formato correcto)\n",
      "    ✅ NAZARENKO_KSENIA_P5_CITIM11.pdf (ya tiene formato correcto)\n",
      "    ✅ OLIVA_RODRIGUEZ_EDUARDO_P5_CITIM11.pdf (ya tiene formato correcto)\n",
      "    ✅ PARIENTE_CARRIAZO_ANTONIO_CITITIM11_P5_CITIM11.pdf (ya tiene formato correcto)\n",
      "    ✅ RODRIGUEZ_MARTIN_RUBEN_P5_CITIM11.pdf (ya tiene formato correcto)\n",
      "    ✅ RODRIGUEZ_RAMOS_CARLOS_P5_CITIM11.pdf (ya tiene formato correcto)\n",
      "    ✅ TARRILLO_MUNDACA_JORGE_AUGUSTO_P5_CITIM11.pdf (ya tiene formato correcto)\n",
      "    ✅ TERESO_SILVA_LUIS_P5_CITIM11.pdf (ya tiene formato correcto)\n",
      "    ✅ TRULL_GONZALEZ_SARA_P5_CITIM11.pdf (ya tiene formato correcto)\n",
      "    ✅ XU_HAOYUAN_P5_CITIM11.pdf (ya tiene formato correcto)\n",
      "\n",
      "📁 Procesando carpeta: CITIM12\n",
      "  📂 Practica_3\n",
      "    ✅ GONZALEZ_RODRIGUEZ_RUBEN_P3_CITIM12.pdf (ya tiene formato correcto)\n",
      "    ✅ JIAYI_LIU_P3_CITIM12.pdf (ya tiene formato correcto)\n",
      "    ✅ LIU_JIAYI_P3_CITIM12.pdf (ya tiene formato correcto)\n",
      "    ✅ PAREJAS_LAMBAN_DAVID_P3_CITIM12.pdf (ya tiene formato correcto)\n",
      "    ✅ PLAZA_PASCUAL_LUCAS_P3_CITIM12.pdf (ya tiene formato correcto)\n",
      "    ✅ POSE_COSTA_JUAN_FRANCISCO_P3_CITIM12.pdf (ya tiene formato correcto)\n",
      "    ✅ PUEBLA_MARTINEZ_FELIX_P3_CITIM12.pdf (ya tiene formato correcto)\n",
      "    ✅ RODRIGUES_ARROYO_HECTOR_P3_CITIM12.pdf (ya tiene formato correcto)\n",
      "    ✅ RODRIGUEZ_ARROYO_HECTOR_P3_CITIM12.pdf (ya tiene formato correcto)\n",
      "    ✅ SALVADOR_GARCIA_MARCOS_P3_CITIM12.pdf (ya tiene formato correcto)\n",
      "    ✅ SANZ_PASTOR_SANTIAGO_P3_CITIM12.pdf (ya tiene formato correcto)\n",
      "    ✅ SEGOVIA_GUTIERREZ_ANGEL_P3_CITIM12.pdf (ya tiene formato correcto)\n",
      "    ✅ SERNA_QUINTERO_JUAN_JOSE_P3_CITIM12.pdf (ya tiene formato correcto)\n",
      "    ✅ SEÑORANS_DAVILA_JAVIER_P3_CITIM12.pdf (ya tiene formato correcto)\n",
      "    ✅ TORRES_SAN_FELIPE_GUILLERMO_P3_CITIM12.pdf (ya tiene formato correcto)\n",
      "  📂 Practica_5\n",
      "    ✅ CHIFOR_NICOLAS_MARIUS_P5_CITIM12.pdf (ya tiene formato correcto)\n",
      "    ✅ GARCIA_CARRETERO_SAMUEL_P5_CITIM12.pdf (ya tiene formato correcto)\n",
      "    ✅ GOMEZ_ROBLEDANO_PABLO_P5_CITIM12.pdf (ya tiene formato correcto)\n",
      "    ✅ GONZALEZ_RODRIGUEZ_RUBEN_P5_CITIM12.pdf (ya tiene formato correcto)\n",
      "    ✅ JIAYI_LIU_P5_CITIM12.pdf (ya tiene formato correcto)\n",
      "    ✅ JIMENEZ_SANZ_SERGIO_P5_CITIM12.pdf (ya tiene formato correcto)\n",
      "    ✅ LIU_JIAYI_P5_CITIM12.pdf (ya tiene formato correcto)\n",
      "    ✅ NUÑEZ_GONZALEZ_ARANCHA_P5_CITIM12.pdf (ya tiene formato correcto)\n",
      "    ✅ PALOMERA_MARTIN_CARLOS_P5_CITIM12.pdf (ya tiene formato correcto)\n",
      "    ✅ PANIS_MARAMBA_TRISHALYN_P5_CITIM12.pdf (ya tiene formato correcto)\n",
      "    ✅ PAREJAS_LAMBAN_DAVID_P5_CITIM12.pdf (ya tiene formato correcto)\n",
      "    ✅ PLAZA_PASCUAL_LUCAS_P5_CITIM12.pdf (ya tiene formato correcto)\n",
      "    ✅ POSE_COSTA_JUAN_FRANCISCO_P5_CITIM12.pdf (ya tiene formato correcto)\n",
      "    ✅ PUEBLA_MARTINEZ_FELIX_P5_CITIM12.pdf (ya tiene formato correcto)\n",
      "    ✅ RODRIGUES_ARROYO_HECTOR_P5_CITIM12.pdf (ya tiene formato correcto)\n",
      "    ✅ ROMO_TAMAME_EVA_P5_CITIM12.pdf (ya tiene formato correcto)\n",
      "    ✅ SALVADOR_GARCIA_MARCOS_P5_CITIM12.pdf (ya tiene formato correcto)\n",
      "    ✅ SANCHEZ_SANTANA_JHON_LEUDY_P5_CITIM12.pdf (ya tiene formato correcto)\n",
      "    ✅ SANZ_COLON_ADRIANA_P5_CITIM12.pdf (ya tiene formato correcto)\n",
      "    ✅ SANZ_PASTOR_SANTIAGO_P5_CITIM12.pdf (ya tiene formato correcto)\n",
      "    ✅ SEGOVIA_GUTIERREZ_ANGEL_P5_CITIM12.pdf (ya tiene formato correcto)\n",
      "    ✅ SENORANS_DAVILA_JAVIER_P5_CITIM12.pdf (ya tiene formato correcto)\n",
      "    ✅ SERNA_QUINTERO_JUAN_JOSE_P5_CITIM12.pdf (ya tiene formato correcto)\n",
      "    ✅ SEÑORANS_DAVILA_JAVIER_P5_CITIM12.pdf (ya tiene formato correcto)\n",
      "    ✅ TORRES_SAN_FELIPE_GUILLERMO_P5_CITIM12.pdf (ya tiene formato correcto)\n",
      "    ✅ TRUBITSIN_GAVRILOV_ALEX_P5_CITIM12.pdf (ya tiene formato correcto)\n",
      "    ✅ XIA_OSCAR_P5_CITIM12.pdf (ya tiene formato correcto)\n",
      "    ✅ ZHANG_JIONGHAO_P5_CITIM12.pdf (ya tiene formato correcto)\n",
      "    ✅ ZOU_XURUI_P5_CITIM12.pdf (ya tiene formato correcto)\n",
      "\n",
      "📁 Procesando carpeta: CITIT11\n",
      "  📂 Practica_3\n",
      "    ✅ FILALI_BELHADJ_CHAQROUNE_YASSIR_P3_CITIT11.pdf (ya tiene formato correcto)\n",
      "\n",
      "📁 Procesando carpeta: IWSIM11\n",
      "  📂 Practica_3\n",
      "    ✅ BARRERA_VELASQUEZ_ESAU_EZEQUIEL_P3_IWSIM11.pdf (ya tiene formato correcto)\n",
      "    ✅ BEAUTELL_NAVARRO_HUGO_P3_IWSIM11.pdf (ya tiene formato correcto)\n",
      "    ✅ CARRASCO_PARDO_SERGIO_P3_IWSIM11.pdf (ya tiene formato correcto)\n",
      "    ✅ GARCIA_LEON_HUGO_P3_IWSIM11.pdf (ya tiene formato correcto)\n",
      "    ✅ HEINRICKS_GONZALEZ_BRANDON_P3_IWSIM11.pdf (ya tiene formato correcto)\n",
      "    ✅ HERNANDEZ_GARNACHO_JOSE_ANGEL_ARBOLES_P3_IWSIM11.pdf (ya tiene formato correcto)\n",
      "    ✅ LUCERO_PRADA_IRENE_P3_IWSIM11.pdf (ya tiene formato correcto)\n",
      "    ✅ MARTINEZ_SEBASTIA_NACHO_P3_IWSIM11.pdf (ya tiene formato correcto)\n",
      "    ✅ MARTIN_BALLESTER_DANIEL_P3_IWSIM11.pdf (ya tiene formato correcto)\n",
      "    ✅ MARTIN_VERDUGO_CRISTINA_P3_IWSIM11.pdf (ya tiene formato correcto)\n",
      "    ✅ MONEDERO_ANGULO_JAVIER_P3_IWSIM11.pdf (ya tiene formato correcto)\n",
      "    ✅ RODRIGUEZ_SANCHEZ_VICTOR_P3_IWSIM11.pdf (ya tiene formato correcto)\n",
      "    ✅ ROMEO_PEREZ_ALEJANDRO_P3_IWSIM11.pdf (ya tiene formato correcto)\n",
      "  📂 Practica_4\n",
      "    ✅ HERNANDEZ_GARNACHO_JOSE_ANGEL_P4_IWSIM11.pdf (ya tiene formato correcto)\n",
      "  📂 Practica_5\n",
      "    ✅ BARRERA_VELASQUEZ_ESAU_EZEQUIEL_P5_IWSIM11.pdf (ya tiene formato correcto)\n",
      "    ✅ BEAUTELL_NAVARRO_HUGO_P5_IWSIM11.pdf (ya tiene formato correcto)\n",
      "    ✅ BEAUTEL_NAVARRO_HUGO_P5_IWSIM11.pdf (ya tiene formato correcto)\n",
      "    ✅ BLANCO_MARCHAL_SIMON_P5_IWSIM11.pdf (ya tiene formato correcto)\n",
      "    ✅ BRAVO_CUEVA_ALVARO_P5_IWSIM11.pdf (ya tiene formato correcto)\n",
      "    ✅ CAMARA_VILKOVA_VERONICA_LUISA_P5_IWSIM11.pdf (ya tiene formato correcto)\n",
      "    ✅ CARRASCO_PARDO_SERGIO_P5_IWSIM11.pdf (ya tiene formato correcto)\n",
      "    ✅ DEL_POZUELO_ESCALONA_PABLO_P5_IWSIM11.pdf (ya tiene formato correcto)\n",
      "    ✅ GARCIA_LEON_HUGO_P5_IWSIM11.pdf (ya tiene formato correcto)\n",
      "    ✅ HERNANDEZ_MONTERO_LUCIA_P5_IWSIM11.pdf (ya tiene formato correcto)\n",
      "    ✅ HERRERA_GALERA_PEDRO_ALEJANDRO_P5_IWSIM11.pdf (ya tiene formato correcto)\n",
      "    ✅ HIDALGO_PARIENTE_MARCO_MARCO_P5_IWSIM11.pdf (ya tiene formato correcto)\n",
      "    ✅ HIDALGO_PARIENTE_MARCO_P5_IWSIM11.pdf (ya tiene formato correcto)\n",
      "    ✅ IONESCU_SOARE_ALEJANDRO_RAFAEL_P5_IWSIM11.pdf (ya tiene formato correcto)\n",
      "    ✅ IVASIV_KOSYK_MAXYM_P5_IWSIM11.pdf (ya tiene formato correcto)\n",
      "    ✅ JIMENEZ_RAMOS_DANIEL_P5_IWSIM11.pdf (ya tiene formato correcto)\n",
      "    ✅ JUAREZ_GELARDO_TOMAS_P5_IWSIM11.pdf (ya tiene formato correcto)\n",
      "    ✅ JUSUE_ZAVALA_JOSE_RAMON_P5_IWSIM11.pdf (ya tiene formato correcto)\n",
      "    ✅ KE_TAILI_P5_IWSIM11.pdf (ya tiene formato correcto)\n",
      "    ✅ LAFUENTE_SANZ_ALICIA_P5_IWSIM11.pdf (ya tiene formato correcto)\n",
      "    ✅ LEFTERACHE_RAILEANU_NICOLAS_ANDRES_P5_IWSIM11.pdf (ya tiene formato correcto)\n",
      "    ✅ LENCERO_CARRILLO_OSCAR_P5_IWSIM11.pdf (ya tiene formato correcto)\n",
      "    ✅ LI_JILING_P5_IWSIM11.pdf (ya tiene formato correcto)\n",
      "    ✅ LLORENTE_VAQUERO_CARLOS_P5_IWSIM11.pdf (ya tiene formato correcto)\n",
      "    ✅ LOPEZ_COLMENERO_ROSALIA_P5_IWSIM11.pdf (ya tiene formato correcto)\n",
      "    ✅ LOPEZ_DE_LA_MANZANARA_GARCIA_PABLO_P5_IWSIM11.pdf (ya tiene formato correcto)\n",
      "    ✅ LOPEZ_DE_LA_MANZANARA_GARCI_PABLO_P5_IWSIM11.pdf (ya tiene formato correcto)\n",
      "    ✅ LOZANO_MARCOS_MARTA_P5_IWSIM11.pdf (ya tiene formato correcto)\n",
      "    ✅ MAHER_FAIQ_AL_RAWE_MAHMOOD_P5_IWSIM11.pdf (ya tiene formato correcto)\n",
      "    ✅ MARINA_NAVARRO_PAULA_P5_IWSIM11.pdf (ya tiene formato correcto)\n",
      "    🔄 Renombrando:\n",
      "       De: MARINA_NAVARRO_PAULA_P5_IWSIM11_3.pdf\n",
      "       A:  MARINA_NAVARRO_PAULA_P5_IWSIM11.pdf\n",
      "       ⚠️  Conflicto detectado, usando: MARINA_NAVARRO_PAULA_P5_IWSIM11_2.pdf\n",
      "       ✅ Renombrado exitosamente\n",
      "    ✅ MARQUEZ_SANTAMARIA_ALVARO_P5_IWSIM11.pdf (ya tiene formato correcto)\n",
      "    ✅ MARTINEZ_LOPEZ_TERCERO_JESUS_P5_IWSIM11.pdf (ya tiene formato correcto)\n",
      "    ✅ MARTINEZ_SEBASTIA_NACHO_P5_IWSIM11.pdf (ya tiene formato correcto)\n",
      "    ✅ MARTIN_BALLESTER_DANIEL_P5_IWSIM11.pdf (ya tiene formato correcto)\n",
      "    ✅ MARTIN_ESPAÑA_ANTONIO_P5_IWSIM11.pdf (ya tiene formato correcto)\n",
      "    ✅ MARTIN_MARTIN_JORGE_P5_IWSIM11.pdf (ya tiene formato correcto)\n",
      "    ✅ MARTIN_OLIVERO_IRENE_P5_IWSIM11.pdf (ya tiene formato correcto)\n",
      "    ✅ MARTIN_VERDUGO_CRISTINA_P5_IWSIM11.pdf (ya tiene formato correcto)\n",
      "    ✅ MATHEUS_GONCALVEZ_DANIEL_ALEJANDRO_P5_IWSIM11.pdf (ya tiene formato correcto)\n",
      "    ✅ MA_ANNI_P5_IWSIM11.pdf (ya tiene formato correcto)\n",
      "    ✅ MENOYO_PEREZ_ALVARO_P5_IWSIM11.pdf (ya tiene formato correcto)\n",
      "    ✅ MERINO_FERNANDEZ_SOFIA_P5_IWSIM11.pdf (ya tiene formato correcto)\n",
      "    ✅ MONEDERO_ANGULO_JAVIER_P5_IWSIM11.pdf (ya tiene formato correcto)\n",
      "    ✅ MONTARELO_PADILLA_ALBERTO_P5_IWSIM11.pdf (ya tiene formato correcto)\n",
      "    ✅ MORALEDA_SALGUEDO_DAVID_P5_IWSIM11.pdf (ya tiene formato correcto)\n",
      "    ✅ MORALEDA_SALGUERO_DAVID_P5_IWSIM11.pdf (ya tiene formato correcto)\n",
      "    ✅ MORALES_DE_LUIS_HECTOR_P5_IWSIM11.pdf (ya tiene formato correcto)\n",
      "    ✅ MORENO-PALANCAS_CEBALLOS_LUCAS_P5_IWSIM11.pdf (ya tiene formato correcto)\n",
      "    ✅ MORENO_VIRUETE_IGNACIO_P5_IWSIM11.pdf (ya tiene formato correcto)\n",
      "    ✅ MOYA_BLANCO_JESUS_FRANCISCO_P5_IWSIM11.pdf (ya tiene formato correcto)\n",
      "    ✅ MOYA_RIVERA_PABLO_P5_IWSIM11.pdf (ya tiene formato correcto)\n",
      "    ✅ MUÑOZ_FERNANDEZ_MIGUEL_ANGEL_P5_IWSIM11.pdf (ya tiene formato correcto)\n",
      "    ✅ NARANJO_MUÑOZ_ISMAEL_P5_IWSIM11.pdf (ya tiene formato correcto)\n",
      "    ✅ NAVARRETE_HURTADO_IMANOL_P5_IWSIM11.pdf (ya tiene formato correcto)\n",
      "    ✅ NGOMO_NCHAMA_ANTONIO_ELA_P5_IWSIM11.pdf (ya tiene formato correcto)\n",
      "    ✅ PEREZ_DIMAS_IZAN_P5_IWSIM11.pdf (ya tiene formato correcto)\n",
      "    ✅ RODRIGUEZ_SANCHEZ_VICTOR_P5_IWSIM11.pdf (ya tiene formato correcto)\n",
      "    ✅ ROMEO_PEREZ_ALEJANDRO_P5_IWSIM11.pdf (ya tiene formato correcto)\n",
      "    ✅ SICILIA_BALAS_DANIELA_P5_IWSIM11.pdf (ya tiene formato correcto)\n",
      "    ✅ ZHENG_YIFEI_P5_IWSIM11.pdf (ya tiene formato correcto)\n",
      "\n",
      "📁 Procesando carpeta: IWSIM12\n",
      "  📂 Practica_3\n",
      "    ✅ ALVAREZ_AREVALO_MIGUEL_P3_IWSIM12.pdf (ya tiene formato correcto)\n",
      "    ✅ FERNANDEZ_HERRERO_DIEGO_P3_IWSIM12.pdf (ya tiene formato correcto)\n",
      "    ✅ FUENTE_MARTINEZ_HERNAN_GABRIEL_DE_LA_P3_IWSIM12.pdf (ya tiene formato correcto)\n",
      "    ✅ GONZALEZ_BENITO_ANDRES_P3_IWSIM12.pdf (ya tiene formato correcto)\n",
      "    ✅ HEINRICKS_GONZALEZ_BRANDON_P3_IWSIM12.pdf (ya tiene formato correcto)\n",
      "    ✅ OTERO_MORENO_EKAITZ_P3_IWSIM12.pdf (ya tiene formato correcto)\n",
      "    ✅ ROJAS_ILLESCAS_GABRIEL_P3_IWSIM12.pdf (ya tiene formato correcto)\n",
      "    ✅ RUSSO_PEREZ_ALEJANDRO_ISAAC_P3_IWSIM12.pdf (ya tiene formato correcto)\n",
      "    ✅ SANCHEZ_PINA_JORGE_P3_IWSIM12.pdf (ya tiene formato correcto)\n",
      "    ✅ SANCHEZ_PIÑA_JORGE_P3_IWSIM12.pdf (ya tiene formato correcto)\n",
      "    ✅ SANZ_AVILA_DANIEL_P3_IWSIM12.pdf (ya tiene formato correcto)\n",
      "    ✅ SAN_JUAN_FERNANDEZ_MARIO_P3_IWSIM12.pdf (ya tiene formato correcto)\n",
      "    ✅ YE_JUNQIN_P3_IWSIM12.pdf (ya tiene formato correcto)\n",
      "    ✅ ZHU_XIANG_LE_P3_IWSIM12.pdf (ya tiene formato correcto)\n",
      "  📂 Practica_5\n",
      "    ✅ AGUIRRE_HERVÁS_JAVIER_P5_IWSIM12.pdf (ya tiene formato correcto)\n",
      "    ✅ ANTONIO_ELA_NGOMO_NCHAMA_P5_IWSIM12.pdf (ya tiene formato correcto)\n",
      "    ✅ APUNTE_SIERRA_AARON_ALEJANDRO_P5_IWSIM12.pdf (ya tiene formato correcto)\n",
      "    ✅ AUSIN_MORENO_MARCOS_P5_IWSIM12.pdf (ya tiene formato correcto)\n",
      "    ✅ AYALA_MAYA_JULIO_P5_IWSIM12.pdf (ya tiene formato correcto)\n",
      "    ✅ DE_LOS_MOZOS_DE_LA_CRUZ_DIEGO_P5_IWSIM12.pdf (ya tiene formato correcto)\n",
      "    ✅ DOMINGUEZ_ALVAREZ_JAVIER_P5_IWSIM12.pdf (ya tiene formato correcto)\n",
      "    ✅ FORONDA_IRAIZOS_PABLO_RAMIRO_P5_IWSIM12.pdf (ya tiene formato correcto)\n",
      "    ✅ ILIYANOVA_ATANASOVA_ALICIA_P5_IWSIM12.pdf (ya tiene formato correcto)\n",
      "    ✅ JIMENEZ_GARCIA_ANGELA_P5_IWSIM12.pdf (ya tiene formato correcto)\n",
      "    ✅ JIMENEZ_JIMENEZ_ANDREA_P5_IWSIM12.pdf (ya tiene formato correcto)\n",
      "    ✅ LENCERO_CARRILLO_OSCAR_P5_IWSIM12.pdf (ya tiene formato correcto)\n",
      "    ✅ LOZANO_MARCOS_MARTA_P5_IWSIM12.pdf (ya tiene formato correcto)\n",
      "    ✅ MARINA_NAVARRO_PAULA_P5_IWSIM12.pdf (ya tiene formato correcto)\n",
      "    🔄 Renombrando:\n",
      "       De: MARINA_NAVARRO_PAULA_P5_IWSIM12_3.pdf\n",
      "       A:  MARINA_NAVARRO_PAULA_P5_IWSIM12.pdf\n",
      "       ⚠️  Conflicto detectado, usando: MARINA_NAVARRO_PAULA_P5_IWSIM12_2.pdf\n",
      "       ✅ Renombrado exitosamente\n",
      "    ✅ MONTARELO_PADILLA_ALBERTO_P5_IWSIM12.pdf (ya tiene formato correcto)\n",
      "    ✅ MORENO_VIRUETE_IGNACIO_P5_IWSIM12.pdf (ya tiene formato correcto)\n",
      "    ✅ NIETO_HERNANDEZ_JAVIER_P5_IWSIM12.pdf (ya tiene formato correcto)\n",
      "    ✅ ORTIZ_PASAMONTES_MARCOS_P5_IWSIM12.pdf (ya tiene formato correcto)\n",
      "    ✅ PANTOJA_FIGUEROA_ALEJANDRO_P5_IWSIM12.pdf (ya tiene formato correcto)\n",
      "    ✅ PIÑA_RODRIGUEZ_RODRIGO_P5_IWSIM12.pdf (ya tiene formato correcto)\n",
      "    ✅ POENARU_TIMOTEI_LUCIAN_P5_IWSIM12.pdf (ya tiene formato correcto)\n",
      "    ✅ PRIETO_ALVAREZ_MARIA_P5_IWSIM12.pdf (ya tiene formato correcto)\n",
      "    ✅ RAZZAK_AKTER_TARIQUL_ISLAM_P5_IWSIM12.pdf (ya tiene formato correcto)\n",
      "    ✅ ROCHA_BENATTI_ENRIQUE_P5_IWSIM12.pdf (ya tiene formato correcto)\n",
      "    ✅ RODRIGUEZ_BARRIO_SANTIAGO_P5_IWSIM12.pdf (ya tiene formato correcto)\n",
      "    ✅ RODRIGUEZ_MARTIN_DAVID_P5_IWSIM12.pdf (ya tiene formato correcto)\n",
      "    ✅ RODRIGUEZ_ROMAN_DIEGO_P5_IWSIM12.pdf (ya tiene formato correcto)\n",
      "    ✅ ROJAS_ILLESCAS_GABRIEL_P5_IWSIM12.pdf (ya tiene formato correcto)\n",
      "    ✅ RUIZ_PEREZ_CLAUDIA_P5_IWSIM12.pdf (ya tiene formato correcto)\n",
      "    ✅ RUSSO_PEREZ_ALEJANDRO_ISAAC_P5_IWSIM12.pdf (ya tiene formato correcto)\n",
      "    ✅ SAIZ_MOLINA_DAVID_P5_IWSIM12.pdf (ya tiene formato correcto)\n",
      "    ✅ SANCHEZ_DEL_CAMPO_HUGO_P5_IWSIM12.pdf (ya tiene formato correcto)\n",
      "    ✅ SANCHEZ_NUÑO_JORGE_P5_IWSIM12.pdf (ya tiene formato correcto)\n",
      "    ✅ SANCHEZ_PINA_JORGE_P5_IWSIM12.pdf (ya tiene formato correcto)\n",
      "    ✅ SANCHEZ_TAPIADOR_PABLO_P5_IWSIM12.pdf (ya tiene formato correcto)\n",
      "    ✅ SANZ_AVILA_DANIEL_P5_IWSIM12.pdf (ya tiene formato correcto)\n",
      "    ✅ SAN_JUAN_FERNANDEZ_MARIO_P5_IWSIM12.pdf (ya tiene formato correcto)\n",
      "    ✅ SEBASTIANI_DAMAS_SANTIAGO_DANIEL_P5_IWSIM12.pdf (ya tiene formato correcto)\n",
      "    ✅ SILVA_CASTRO_JUAN_P5_IWSIM12.pdf (ya tiene formato correcto)\n",
      "    ✅ SORET_EL_HARTI_SARAH_P5_IWSIM12.pdf (ya tiene formato correcto)\n",
      "    ✅ STRAUS_PEÑAFIEL_ALVARO_P5_IWSIM12.pdf (ya tiene formato correcto)\n",
      "    ✅ TAIPE_TICSE_LUIS_IÑAKI_P5_IWSIM12.pdf (ya tiene formato correcto)\n",
      "    ✅ TAMAKI_MORENO_ALVARO_P5_IWSIM12.pdf (ya tiene formato correcto)\n",
      "    ✅ TITUAÑA_SOTALIN_BRANDON_ALEXIS_P5_IWSIM12.pdf (ya tiene formato correcto)\n",
      "    ✅ VAQUEIRO_JIMENEZ_DAVID_P5_IWSIM12.pdf (ya tiene formato correcto)\n",
      "    ✅ VERDIN_DOMINGUEZ_LARA_P5_IWSIM12.pdf (ya tiene formato correcto)\n",
      "    ✅ VICENTE_MIGUEL_CELIA_P5_IWSIM12.pdf (ya tiene formato correcto)\n",
      "    ✅ VILLA_MARTIN_PABLO_P5_IWSIM12.pdf (ya tiene formato correcto)\n",
      "    ✅ VINDEL_DOMINGUEZ_JORGE_P5_IWSIM12.pdf (ya tiene formato correcto)\n",
      "    ✅ YANG_JINXIAN_P5_IWSIM12.pdf (ya tiene formato correcto)\n",
      "    ✅ YUHANG_ZHOU_P5_IWSIM12.pdf (ya tiene formato correcto)\n",
      "    ✅ ZHU_XIANG_LE_P5_IWSIM12.pdf (ya tiene formato correcto)\n",
      "    ✅ ZODER_MENDEZ_ANA_P5_IWSIM12.pdf (ya tiene formato correcto)\n",
      "\n",
      "📁 Procesando carpeta: IWSIT12\n",
      "\n",
      "📁 Procesando carpeta: problemático\n",
      "  📂 Carpeta especial: problemático\n",
      "    ✅ CAMARA_VILKOVA_VERONICA_LUISA_P3_IWSIM11.pdf (ya tiene formato correcto)\n",
      "    ✅ FUENTE_MARTINEZ_HERNAN_GABRIEL_DE_LA_P5_IWSIM12.pdf (ya tiene formato correcto)\n",
      "    ✅ FUERIS_FRUTOS_MANUEL_P5_IWSIT12.pdf (ya tiene formato correcto)\n",
      "    ✅ HEINRICKS_GONZALEZ_BRANDON_P3_IWSIM11.pdf (ya tiene formato correcto)\n",
      "    ✅ HEINRICKS_GONZALEZ_BRANDON_P5_IWSIM11.pdf (ya tiene formato correcto)\n",
      "    ✅ IANCU_IANCU_GEORGIAN_SORIN_P3_IWSIM11.pdf (ya tiene formato correcto)\n",
      "    ✅ IANCU_IANCU_GEORGIAN_SORIN_P5_IWSIM11.pdf (ya tiene formato correcto)\n",
      "    ✅ NAUTIYAL_BHATT_NINAD_P3_IWSIM11.pdf (ya tiene formato correcto)\n",
      "    ✅ NAUTIYAL_BHATT_NINAD_P5_IWSIM11.pdf (ya tiene formato correcto)\n",
      "    ✅ PRIETO_ALVAREZ_MARIA_P5_IWSIM12.pdf (ya tiene formato correcto)\n",
      "    ✅ QUISBERT_CHOQUETICLLA_LEONEL_P3_IWSIM12.pdf (ya tiene formato correcto)\n",
      "    ✅ SANCHEZ_RODRIGUEZ_ALVARO_P3_IWSIM12.pdf (ya tiene formato correcto)\n",
      "    ✅ SANCHEZ_RODRIGUEZ_ALVARO_P5_IWSIM12.pdf (ya tiene formato correcto)\n",
      "    ✅ ZHENG_YIFEI_P3_IWSIM12.pdf (ya tiene formato correcto)\n",
      "    ✅ ZODER_MENDEZ_PABLO_JOACHIM_P5_IWSIM12.pdf (ya tiene formato correcto)\n",
      "\n",
      "================================================================================\n",
      "📊 RESUMEN DE ESTANDARIZACIÓN:\n",
      "Total de archivos procesados: 258\n",
      "Archivos renombrados: 2\n",
      "Archivos que ya tenían formato correcto: 256\n",
      "\n",
      "✅ No se encontraron errores\n"
     ]
    }
   ],
   "source": [
    "def estandarizar_nombres_examenes(ruta_examenes=\"../data/examenes_procesados/\"):\n",
    "    \"\"\"\n",
    "    Verifica y estandariza todos los nombres de archivos de exámenes \n",
    "    siguiendo el formato: APELLIDOS_NOMBRE_P<numpractica>_<GRUPO>\n",
    "    \"\"\"\n",
    "    ruta_examenes = Path(ruta_examenes)\n",
    "    \n",
    "    if not ruta_examenes.exists():\n",
    "        print(f\"❌ La ruta {ruta_examenes} no existe\")\n",
    "        return\n",
    "    \n",
    "    archivos_procesados = 0\n",
    "    archivos_renombrados = 0\n",
    "    errores = []\n",
    "    \n",
    "    print(\"🔍 Verificando nombres de archivos en carpetas de exámenes...\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Recorrer todas las carpetas de grupos\n",
    "    for carpeta_grupo in ruta_examenes.iterdir():\n",
    "        if not carpeta_grupo.is_dir():\n",
    "            continue\n",
    "            \n",
    "        print(f\"\\n📁 Procesando carpeta: {carpeta_grupo.name}\")\n",
    "        \n",
    "        # Si es una carpeta de grupo normal (con subcarpetas de prácticas)\n",
    "        if carpeta_grupo.name not in [\"extraviados\", \"problemático\", \"eliminados\"]:\n",
    "            for subcarpeta in carpeta_grupo.iterdir():\n",
    "                if subcarpeta.is_dir() and subcarpeta.name.startswith(\"Practica_\"):\n",
    "                    # Extraer número de práctica\n",
    "                    practica_num = subcarpeta.name.replace(\"Practica_\", \"\")\n",
    "                    print(f\"  📂 {subcarpeta.name}\")\n",
    "                    \n",
    "                    # Procesar archivos en esta carpeta\n",
    "                    for archivo_pdf in subcarpeta.glob(\"*.pdf\"):\n",
    "                        archivos_procesados += 1\n",
    "                        \n",
    "                        nombre_actual = archivo_pdf.stem\n",
    "                        formato_esperado = generar_nombre_estandar(\n",
    "                            nombre_actual, practica_num, carpeta_grupo.name\n",
    "                        )\n",
    "                        \n",
    "                        if nombre_actual != formato_esperado:\n",
    "                            print(f\"    🔄 Renombrando:\")\n",
    "                            print(f\"       De: {nombre_actual}.pdf\")\n",
    "                            print(f\"       A:  {formato_esperado}.pdf\")\n",
    "                            \n",
    "                            try:\n",
    "                                nuevo_path = archivo_pdf.parent / f\"{formato_esperado}.pdf\"\n",
    "                                \n",
    "                                # Evitar conflictos\n",
    "                                contador = 2\n",
    "                                while nuevo_path.exists():\n",
    "                                    nuevo_formato = f\"{formato_esperado}_{contador}\"\n",
    "                                    nuevo_path = archivo_pdf.parent / f\"{nuevo_formato}.pdf\"\n",
    "                                    print(f\"       ⚠️  Conflicto detectado, usando: {nuevo_formato}.pdf\")\n",
    "                                    contador += 1\n",
    "                                \n",
    "                                archivo_pdf.rename(nuevo_path)\n",
    "                                archivos_renombrados += 1\n",
    "                                print(f\"       ✅ Renombrado exitosamente\")\n",
    "                                \n",
    "                            except Exception as e:\n",
    "                                error_msg = f\"Error renombrando {archivo_pdf.name}: {e}\"\n",
    "                                errores.append(error_msg)\n",
    "                                print(f\"       ❌ {error_msg}\")\n",
    "                        else:\n",
    "                            print(f\"    ✅ {nombre_actual}.pdf (ya tiene formato correcto)\")\n",
    "        \n",
    "        # Procesar carpetas especiales\n",
    "        else:\n",
    "            print(f\"  📂 Carpeta especial: {carpeta_grupo.name}\")\n",
    "            for archivo_pdf in carpeta_grupo.glob(\"*.pdf\"):\n",
    "                archivos_procesados += 1\n",
    "                \n",
    "                # Para carpetas especiales, intentar detectar práctica y grupo del nombre\n",
    "                practica_detectada = detectar_practica_del_nombre(archivo_pdf.name)\n",
    "                grupo_detectado = detectar_grupo_del_nombre(archivo_pdf.name)\n",
    "                \n",
    "                if practica_detectada and grupo_detectado:\n",
    "                    nombre_actual = archivo_pdf.stem\n",
    "                    formato_esperado = generar_nombre_estandar(\n",
    "                        nombre_actual, practica_detectada, grupo_detectado\n",
    "                    )\n",
    "                    \n",
    "                    if nombre_actual != formato_esperado:\n",
    "                        print(f\"    🔄 Renombrando (carpeta especial):\")\n",
    "                        print(f\"       De: {nombre_actual}.pdf\")\n",
    "                        print(f\"       A:  {formato_esperado}.pdf\")\n",
    "                        \n",
    "                        try:\n",
    "                            nuevo_path = archivo_pdf.parent / f\"{formato_esperado}.pdf\"\n",
    "                            \n",
    "                            # Evitar conflictos\n",
    "                            contador = 2\n",
    "                            while nuevo_path.exists():\n",
    "                                nuevo_formato = f\"{formato_esperado}_{contador}\"\n",
    "                                nuevo_path = archivo_pdf.parent / f\"{nuevo_formato}.pdf\"\n",
    "                                contador += 1\n",
    "                            \n",
    "                            archivo_pdf.rename(nuevo_path)\n",
    "                            archivos_renombrados += 1\n",
    "                            print(f\"       ✅ Renombrado exitosamente\")\n",
    "                            \n",
    "                        except Exception as e:\n",
    "                            error_msg = f\"Error renombrando {archivo_pdf.name}: {e}\"\n",
    "                            errores.append(error_msg)\n",
    "                            print(f\"       ❌ {error_msg}\")\n",
    "                    else:\n",
    "                        print(f\"    ✅ {archivo_pdf.name} (ya tiene formato correcto)\")\n",
    "                else:\n",
    "                    print(f\"    ⚠️  {archivo_pdf.name} (no se pudo detectar práctica/grupo)\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"📊 RESUMEN DE ESTANDARIZACIÓN:\")\n",
    "    print(f\"Total de archivos procesados: {archivos_procesados}\")\n",
    "    print(f\"Archivos renombrados: {archivos_renombrados}\")\n",
    "    print(f\"Archivos que ya tenían formato correcto: {archivos_procesados - archivos_renombrados}\")\n",
    "    \n",
    "    if errores:\n",
    "        print(f\"\\n❌ ERRORES ({len(errores)}):\")\n",
    "        for error in errores:\n",
    "            print(f\"  - {error}\")\n",
    "    else:\n",
    "        print(\"\\n✅ No se encontraron errores\")\n",
    "\n",
    "def generar_nombre_estandar(nombre_actual, practica_num, grupo):\n",
    "    \"\"\"\n",
    "    Genera el nombre estándar basado en el nombre actual\n",
    "    Formato: APELLIDOS_NOMBRE_P<numpractica>_<GRUPO>\n",
    "    \"\"\"\n",
    "    # Limpiar el nombre actual de elementos no deseados\n",
    "    nombre_limpio = nombre_actual.upper()\n",
    "    \n",
    "    # Remover elementos que no sean nombres (práctica anterior, grupo anterior, etc.)\n",
    "    elementos_a_remover = [\n",
    "        rf'_P\\d+', rf'P\\d+_', rf'P\\d+$',  # Prácticas\n",
    "        rf'_{grupo}', rf'{grupo}_', rf'^{grupo}',  # Grupo actual\n",
    "        r'_CITIM\\d+', r'_IWSIM\\d+', r'_CITIT\\d+', r'_IWSIT\\d+',  # Otros grupos\n",
    "        r'CITIM\\d+_', r'IWSIM\\d+_', r'CITIT\\d+_', r'IWSIT\\d+_',\n",
    "        r'_\\d+$'  # Números al final\n",
    "    ]\n",
    "    \n",
    "    for patron in elementos_a_remover:\n",
    "        nombre_limpio = re.sub(patron, '', nombre_limpio)\n",
    "    \n",
    "    # Limpiar guiones bajos múltiples y al inicio/final\n",
    "    nombre_limpio = re.sub(r'_+', '_', nombre_limpio).strip('_')\n",
    "    \n",
    "    # Si está vacío, usar un nombre por defecto\n",
    "    if not nombre_limpio:\n",
    "        nombre_limpio = \"SIN_NOMBRE\"\n",
    "    \n",
    "    # Construir el formato estándar\n",
    "    formato_estandar = f\"{nombre_limpio}_P{practica_num}_{grupo}\"\n",
    "    \n",
    "    return formato_estandar\n",
    "\n",
    "def detectar_practica_del_nombre(nombre_archivo):\n",
    "    \"\"\"Detecta el número de práctica del nombre del archivo\"\"\"\n",
    "    nombre = nombre_archivo.upper()\n",
    "    \n",
    "    # Buscar patrones de práctica\n",
    "    patrones = [\n",
    "        r'P(\\d)',\n",
    "        r'_(\\d)_',\n",
    "        r'PRACTICA_?(\\d)',\n",
    "    ]\n",
    "    \n",
    "    for patron in patrones:\n",
    "        match = re.search(patron, nombre)\n",
    "        if match:\n",
    "            return match.group(1)\n",
    "    \n",
    "    # Buscar palabras clave\n",
    "    if 'LISTA' in nombre or '3' in nombre:\n",
    "        return '3'\n",
    "    elif 'GRAFO' in nombre or '5' in nombre:\n",
    "        return '5'\n",
    "    elif '4' in nombre:\n",
    "        return '4'\n",
    "    elif '2' in nombre:\n",
    "        return '2'\n",
    "    \n",
    "    return None\n",
    "\n",
    "def detectar_grupo_del_nombre(nombre_archivo):\n",
    "    \"\"\"Detecta el grupo del nombre del archivo\"\"\"\n",
    "    nombre = nombre_archivo.upper()\n",
    "    \n",
    "    # Buscar patrones de grupo\n",
    "    grupos_posibles = ['CITIM11', 'CITIM12', 'IWSIM11', 'IWSIM12', 'CITIT11', 'CITIT12', 'IWSIT11', 'IWSIT12']\n",
    "    \n",
    "    for grupo in grupos_posibles:\n",
    "        if grupo in nombre:\n",
    "            return grupo\n",
    "    \n",
    "    return None\n",
    "\n",
    "def verificar_estructura_completa(ruta_examenes=\"../data/examenes_procesados/\"):\n",
    "    \"\"\"\n",
    "    Verifica que todos los archivos sigan el formato correcto después de la estandarización\n",
    "    \"\"\"\n",
    "    ruta_examenes = Path(ruta_examenes)\n",
    "    \n",
    "    print(\"\\n🔍 VERIFICACIÓN FINAL DE FORMATO:\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    patron_correcto = re.compile(r'^.+_P[2-5]_[A-Z]+\\d+$')\n",
    "    archivos_incorrectos = []\n",
    "    \n",
    "    for carpeta_grupo in ruta_examenes.iterdir():\n",
    "        if not carpeta_grupo.is_dir() or carpeta_grupo.name in [\"eliminados\"]:\n",
    "            continue\n",
    "            \n",
    "        if carpeta_grupo.name not in [\"extraviados\", \"problemático\"]:\n",
    "            # Carpetas de grupo normales\n",
    "            for subcarpeta in carpeta_grupo.iterdir():\n",
    "                if subcarpeta.is_dir() and subcarpeta.name.startswith(\"Practica_\"):\n",
    "                    for archivo_pdf in subcarpeta.glob(\"*.pdf\"):\n",
    "                        nombre = archivo_pdf.stem\n",
    "                        if not patron_correcto.match(nombre):\n",
    "                            archivos_incorrectos.append(str(archivo_pdf.relative_to(ruta_examenes)))\n",
    "                        else:\n",
    "                            print(f\"✅ {archivo_pdf.relative_to(ruta_examenes)}\")\n",
    "        else:\n",
    "            # Carpetas especiales\n",
    "            for archivo_pdf in carpeta_grupo.glob(\"*.pdf\"):\n",
    "                nombre = archivo_pdf.stem\n",
    "                if not patron_correcto.match(nombre):\n",
    "                    archivos_incorrectos.append(str(archivo_pdf.relative_to(ruta_examenes)))\n",
    "                else:\n",
    "                    print(f\"✅ {archivo_pdf.relative_to(ruta_examenes)}\")\n",
    "    \n",
    "    if archivos_incorrectos:\n",
    "        print(f\"\\n⚠️  ARCHIVOS QUE AÚN NO SIGUEN EL FORMATO:\")\n",
    "        for archivo in archivos_incorrectos:\n",
    "            print(f\"  - {archivo}\")\n",
    "    else:\n",
    "        print(f\"\\n🎉 ¡Todos los archivos siguen el formato correcto!\")\n",
    "\n",
    "# Ejecutar la estandarización\n",
    "estandarizar_nombres_examenes()\n",
    "\n",
    "# Verificar el resultado\n",
    "#verificar_estructura_completa()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def encontrar_archivos_con_sufijo_numerico(ruta_examenes=\"../data/examenes_procesados/\"):\n",
    "    \"\"\"\n",
    "    Encuentra y lista todos los archivos que tienen sufijos numéricos (_2, _3, etc.)\n",
    "    \"\"\"\n",
    "    \n",
    "    ruta_examenes = Path(ruta_examenes)\n",
    "    \n",
    "    if not ruta_examenes.exists():\n",
    "        print(f\"❌ La ruta {ruta_examenes} no existe\")\n",
    "        return []\n",
    "    \n",
    "    # Patrón para detectar archivos con sufijo numérico\n",
    "    patron_sufijo = re.compile(r'.*_(\\d+)\\.pdf$', re.IGNORECASE)\n",
    "    \n",
    "    archivos_con_sufijo = []\n",
    "    archivos_procesados = 0\n",
    "    \n",
    "    print(\"🔍 Buscando archivos con sufijos numéricos (_N)...\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Recorrer todas las carpetas y archivos\n",
    "    for root, dirs, files in os.walk(ruta_examenes):\n",
    "        for file in files:\n",
    "            if file.lower().endswith('.pdf'):\n",
    "                archivos_procesados += 1\n",
    "                \n",
    "                # Verificar si el archivo tiene sufijo numérico\n",
    "                match = patron_sufijo.match(file)\n",
    "                if match:\n",
    "                    archivo_path = Path(root) / file\n",
    "                    sufijo_numero = int(match.group(1))\n",
    "                    \n",
    "                    info_archivo = {\n",
    "                        'ruta_completa': archivo_path,\n",
    "                        'ruta_relativa': archivo_path.relative_to(ruta_examenes),\n",
    "                        'nombre': file,\n",
    "                        'sufijo': sufijo_numero,\n",
    "                        'carpeta': archivo_path.parent.name,\n",
    "                        'tamaño': archivo_path.stat().st_size\n",
    "                    }\n",
    "                    \n",
    "                    archivos_con_sufijo.append(info_archivo)\n",
    "    \n",
    "    print(f\"\\n📊 RESUMEN:\")\n",
    "    print(f\"Total de archivos procesados: {archivos_procesados}\")\n",
    "    print(f\"Archivos con sufijo numérico encontrados: {len(archivos_con_sufijo)}\")\n",
    "    \n",
    "    if archivos_con_sufijo:\n",
    "        print(f\"\\n📁 ARCHIVOS CON SUFIJOS NUMÉRICOS:\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        # Ordenar por carpeta y luego por nombre\n",
    "        archivos_ordenados = sorted(archivos_con_sufijo, key=lambda x: (str(x['ruta_relativa'].parent), x['nombre']))\n",
    "        \n",
    "        carpeta_actual = None\n",
    "        for archivo in archivos_ordenados:\n",
    "            carpeta = str(archivo['ruta_relativa'].parent)\n",
    "            \n",
    "            # Mostrar encabezado de carpeta si cambia\n",
    "            if carpeta != carpeta_actual:\n",
    "                print(f\"\\n📂 {carpeta}\")\n",
    "                carpeta_actual = carpeta\n",
    "            \n",
    "            # Mostrar archivo con sufijo resaltado\n",
    "            nombre_sin_sufijo = archivo['nombre'].replace(f\"_{archivo['sufijo']}.pdf\", \".pdf\")\n",
    "            print(f\"   ✓ {archivo['nombre']} (sufijo: _{archivo['sufijo']})\")\n",
    "            print(f\"     → Nombre original sería: {nombre_sin_sufijo}\")\n",
    "        \n",
    "        # Estadísticas por sufijo\n",
    "        print(f\"\\n📈 ESTADÍSTICAS POR SUFIJO:\")\n",
    "        sufijos_count = {}\n",
    "        for archivo in archivos_con_sufijo:\n",
    "            sufijo = archivo['sufijo']\n",
    "            if sufijo not in sufijos_count:\n",
    "                sufijos_count[sufijo] = 0\n",
    "            sufijos_count[sufijo] += 1\n",
    "        \n",
    "        for sufijo in sorted(sufijos_count.keys()):\n",
    "            print(f\"   Sufijo _{sufijo}: {sufijos_count[sufijo]} archivos\")\n",
    "        \n",
    "        # Estadísticas por carpeta\n",
    "        print(f\"\\n📂 ESTADÍSTICAS POR CARPETA:\")\n",
    "        carpetas_count = {}\n",
    "        for archivo in archivos_con_sufijo:\n",
    "            carpeta = str(archivo['ruta_relativa'].parent)\n",
    "            if carpeta not in carpetas_count:\n",
    "                carpetas_count[carpeta] = 0\n",
    "            carpetas_count[carpeta] += 1\n",
    "        \n",
    "        for carpeta in sorted(carpetas_count.keys()):\n",
    "            print(f\"   {carpeta}: {carpetas_count[carpeta]} archivos\")\n",
    "        \n",
    "        return archivos_con_sufijo\n",
    "    else:\n",
    "        print(f\"\\n✅ No se encontraron archivos con sufijos numéricos\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Buscando archivos con sufijos numéricos (_N)...\n",
      "============================================================\n",
      "\n",
      "📊 RESUMEN:\n",
      "Total de archivos procesados: 259\n",
      "Archivos con sufijo numérico encontrados: 2\n",
      "\n",
      "📁 ARCHIVOS CON SUFIJOS NUMÉRICOS:\n",
      "================================================================================\n",
      "\n",
      "📂 IWSIM11\\Practica_5\n",
      "   ✓ MARINA_NAVARRO_PAULA_P5_IWSIM11_2.pdf (sufijo: _2)\n",
      "     → Nombre original sería: MARINA_NAVARRO_PAULA_P5_IWSIM11.pdf\n",
      "\n",
      "📂 IWSIM12\\Practica_5\n",
      "   ✓ MARINA_NAVARRO_PAULA_P5_IWSIM12_2.pdf (sufijo: _2)\n",
      "     → Nombre original sería: MARINA_NAVARRO_PAULA_P5_IWSIM12.pdf\n",
      "\n",
      "📈 ESTADÍSTICAS POR SUFIJO:\n",
      "   Sufijo _2: 2 archivos\n",
      "\n",
      "📂 ESTADÍSTICAS POR CARPETA:\n",
      "   IWSIM11\\Practica_5: 1 archivos\n",
      "   IWSIM12\\Practica_5: 1 archivos\n"
     ]
    }
   ],
   "source": [
    "# Ejecutar la búsqueda\n",
    "archivos_con_sufijo = encontrar_archivos_con_sufijo_numerico()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 RESUMEN DE ELIMINACIÓN:\n",
      "Total de archivos con sufijo: 2\n",
      "Archivos que contienen 'Paula' (se conservarán): 2\n",
      "Archivos a eliminar: 0\n",
      "\n",
      "✅ No hay archivos para eliminar\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Filtrar archivos que NO contienen 'Paula' en el nombre\n",
    "archivos_a_eliminar = [archivo for archivo in archivos_con_sufijo if 'PAULA' not in archivo['nombre'].upper()]\n",
    "\n",
    "print(f\"📊 RESUMEN DE ELIMINACIÓN:\")\n",
    "print(f\"Total de archivos con sufijo: {len(archivos_con_sufijo)}\")\n",
    "print(f\"Archivos que contienen 'Paula' (se conservarán): {len(archivos_con_sufijo) - len(archivos_a_eliminar)}\")\n",
    "print(f\"Archivos a eliminar: {len(archivos_a_eliminar)}\")\n",
    "\n",
    "if archivos_a_eliminar:\n",
    "    print(f\"\\n🗑️ ELIMINANDO ARCHIVOS:\")\n",
    "    archivos_eliminados = 0\n",
    "    errores_eliminacion = []\n",
    "    \n",
    "    for archivo in archivos_a_eliminar:\n",
    "        try:\n",
    "            archivo['ruta_completa'].unlink()  # Eliminar el archivo\n",
    "            archivos_eliminados += 1\n",
    "            print(f\"  ✅ Eliminado: {archivo['ruta_relativa']}\")\n",
    "        except Exception as e:\n",
    "            error_msg = f\"Error eliminando {archivo['ruta_relativa']}: {e}\"\n",
    "            errores_eliminacion.append(error_msg)\n",
    "            print(f\"  ❌ {error_msg}\")\n",
    "    \n",
    "    print(f\"\\n📈 RESULTADO:\")\n",
    "    print(f\"Archivos eliminados exitosamente: {archivos_eliminados}\")\n",
    "    \n",
    "    if errores_eliminacion:\n",
    "        print(f\"Errores durante la eliminación: {len(errores_eliminacion)}\")\n",
    "        for error in errores_eliminacion:\n",
    "            print(f\"  - {error}\")\n",
    "    else:\n",
    "        print(\"✅ Todos los archivos se eliminaron sin errores\")\n",
    "        \n",
    "    # Mostrar archivos conservados (con Paula)\n",
    "    archivos_conservados = [archivo for archivo in archivos_con_sufijo if 'PAULA' in archivo['nombre'].upper()]\n",
    "    if archivos_conservados:\n",
    "        print(f\"\\n💾 ARCHIVOS CONSERVADOS (contienen 'Paula'):\")\n",
    "        for archivo in archivos_conservados:\n",
    "            print(f\"  ✓ {archivo['ruta_relativa']}\")\n",
    "else:\n",
    "    print(f\"\\n✅ No hay archivos para eliminar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buscar_alumnos_practicas_2_4(ruta_examenes=\"../data/examenes_procesados/\"):\n",
    "    \"\"\"\n",
    "    Busca alumnos que han entregado prácticas 2 o 4 basándose en la estructura de carpetas\n",
    "    y nombres de archivos. Marca con * los que están en carpeta problemático.\n",
    "    \"\"\"\n",
    "    ruta_examenes = Path(ruta_examenes)\n",
    "    \n",
    "    if not ruta_examenes.exists():\n",
    "        print(f\"❌ La ruta {ruta_examenes} no existe\")\n",
    "        return []\n",
    "    \n",
    "    alumnos_practicas_2_4 = []\n",
    "    \n",
    "    print(\"🔍 Buscando entregas de prácticas 2 y 4...\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Recorrer todas las carpetas de grupos\n",
    "    for carpeta_grupo in ruta_examenes.iterdir():\n",
    "        if not carpeta_grupo.is_dir():\n",
    "            continue\n",
    "            \n",
    "        # Procesar carpetas de grupos normales\n",
    "        if carpeta_grupo.name not in [\"extraviados\", \"eliminados\"]:\n",
    "            # Si es problemático, marcar con asterisco\n",
    "            asterisco = \" *\" if carpeta_grupo.name == \"problemático\" else \"\"\n",
    "            \n",
    "            if carpeta_grupo.name == \"problemático\":\n",
    "                # En problemático, buscar directamente archivos PDF\n",
    "                for archivo_pdf in carpeta_grupo.glob(\"*.pdf\"):\n",
    "                    practica = detectar_practica_del_nombre(archivo_pdf.name)\n",
    "                    if practica in ['2', '4']:\n",
    "                        info_alumno = extraer_info_alumno(archivo_pdf, practica, \"problemático\", True)\n",
    "                        if info_alumno:\n",
    "                            alumnos_practicas_2_4.append(info_alumno)\n",
    "            else:\n",
    "                # Buscar en subcarpetas de prácticas\n",
    "                for subcarpeta in carpeta_grupo.iterdir():\n",
    "                    if subcarpeta.is_dir() and subcarpeta.name.startswith(\"Practica_\"):\n",
    "                        practica_num = subcarpeta.name.replace(\"Practica_\", \"\")\n",
    "                        \n",
    "                        if practica_num in ['2', '4']:\n",
    "                            print(f\"📂 Encontrada {subcarpeta.name} en grupo {carpeta_grupo.name}\")\n",
    "                            \n",
    "                            for archivo_pdf in subcarpeta.glob(\"*.pdf\"):\n",
    "                                info_alumno = extraer_info_alumno(archivo_pdf, practica_num, carpeta_grupo.name, False)\n",
    "                                if info_alumno:\n",
    "                                    alumnos_practicas_2_4.append(info_alumno)\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(f\"📊 RESUMEN: Encontrados {len(alumnos_practicas_2_4)} alumnos con prácticas 2 o 4\")\n",
    "    \n",
    "    if alumnos_practicas_2_4:\n",
    "        # Organizar por grupo y práctica\n",
    "        por_grupo_practica = {}\n",
    "        \n",
    "        for alumno in alumnos_practicas_2_4:\n",
    "            grupo = alumno['grupo']\n",
    "            practica = alumno['practica']\n",
    "            key = f\"{grupo}_P{practica}\"\n",
    "            \n",
    "            if key not in por_grupo_practica:\n",
    "                por_grupo_practica[key] = []\n",
    "            por_grupo_practica[key].append(alumno)\n",
    "        \n",
    "        print(f\"\\n📋 LISTADO POR GRUPO Y PRÁCTICA:\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        for key in sorted(por_grupo_practica.keys()):\n",
    "            grupo, practica_info = key.split('_P')\n",
    "            asterisco = \" *\" if any(a['problematico'] for a in por_grupo_practica[key]) else \"\"\n",
    "            \n",
    "            print(f\"\\n📚 GRUPO {grupo} - PRÁCTICA {practica_info}{asterisco}\")\n",
    "            print(\"-\" * 40)\n",
    "            \n",
    "            for alumno in sorted(por_grupo_practica[key], key=lambda x: (x['apellidos'], x['nombre'])):\n",
    "                asterisco_individual = \" *\" if alumno['problematico'] else \"\"\n",
    "                print(f\"  • {alumno['apellidos']}, {alumno['nombre']}{asterisco_individual}\")\n",
    "    \n",
    "    return alumnos_practicas_2_4\n",
    "\n",
    "def extraer_info_alumno(archivo_pdf, practica, grupo, es_problematico):\n",
    "    \"\"\"Extrae información del alumno desde el nombre del archivo\"\"\"\n",
    "    nombre_archivo = archivo_pdf.stem\n",
    "    \n",
    "    # Limpiar el nombre del archivo para extraer apellidos y nombre\n",
    "    nombre_limpio = nombre_archivo\n",
    "    \n",
    "    # Remover elementos conocidos (práctica, grupo, etc.)\n",
    "    patrones_a_remover = [\n",
    "        rf'_P{practica}', rf'P{practica}_', rf'P{practica}$',\n",
    "        rf'_{grupo}', rf'{grupo}_', rf'^{grupo}',\n",
    "        r'_CITIM\\d+', r'_IWSIM\\d+', r'_CITIT\\d+', r'_IWSIT\\d+',\n",
    "        r'CITIM\\d+_', r'IWSIM\\d+_', r'CITIT\\d+_', r'IWSIT\\d+_',\n",
    "        r'_\\d+$'  # Números al final\n",
    "    ]\n",
    "    \n",
    "    for patron in patrones_a_remover:\n",
    "        nombre_limpio = re.sub(patron, '', nombre_limpio, flags=re.IGNORECASE)\n",
    "    \n",
    "    # Limpiar guiones bajos múltiples\n",
    "    nombre_limpio = re.sub(r'_+', '_', nombre_limpio).strip('_')\n",
    "    \n",
    "    # Separar apellidos y nombre\n",
    "    partes = nombre_limpio.split('_')\n",
    "    \n",
    "    if len(partes) >= 2:\n",
    "        # Asumir que la última parte es el nombre y el resto apellidos\n",
    "        apellidos = '_'.join(partes[:-1]).replace('_', ' ')\n",
    "        nombre = partes[-1]\n",
    "    elif len(partes) == 1:\n",
    "        apellidos = partes[0]\n",
    "        nombre = ''\n",
    "    else:\n",
    "        apellidos = nombre_archivo\n",
    "        nombre = ''\n",
    "    \n",
    "    return {\n",
    "        'archivo': archivo_pdf.name,\n",
    "        'apellidos': apellidos,\n",
    "        'nombre': nombre,\n",
    "        'practica': practica,\n",
    "        'grupo': grupo,\n",
    "        'problematico': es_problematico\n",
    "    }\n",
    "\n",
    "def detectar_practica_del_nombre(nombre_archivo):\n",
    "    \"\"\"Detecta el número de práctica del nombre del archivo\"\"\"\n",
    "    nombre = nombre_archivo.upper()\n",
    "    \n",
    "    # Buscar patrones de práctica\n",
    "    patrones = [\n",
    "        r'P(\\d)',\n",
    "        r'_(\\d)_',\n",
    "        r'PRACTICA_?(\\d)',\n",
    "    ]\n",
    "    \n",
    "    for patron in patrones:\n",
    "        match = re.search(patron, nombre)\n",
    "        if match:\n",
    "            return match.group(1)\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buscar a Hernandez Garnacho Jose Angel en el DataFrame\n",
    "#busqueda = df_con_practicas_y_examenes[\n",
    "#    (df_con_practicas_y_examenes['Apellido(s)'].str.contains('FUERIS FRUTOS', case=False, na=False)) &\n",
    "#    (df_con_practicas_y_examenes['Nombre'].str.contains('MANUEL', case=False, na=False))\n",
    "#]\n",
    "#print(\"Resultados de búsqueda para Hernandez Garnacho Jose Angel:\")\n",
    "#print(busqueda[['Nombre', 'Apellido(s)', 'Grupos']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#alumnos_con_practicas_2_4 = buscar_alumnos_practicas_2_4()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraer_info_alumno_citit(archivo_pdf, practica, grupo, es_problematico):\n",
    "    \"\"\"\n",
    "    Extrae información del alumno desde el nombre del archivo para grupos CITIT/IWSIT\n",
    "    \"\"\"\n",
    "    nombre_archivo = archivo_pdf.stem\n",
    "    \n",
    "    # Limpiar el nombre del archivo para extraer apellidos y nombre\n",
    "    nombre_limpio = nombre_archivo\n",
    "    \n",
    "    # Remover elementos conocidos (práctica, grupo, etc.)\n",
    "    patrones_a_remover = [\n",
    "        rf'_P{practica}', rf'P{practica}_', rf'P{practica}$',\n",
    "        rf'_{grupo}', rf'{grupo}_', rf'^{grupo}',\n",
    "        r'_CITIT\\d+', r'_IWSIT\\d+', r'_CITIM\\d+', r'_IWSIM\\d+',\n",
    "        r'CITIT\\d+_', r'IWSIT\\d+_', r'CITIM\\d+_', r'IWSIM\\d+_',\n",
    "        r'_\\d+$'  # Números al final\n",
    "    ]\n",
    "    \n",
    "    for patron in patrones_a_remover:\n",
    "        nombre_limpio = re.sub(patron, '', nombre_limpio, flags=re.IGNORECASE)\n",
    "    \n",
    "    # Limpiar guiones bajos múltiples\n",
    "    nombre_limpio = re.sub(r'_+', '_', nombre_limpio).strip('_')\n",
    "    \n",
    "    # Separar apellidos y nombre\n",
    "    partes = nombre_limpio.split('_')\n",
    "    \n",
    "    if len(partes) >= 2:\n",
    "        # Asumir que la última parte es el nombre y el resto apellidos\n",
    "        apellidos = '_'.join(partes[:-1]).replace('_', ' ')\n",
    "        nombre = partes[-1]\n",
    "    elif len(partes) == 1:\n",
    "        apellidos = partes[0]\n",
    "        nombre = ''\n",
    "    else:\n",
    "        apellidos = nombre_archivo\n",
    "        nombre = ''\n",
    "    \n",
    "    return {\n",
    "        'archivo': archivo_pdf.name,\n",
    "        'apellidos': apellidos,\n",
    "        'nombre': nombre,\n",
    "        'practica': practica,\n",
    "        'grupo': grupo,\n",
    "        'problematico': es_problematico\n",
    "    }\n",
    "\n",
    "def buscar_alumnos_grupos_citit_iwsit(ruta_examenes=\"../data/examenes_procesados/\"):\n",
    "    \"\"\"\n",
    "    Busca alumnos de los grupos CITIT11, CITIT12, IWSIT11, IWSIT12 clasificados por práctica.\n",
    "    Verifica el grupo correcto consultando el DataFrame de alumnos.\n",
    "    \"\"\"\n",
    "    ruta_examenes = Path(ruta_examenes)\n",
    "    \n",
    "    if not ruta_examenes.exists():\n",
    "        print(f\"La ruta {ruta_examenes} no existe\")\n",
    "        return []\n",
    "    \n",
    "    # Grupos objetivo\n",
    "    grupos_objetivo = ['CITIT11', 'CITIT12', 'IWSIT11', 'IWSIT12']\n",
    "    alumnos_encontrados = []\n",
    "    \n",
    "    print(\"Buscando alumnos de grupos CITIT/IWSIT...\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Recorrer todas las carpetas de grupos\n",
    "    for carpeta_grupo in ruta_examenes.iterdir():\n",
    "        if not carpeta_grupo.is_dir():\n",
    "            continue\n",
    "            \n",
    "        # Verificar si es uno de los grupos objetivo O carpeta problemático\n",
    "        es_grupo_objetivo = carpeta_grupo.name in grupos_objetivo\n",
    "        es_problematico = carpeta_grupo.name == \"problemático\"\n",
    "        \n",
    "        if es_grupo_objetivo or es_problematico:\n",
    "            print(f\"\\nProcesando carpeta: {carpeta_grupo.name}\")\n",
    "            \n",
    "            if es_problematico:\n",
    "                # En problemático, buscar directamente archivos PDF y verificar si son de grupos objetivo\n",
    "                for archivo_pdf in carpeta_grupo.glob(\"*.pdf\"):\n",
    "                    grupo_detectado = detectar_grupo_del_nombre(archivo_pdf.name)\n",
    "                    practica = detectar_practica_del_nombre(archivo_pdf.name)\n",
    "                    if practica:\n",
    "                        info_alumno = extraer_info_alumno_citit(archivo_pdf, practica, grupo_detectado or carpeta_grupo.name, True)\n",
    "                        if info_alumno:\n",
    "                            # Verificar grupo real en el DataFrame\n",
    "                            grupo_real = verificar_grupo_en_dataframe(info_alumno['apellidos'], info_alumno['nombre'])\n",
    "                            if grupo_real in grupos_objetivo:\n",
    "                                info_alumno['grupo_real'] = grupo_real\n",
    "                                info_alumno['grupo_carpeta'] = carpeta_grupo.name\n",
    "                                alumnos_encontrados.append(info_alumno)\n",
    "                                print(f\"    {info_alumno['apellidos']}, {info_alumno['nombre']} (P{practica}, {grupo_real}) *\")\n",
    "            else:\n",
    "                # Buscar en subcarpetas de prácticas\n",
    "                for subcarpeta in carpeta_grupo.iterdir():\n",
    "                    if subcarpeta.is_dir() and subcarpeta.name.startswith(\"Practica_\"):\n",
    "                        practica_num = subcarpeta.name.replace(\"Practica_\", \"\")\n",
    "                        print(f\"  {subcarpeta.name}\")\n",
    "                        \n",
    "                        for archivo_pdf in subcarpeta.glob(\"*.pdf\"):\n",
    "                            info_alumno = extraer_info_alumno_citit(archivo_pdf, practica_num, carpeta_grupo.name, False)\n",
    "                            if info_alumno:\n",
    "                                # Verificar grupo real en el DataFrame\n",
    "                                grupo_real = verificar_grupo_en_dataframe(info_alumno['apellidos'], info_alumno['nombre'])\n",
    "                                if grupo_real in grupos_objetivo:\n",
    "                                    info_alumno['grupo_real'] = grupo_real\n",
    "                                    info_alumno['grupo_carpeta'] = carpeta_grupo.name\n",
    "                                    alumnos_encontrados.append(info_alumno)\n",
    "                                    \n",
    "                                    # Mostrar advertencia si el grupo de carpeta no coincide con el real\n",
    "                                    if grupo_real != carpeta_grupo.name:\n",
    "                                        print(f\"    {info_alumno['apellidos']}, {info_alumno['nombre']} (Grupo real: {grupo_real}, Carpeta: {carpeta_grupo.name}) ⚠️\")\n",
    "                                    else:\n",
    "                                        print(f\"    {info_alumno['apellidos']}, {info_alumno['nombre']}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(f\"RESUMEN: Encontrados {len(alumnos_encontrados)} alumnos de grupos CITIT/IWSIT\")\n",
    "    \n",
    "    if alumnos_encontrados:\n",
    "        # Organizar por práctica y luego por grupo REAL\n",
    "        por_practica = {}\n",
    "        \n",
    "        for alumno in alumnos_encontrados:\n",
    "            practica = alumno['practica']\n",
    "            if practica not in por_practica:\n",
    "                por_practica[practica] = {}\n",
    "            \n",
    "            grupo = alumno['grupo_real']  # Usar grupo real del DataFrame\n",
    "            if grupo not in por_practica[practica]:\n",
    "                por_practica[practica][grupo] = []\n",
    "            \n",
    "            por_practica[practica][grupo].append(alumno)\n",
    "        \n",
    "        print(f\"\\nLISTADO SEPARADO EN DOS LISTAS:\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        # Ordenar por número de práctica\n",
    "        for practica in sorted(por_practica.keys(), key=lambda x: int(x) if x.isdigit() else 999):\n",
    "            print(f\"\\nPractica {practica}:\")\n",
    "            print(\"-\" * 50)\n",
    "            \n",
    "            # Ordenar grupos alfabéticamente\n",
    "            for grupo in sorted(por_practica[practica].keys()):\n",
    "                alumnos_grupo = por_practica[practica][grupo]\n",
    "                \n",
    "                # Separar en problemáticos y normales\n",
    "                alumnos_normales = [alumno for alumno in alumnos_grupo if not alumno['problematico']]\n",
    "                alumnos_problematicos = [alumno for alumno in alumnos_grupo if alumno['problematico']]\n",
    "                \n",
    "                print(f\"\\nGrupo {grupo}:\")\n",
    "                \n",
    "                # Lista de alumnos normales\n",
    "                if alumnos_normales:\n",
    "                    print(\"  Alumnos normales:\")\n",
    "                    for alumno in sorted(alumnos_normales, key=lambda x: (x['apellidos'], x['nombre'])):\n",
    "                        print(f\"    {alumno['apellidos']}, {alumno['nombre']}\")\n",
    "                \n",
    "                # Lista de alumnos problemáticos (dentro del mismo grupo)\n",
    "                if alumnos_problematicos:\n",
    "                    print(\"  Alumnos problemáticos:\")\n",
    "                    for alumno in sorted(alumnos_problematicos, key=lambda x: (x['apellidos'], x['nombre'])):\n",
    "                        print(f\"    {alumno['apellidos']}, {alumno['nombre']} *\")\n",
    "        \n",
    "        print(f\"\\n\" + \"-\" * 40)\n",
    "        print(f\"RESUMEN POR GRUPO:\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        resumen_grupos = {}\n",
    "        for alumno in alumnos_encontrados:\n",
    "            grupo = alumno['grupo_real']  # Usar grupo real\n",
    "            if grupo not in resumen_grupos:\n",
    "                resumen_grupos[grupo] = {'total': 0, 'problematicos': 0}\n",
    "            resumen_grupos[grupo]['total'] += 1\n",
    "            if alumno['problematico']:\n",
    "                resumen_grupos[grupo]['problematicos'] += 1\n",
    "        \n",
    "        for grupo in sorted(resumen_grupos.keys()):\n",
    "            total = resumen_grupos[grupo]['total']\n",
    "            problematicos = resumen_grupos[grupo]['problematicos']\n",
    "            print(f\"  {grupo}: {total} alumnos (problemáticos: {problematicos})\")\n",
    "    \n",
    "    return alumnos_encontrados\n",
    "\n",
    "def verificar_grupo_en_dataframe(apellidos, nombre):\n",
    "    \"\"\"\n",
    "    Verifica el grupo real del alumno consultando el DataFrame df_con_practicas_y_examenes\n",
    "    \"\"\"\n",
    "    if 'df_con_practicas_y_examenes' not in globals():\n",
    "        print(\"⚠️ DataFrame df_con_practicas_y_examenes no está disponible\")\n",
    "        return \"GRUPO_NO_ENCONTRADO\"\n",
    "    \n",
    "    apellidos_limpio = apellidos.upper().strip()\n",
    "    nombre_limpio = nombre.upper().strip()\n",
    "    \n",
    "    # Buscar coincidencia exacta primero\n",
    "    mask_exacta = (df_con_practicas_y_examenes['Apellido(s)'].str.upper().str.strip() == apellidos_limpio) & \\\n",
    "                  (df_con_practicas_y_examenes['Nombre'].str.upper().str.strip() == nombre_limpio)\n",
    "    \n",
    "    if mask_exacta.any():\n",
    "        return df_con_practicas_y_examenes.loc[mask_exacta, 'Grupos'].iloc[0]\n",
    "    \n",
    "    # Si no hay coincidencia exacta, buscar coincidencia parcial\n",
    "    if apellidos_limpio and nombre_limpio:\n",
    "        mask_parcial = df_con_practicas_y_examenes['Apellido(s)'].str.upper().str.contains(apellidos_limpio[:5], na=False) & \\\n",
    "                       df_con_practicas_y_examenes['Nombre'].str.upper().str.contains(nombre_limpio[:3], na=False)\n",
    "        \n",
    "        if mask_parcial.any():\n",
    "            return df_con_practicas_y_examenes.loc[mask_parcial, 'Grupos'].iloc[0]\n",
    "    \n",
    "    return \"GRUPO_NO_ENCONTRADO\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buscar_alumnos_grupos_citit_iwsit(ruta_examenes=\"../data/examenes_procesados/\"):\n",
    "    \"\"\"\n",
    "    Busca alumnos de los grupos CITIT11, CITIT12, IWSIT11, IWSIT12 clasificados por práctica.\n",
    "    Verifica el grupo correcto consultando el DataFrame de alumnos.\n",
    "    \"\"\"\n",
    "    ruta_examenes = Path(ruta_examenes)\n",
    "    \n",
    "    if not ruta_examenes.exists():\n",
    "        print(f\"La ruta {ruta_examenes} no existe\")\n",
    "        return []\n",
    "    \n",
    "    # Grupos objetivo\n",
    "    grupos_objetivo = ['CITIT11', 'CITIT12', 'IWSIT11', 'IWSIT12']\n",
    "    alumnos_encontrados = []\n",
    "    \n",
    "    print(\"Buscando alumnos de grupos CITIT/IWSIT...\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Recorrer todas las carpetas de grupos\n",
    "    for carpeta_grupo in ruta_examenes.iterdir():\n",
    "        if not carpeta_grupo.is_dir():\n",
    "            continue\n",
    "            \n",
    "        # Verificar si es uno de los grupos objetivo O carpeta problemático\n",
    "        es_grupo_objetivo = carpeta_grupo.name in grupos_objetivo\n",
    "        es_problematico = carpeta_grupo.name == \"problemático\"\n",
    "        \n",
    "        if es_grupo_objetivo or es_problematico:\n",
    "            print(f\"\\nProcesando carpeta: {carpeta_grupo.name}\")\n",
    "            \n",
    "            if es_problematico:\n",
    "                # En problemático, buscar directamente archivos PDF y verificar si son de grupos objetivo\n",
    "                for archivo_pdf in carpeta_grupo.glob(\"*.pdf\"):\n",
    "                    grupo_detectado = detectar_grupo_del_nombre(archivo_pdf.name)\n",
    "                    practica = detectar_practica_del_nombre(archivo_pdf.name)\n",
    "                    if practica:\n",
    "                        info_alumno = extraer_info_alumno_citit(archivo_pdf, practica, grupo_detectado or carpeta_grupo.name, True)\n",
    "                        if info_alumno:\n",
    "                            # Verificar grupo real en el DataFrame\n",
    "                            grupo_real = verificar_grupo_en_dataframe(info_alumno['apellidos'], info_alumno['nombre'])\n",
    "                            if grupo_real in grupos_objetivo:\n",
    "                                info_alumno['grupo_real'] = grupo_real\n",
    "                                info_alumno['grupo_carpeta'] = carpeta_grupo.name\n",
    "                                alumnos_encontrados.append(info_alumno)\n",
    "                                print(f\"    {info_alumno['apellidos']}, {info_alumno['nombre']} (P{practica}, {grupo_real}) *\")\n",
    "            else:\n",
    "                # Buscar en subcarpetas de prácticas\n",
    "                for subcarpeta in carpeta_grupo.iterdir():\n",
    "                    if subcarpeta.is_dir() and subcarpeta.name.startswith(\"Practica_\"):\n",
    "                        practica_num = subcarpeta.name.replace(\"Practica_\", \"\")\n",
    "                        print(f\"  {subcarpeta.name}\")\n",
    "                        \n",
    "                        for archivo_pdf in subcarpeta.glob(\"*.pdf\"):\n",
    "                            info_alumno = extraer_info_alumno_citit(archivo_pdf, practica_num, carpeta_grupo.name, False)\n",
    "                            if info_alumno:\n",
    "                                # Verificar grupo real en el DataFrame\n",
    "                                grupo_real = verificar_grupo_en_dataframe(info_alumno['apellidos'], info_alumno['nombre'])\n",
    "                                if grupo_real in grupos_objetivo:\n",
    "                                    info_alumno['grupo_real'] = grupo_real\n",
    "                                    info_alumno['grupo_carpeta'] = carpeta_grupo.name\n",
    "                                    alumnos_encontrados.append(info_alumno)\n",
    "                                    \n",
    "                                    # Mostrar advertencia si el grupo de carpeta no coincide con el real\n",
    "                                    if grupo_real != carpeta_grupo.name:\n",
    "                                        print(f\"    {info_alumno['apellidos']}, {info_alumno['nombre']} (Grupo real: {grupo_real}, Carpeta: {carpeta_grupo.name}) ⚠️\")\n",
    "                                    else:\n",
    "                                        print(f\"    {info_alumno['apellidos']}, {info_alumno['nombre']}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(f\"RESUMEN: Encontrados {len(alumnos_encontrados)} alumnos de grupos CITIT/IWSIT\")\n",
    "    \n",
    "    if alumnos_encontrados:\n",
    "        # Organizar por práctica y luego por grupo REAL\n",
    "        por_practica = {}\n",
    "        \n",
    "        for alumno in alumnos_encontrados:\n",
    "            practica = alumno['practica']\n",
    "            if practica not in por_practica:\n",
    "                por_practica[practica] = {}\n",
    "            \n",
    "            grupo = alumno['grupo_real']  # Usar grupo real del DataFrame\n",
    "            if grupo not in por_practica[practica]:\n",
    "                por_practica[practica][grupo] = []\n",
    "            \n",
    "            por_practica[practica][grupo].append(alumno)\n",
    "        \n",
    "        print(f\"\\nLISTADO SEPARADO EN DOS LISTAS:\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        # Ordenar por número de práctica\n",
    "        for practica in sorted(por_practica.keys(), key=lambda x: int(x) if x.isdigit() else 999):\n",
    "            print(f\"\\nPractica {practica}:\")\n",
    "            print(\"-\" * 50)\n",
    "            \n",
    "            # Ordenar grupos alfabéticamente\n",
    "            for grupo in sorted(por_practica[practica].keys()):\n",
    "                alumnos_grupo = por_practica[practica][grupo]\n",
    "                \n",
    "                # Separar en problemáticos y normales\n",
    "                alumnos_normales = [alumno for alumno in alumnos_grupo if not alumno['problematico']]\n",
    "                alumnos_problematicos = [alumno for alumno in alumnos_grupo if alumno['problematico']]\n",
    "                \n",
    "                print(f\"\\nGrupo {grupo}:\")\n",
    "                \n",
    "                # Lista de alumnos normales\n",
    "                if alumnos_normales:\n",
    "                    print(\"  Alumnos normales:\")\n",
    "                    for alumno in sorted(alumnos_normales, key=lambda x: (x['apellidos'], x['nombre'])):\n",
    "                        print(f\"    {alumno['apellidos']}, {alumno['nombre']}\")\n",
    "                \n",
    "                # Lista de alumnos problemáticos (dentro del mismo grupo)\n",
    "                if alumnos_problematicos:\n",
    "                    print(\"  Alumnos problemáticos:\")\n",
    "                    for alumno in sorted(alumnos_problematicos, key=lambda x: (x['apellidos'], x['nombre'])):\n",
    "                        print(f\"    {alumno['apellidos']}, {alumno['nombre']} *\")\n",
    "        \n",
    "        print(f\"\\n\" + \"-\" * 40)\n",
    "        print(f\"RESUMEN POR GRUPO:\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        resumen_grupos = {}\n",
    "        for alumno in alumnos_encontrados:\n",
    "            grupo = alumno['grupo_real']  # Usar grupo real\n",
    "            if grupo not in resumen_grupos:\n",
    "                resumen_grupos[grupo] = {'total': 0, 'problematicos': 0}\n",
    "            resumen_grupos[grupo]['total'] += 1\n",
    "            if alumno['problematico']:\n",
    "                resumen_grupos[grupo]['problematicos'] += 1\n",
    "        \n",
    "        for grupo in sorted(resumen_grupos.keys()):\n",
    "            total = resumen_grupos[grupo]['total']\n",
    "            problematicos = resumen_grupos[grupo]['problematicos']\n",
    "            print(f\"  {grupo}: {total} alumnos (problemáticos: {problematicos})\")\n",
    "    \n",
    "    return alumnos_encontrados\n",
    "\n",
    "def verificar_grupo_en_dataframe(apellidos, nombre):\n",
    "    \"\"\"\n",
    "    Verifica el grupo real del alumno consultando el DataFrame df_con_practicas_y_examenes\n",
    "    \"\"\"\n",
    "    if 'df_con_practicas_y_examenes' not in globals():\n",
    "        print(\"⚠️ DataFrame df_con_practicas_y_examenes no está disponible\")\n",
    "        return \"GRUPO_NO_ENCONTRADO\"\n",
    "    \n",
    "    apellidos_limpio = apellidos.upper().strip()\n",
    "    nombre_limpio = nombre.upper().strip()\n",
    "    \n",
    "    # Buscar coincidencia exacta primero\n",
    "    mask_exacta = (df_con_practicas_y_examenes['Apellido(s)'].str.upper().str.strip() == apellidos_limpio) & \\\n",
    "                  (df_con_practicas_y_examenes['Nombre'].str.upper().str.strip() == nombre_limpio)\n",
    "    \n",
    "    if mask_exacta.any():\n",
    "        return df_con_practicas_y_examenes.loc[mask_exacta, 'Grupos'].iloc[0]\n",
    "    \n",
    "    # Si no hay coincidencia exacta, buscar coincidencia parcial\n",
    "    if apellidos_limpio and nombre_limpio:\n",
    "        mask_parcial = df_con_practicas_y_examenes['Apellido(s)'].str.upper().str.contains(apellidos_limpio[:5], na=False) & \\\n",
    "                       df_con_practicas_y_examenes['Nombre'].str.upper().str.contains(nombre_limpio[:3], na=False)\n",
    "        \n",
    "        if mask_parcial.any():\n",
    "            return df_con_practicas_y_examenes.loc[mask_parcial, 'Grupos'].iloc[0]\n",
    "    \n",
    "    return \"GRUPO_NO_ENCONTRADO\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Ejecutar la búsqueda\n",
    "#alumnos_citit_iwsit = buscar_alumnos_grupos_citit_iwsit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import re\n",
    "from pypdf import PdfReader\n",
    "import hashlib\n",
    "\n",
    "def buscar_origen_lote(nombre_archivo_objetivo, ruta_lotes=\"../data/raw/\", ruta_examenes=\"../data/examenes_procesados/\"):\n",
    "    \"\"\"\n",
    "    Busca de qué lote proviene un archivo específico comparando contenido de PDFs\n",
    "    \"\"\"\n",
    "    \n",
    "    # Buscar el archivo objetivo en examenes_procesados\n",
    "    archivo_objetivo = None\n",
    "    ruta_examenes = Path(ruta_examenes)\n",
    "    \n",
    "    for root, dirs, files in os.walk(ruta_examenes):\n",
    "        for file in files:\n",
    "            if nombre_archivo_objetivo.lower() in file.lower():\n",
    "                archivo_objetivo = Path(root) / file\n",
    "                break\n",
    "        if archivo_objetivo:\n",
    "            break\n",
    "    \n",
    "    if not archivo_objetivo or not archivo_objetivo.exists():\n",
    "        print(f\"❌ No se encontró el archivo {nombre_archivo_objetivo} en examenes_procesados\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"🎯 Archivo encontrado: {archivo_objetivo}\")\n",
    "    \n",
    "    # Leer el contenido del archivo objetivo para comparar\n",
    "    try:\n",
    "        reader_objetivo = PdfReader(archivo_objetivo)\n",
    "        contenido_objetivo = \"\"\n",
    "        for page in reader_objetivo.pages:\n",
    "            contenido_objetivo += page.extract_text()\n",
    "        \n",
    "        # Hash del contenido para comparación rápida\n",
    "        hash_objetivo = hashlib.md5(contenido_objetivo.encode()).hexdigest()\n",
    "        print(f\"📝 Hash del archivo objetivo: {hash_objetivo[:16]}...\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error leyendo archivo objetivo: {e}\")\n",
    "        return None\n",
    "    \n",
    "    # Buscar en todos los lotes\n",
    "    ruta_lotes = Path(ruta_lotes)\n",
    "    if not ruta_lotes.exists():\n",
    "        print(f\"❌ La ruta de lotes {ruta_lotes} no existe\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"\\n🔍 Buscando en lotes de {ruta_lotes}...\")\n",
    "    \n",
    "    lotes_encontrados = []\n",
    "    \n",
    "    for archivo_lote in ruta_lotes.glob(\"*.pdf\"):\n",
    "        print(f\"  📄 Revisando {archivo_lote.name}...\")\n",
    "        \n",
    "        try:\n",
    "            reader_lote = PdfReader(archivo_lote)\n",
    "            num_paginas = len(reader_lote.pages)\n",
    "            \n",
    "            # Revisar cada página del lote\n",
    "            for i in range(num_paginas):\n",
    "                try:\n",
    "                    page = reader_lote.pages[i]\n",
    "                    contenido_pagina = page.extract_text()\n",
    "                    hash_pagina = hashlib.md5(contenido_pagina.encode()).hexdigest()\n",
    "                    \n",
    "                    # Comparar hashes\n",
    "                    if hash_pagina == hash_objetivo:\n",
    "                        lotes_encontrados.append({\n",
    "                            'lote': archivo_lote.name,\n",
    "                            'pagina': i + 1,\n",
    "                            'total_paginas': num_paginas,\n",
    "                            'coincidencia': 'exacta'\n",
    "                        })\n",
    "                        print(f\"    ✅ COINCIDENCIA EXACTA: Página {i + 1} de {num_paginas}\")\n",
    "                    \n",
    "                    # También buscar coincidencias parciales por texto clave\n",
    "                    elif buscar_coincidencias_texto(contenido_pagina, contenido_objetivo):\n",
    "                        lotes_encontrados.append({\n",
    "                            'lote': archivo_lote.name,\n",
    "                            'pagina': i + 1,\n",
    "                            'total_paginas': num_paginas,\n",
    "                            'coincidencia': 'parcial'\n",
    "                        })\n",
    "                        print(f\"    🔍 Coincidencia parcial: Página {i + 1} de {num_paginas}\")\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    print(f\"    ⚠️ Error leyendo página {i + 1}: {e}\")\n",
    "                    continue\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"    ❌ Error leyendo lote {archivo_lote.name}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    # Mostrar resultados\n",
    "    print(f\"\\n\" + \"=\"*60)\n",
    "    print(f\"📊 RESULTADOS PARA: {nombre_archivo_objetivo}\")\n",
    "    print(f\"=\"*60)\n",
    "    \n",
    "    if lotes_encontrados:\n",
    "        print(f\"🎉 Encontradas {len(lotes_encontrados)} coincidencias:\")\n",
    "        \n",
    "        for coincidencia in lotes_encontrados:\n",
    "            tipo_icono = \"🎯\" if coincidencia['coincidencia'] == 'exacta' else \"🔍\"\n",
    "            print(f\"\\n{tipo_icono} LOTE: {coincidencia['lote']}\")\n",
    "            print(f\"   📍 Página: {coincidencia['pagina']} de {coincidencia['total_paginas']}\")\n",
    "            print(f\"   📝 Tipo: {coincidencia['coincidencia']}\")\n",
    "            \n",
    "            # Calcular posición aproximada en el examen\n",
    "            if coincidencia['pagina'] % 2 == 1:  # Página impar\n",
    "                examen_num = (coincidencia['pagina'] + 1) // 2\n",
    "                print(f\"   📄 Probablemente examen #{examen_num} (página 1)\")\n",
    "            else:  # Página par\n",
    "                examen_num = coincidencia['pagina'] // 2\n",
    "                print(f\"   📄 Probablemente examen #{examen_num} (página 2)\")\n",
    "                \n",
    "        return lotes_encontrados\n",
    "    else:\n",
    "        print(\"❌ No se encontraron coincidencias en ningún lote\")\n",
    "        print(\"\\n💡 Posibles causas:\")\n",
    "        print(\"   - El archivo fue modificado después de la extracción\")\n",
    "        print(\"   - El archivo proviene de una fuente diferente\")\n",
    "        print(\"   - Error en la comparación de contenido\")\n",
    "        return None\n",
    "\n",
    "def buscar_coincidencias_texto(texto1, texto2):\n",
    "    \"\"\"Busca coincidencias parciales entre dos textos\"\"\"\n",
    "    # Limpiar y normalizar textos\n",
    "    texto1_limpio = re.sub(r'\\s+', ' ', texto1.upper().strip())\n",
    "    texto2_limpio = re.sub(r'\\s+', ' ', texto2.upper().strip())\n",
    "    \n",
    "    # Buscar fragmentos comunes significativos\n",
    "    palabras1 = set(texto1_limpio.split())\n",
    "    palabras2 = set(texto2_limpio.split())\n",
    "    \n",
    "    # Calcular similitud (Jaccard)\n",
    "    interseccion = len(palabras1.intersection(palabras2))\n",
    "    union = len(palabras1.union(palabras2))\n",
    "    \n",
    "    if union == 0:\n",
    "        return False\n",
    "    \n",
    "    similitud = interseccion / union\n",
    "    return similitud > 0.7  # 70% de similitud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image, ImageChops\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from pathlib import Path\n",
    "from pdf2image import convert_from_path\n",
    "from pypdf import PdfReader\n",
    "\n",
    "def comparar_pdfs_visuales_con_tqdm(nombre_archivo_objetivo, ruta_saved=\"../data/saved/\", ruta_lotes=\"../data/raw/\", \n",
    "                                   mostrar_detalles=False, parar_en_100=False):\n",
    "    \"\"\"\n",
    "    Compara un archivo objetivo con los archivos en /saved y los lotes originales\n",
    "    usando comparación visual y número de páginas con tqdm y mostrando TOP 3 similitudes.\n",
    "    \n",
    "    Args:\n",
    "        mostrar_detalles: Si True, muestra prints detallados. Si False, solo muestra tqdm y resultados.\n",
    "        parar_en_100: Si True, para la búsqueda al encontrar 100% similitud.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Buscar el archivo objetivo en examenes_procesados\n",
    "    archivo_objetivo = None\n",
    "    ruta_examenes = Path(\"../data/examenes_procesados/\")\n",
    "    \n",
    "    for root, dirs, files in os.walk(ruta_examenes):\n",
    "        for file in files:\n",
    "            if nombre_archivo_objetivo.lower() in file.lower():\n",
    "                archivo_objetivo = Path(root) / file\n",
    "                break\n",
    "        if archivo_objetivo:\n",
    "            break\n",
    "    \n",
    "    if not archivo_objetivo or not archivo_objetivo.exists():\n",
    "        print(f\"❌ No se encontró el archivo {nombre_archivo_objetivo} en examenes_procesados\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"🎯 Archivo encontrado: {archivo_objetivo}\")\n",
    "    \n",
    "    # Obtener número de páginas del objetivo\n",
    "    try:\n",
    "        reader_objetivo = PdfReader(archivo_objetivo)\n",
    "        num_paginas_objetivo = len(reader_objetivo.pages)\n",
    "        print(f\"📄 Páginas del archivo objetivo: {num_paginas_objetivo}\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error leyendo archivo objetivo: {e}\")\n",
    "        return None\n",
    "    \n",
    "    # Convertir páginas del objetivo a imágenes para comparación\n",
    "    print(f\"🖼️ Convirtiendo archivo objetivo a imágenes...\")\n",
    "    try:\n",
    "        imagenes_objetivo = convert_from_path(\n",
    "            archivo_objetivo, \n",
    "            dpi=100,\n",
    "            fmt='jpeg'\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error convirtiendo archivo objetivo: {e}\")\n",
    "        return None\n",
    "    \n",
    "    # Listas para almacenar similitudes y TOP 3 actuales\n",
    "    todas_las_similitudes = []\n",
    "    todas_las_similitudes_lotes = []\n",
    "    coincidencias_encontradas = []\n",
    "    parada_activada = False\n",
    "    \n",
    "    def mostrar_top3_actual():\n",
    "        \"\"\"Muestra los TOP 3 actuales combinando saved y lotes\"\"\"\n",
    "        # Combinar todas las similitudes válidas\n",
    "        similitudes_combinadas = []\n",
    "        \n",
    "        # Añadir de saved\n",
    "        for s in todas_las_similitudes:\n",
    "            if s['similitud'] > 0:\n",
    "                similitudes_combinadas.append(s)\n",
    "        \n",
    "        # Añadir de lotes\n",
    "        for s in todas_las_similitudes_lotes:\n",
    "            if s['similitud'] > 0:\n",
    "                similitudes_combinadas.append(s)\n",
    "        \n",
    "        if similitudes_combinadas:\n",
    "            top_3 = sorted(similitudes_combinadas, key=lambda x: x['similitud'], reverse=True)[:3]\n",
    "            \n",
    "            top_str = \"TOP 3: \"\n",
    "            for i, sim in enumerate(top_3, 1):\n",
    "                icono = \"🥇\" if i == 1 else \"🥈\" if i == 2 else \"🥉\"\n",
    "                if sim['tipo'] == 'lote':\n",
    "                    top_str += f\"{icono}{sim['similitud']:.3f}({sim['archivo'][:15]}..Ex#{sim['examen_num']}) \"\n",
    "                else:\n",
    "                    top_str += f\"{icono}{sim['similitud']:.3f}({sim['archivo'][:15]}...) \"\n",
    "            \n",
    "            return top_str\n",
    "        else:\n",
    "            return \"TOP 3: Sin coincidencias aún\"\n",
    "    \n",
    "    # 1. COMPARAR CON ARCHIVOS EN /saved\n",
    "    print(f\"\\n🔍 Comparando con archivos en {ruta_saved}...\")\n",
    "    ruta_saved = Path(ruta_saved)\n",
    "    \n",
    "    if ruta_saved.exists():\n",
    "        archivos_saved = list(ruta_saved.glob(\"*.pdf\"))\n",
    "        print(f\"📁 Encontrados {len(archivos_saved)} archivos en saved\")\n",
    "        \n",
    "        # Usar tqdm para mostrar progreso CON TOP 3 ACTUALIZADO\n",
    "        progress_bar = tqdm(archivos_saved, desc=\"💾 Comparando con /saved\", unit=\"archivo\")\n",
    "        \n",
    "        for archivo_saved in progress_bar:\n",
    "            if parada_activada:\n",
    "                break\n",
    "                \n",
    "            try:\n",
    "                reader_saved = PdfReader(archivo_saved)\n",
    "                num_paginas_saved = len(reader_saved.pages)\n",
    "                \n",
    "                # Solo comparar si tienen el mismo número de páginas\n",
    "                if num_paginas_saved == num_paginas_objetivo:\n",
    "                    if mostrar_detalles:\n",
    "                        tqdm.write(f\"  📄 {archivo_saved.name} ({num_paginas_saved} páginas) - Comparando...\")\n",
    "                    \n",
    "                    # Convertir a imágenes\n",
    "                    imagenes_saved = convert_from_path(archivo_saved, dpi=100, fmt='jpeg')\n",
    "                    \n",
    "                    # Comparar cada página\n",
    "                    similitud_total = comparar_imagenes_paginas(imagenes_objetivo, imagenes_saved)\n",
    "                    \n",
    "                    # GUARDAR SIMILITUD\n",
    "                    similitud_info = {\n",
    "                        'archivo': archivo_saved.name,\n",
    "                        'ruta': str(archivo_saved),\n",
    "                        'tipo': 'saved',\n",
    "                        'similitud': similitud_total,\n",
    "                        'paginas': num_paginas_saved\n",
    "                    }\n",
    "                    todas_las_similitudes.append(similitud_info)\n",
    "                    \n",
    "                    if similitud_total > 0.85:  # 85% de similitud\n",
    "                        coincidencias_encontradas.append(similitud_info)\n",
    "                        if mostrar_detalles:\n",
    "                            tqdm.write(f\"    ✅ COINCIDENCIA: {similitud_total:.2%}\")\n",
    "                        \n",
    "                        # PARADA AUTOMÁTICA al 100%\n",
    "                        if parar_en_100 and similitud_total >= 0.999:  # 99.9% se considera 100%\n",
    "                            tqdm.write(f\"    🎯 ¡100% SIMILITUD ENCONTRADA! Deteniendo búsqueda...\")\n",
    "                            parada_activada = True\n",
    "                            break\n",
    "                    elif mostrar_detalles:\n",
    "                        tqdm.write(f\"    ❌ No coincide: {similitud_total:.2%}\")\n",
    "                else:\n",
    "                    # Añadir con similitud 0 para estadísticas\n",
    "                    todas_las_similitudes.append({\n",
    "                        'archivo': archivo_saved.name,\n",
    "                        'ruta': str(archivo_saved),\n",
    "                        'tipo': 'saved',\n",
    "                        'similitud': 0.0,\n",
    "                        'paginas': f\"{num_paginas_saved} páginas\"\n",
    "                    })\n",
    "                \n",
    "                # ACTUALIZAR DESCRIPCIÓN CON TOP 3 ACTUAL\n",
    "                progress_bar.set_description(f\"💾 Saved | {mostrar_top3_actual()}\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                if mostrar_detalles:\n",
    "                    tqdm.write(f\"  ❌ Error procesando {archivo_saved.name}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        progress_bar.close()\n",
    "    \n",
    "    # 2. COMPARAR CON LOTES ORIGINALES (solo si no se activó la parada)\n",
    "    if not parada_activada:\n",
    "        print(f\"\\n🔍 Comparando con lotes originales en {ruta_lotes}...\")\n",
    "        ruta_lotes = Path(ruta_lotes)\n",
    "        \n",
    "        if ruta_lotes.exists():\n",
    "            archivos_lotes = list(ruta_lotes.glob(\"*.pdf\"))\n",
    "            \n",
    "            progress_bar_lotes = tqdm(archivos_lotes, desc=\"📦 Comparando con lotes\", unit=\"lote\")\n",
    "            \n",
    "            for archivo_lote in progress_bar_lotes:\n",
    "                if parada_activada:\n",
    "                    break\n",
    "                    \n",
    "                if mostrar_detalles:\n",
    "                    tqdm.write(f\"  📄 Revisando {archivo_lote.name}...\")\n",
    "                \n",
    "                try:\n",
    "                    reader_lote = PdfReader(archivo_lote)\n",
    "                    num_paginas_lote = len(reader_lote.pages)\n",
    "                    \n",
    "                    # Buscar secuencias de páginas que coincidan en número\n",
    "                    for inicio in range(0, num_paginas_lote, 2):  # Examenes de 2 páginas\n",
    "                        if parada_activada:\n",
    "                            break\n",
    "                            \n",
    "                        fin = min(inicio + num_paginas_objetivo, num_paginas_lote)\n",
    "                        \n",
    "                        if fin - inicio == num_paginas_objetivo:\n",
    "                            if mostrar_detalles:\n",
    "                                tqdm.write(f\"    🔍 Comparando páginas {inicio+1}-{fin} del lote...\")\n",
    "                            \n",
    "                            try:\n",
    "                                imagenes_lote = convert_from_path(\n",
    "                                    archivo_lote,\n",
    "                                    first_page=inicio + 1,\n",
    "                                    last_page=fin,\n",
    "                                    dpi=100,\n",
    "                                    fmt='jpeg'\n",
    "                                )\n",
    "                                \n",
    "                                # Comparar\n",
    "                                similitud_total = comparar_imagenes_paginas(imagenes_objetivo, imagenes_lote)\n",
    "                                examen_num = (inicio // 2) + 1\n",
    "                                \n",
    "                                # GUARDAR SIMILITUD\n",
    "                                similitud_info = {\n",
    "                                    'archivo': archivo_lote.name,\n",
    "                                    'ruta': str(archivo_lote),\n",
    "                                    'tipo': 'lote',\n",
    "                                    'similitud': similitud_total,\n",
    "                                    'paginas': f\"{inicio+1}-{fin}\",\n",
    "                                    'examen_num': examen_num\n",
    "                                }\n",
    "                                todas_las_similitudes_lotes.append(similitud_info)\n",
    "                                \n",
    "                                if similitud_total > 0.85:\n",
    "                                    coincidencias_encontradas.append(similitud_info)\n",
    "                                    if mostrar_detalles:\n",
    "                                        tqdm.write(f\"      ✅ COINCIDENCIA: {similitud_total:.2%} (Examen #{examen_num})\")\n",
    "                                    \n",
    "                                    # PARADA AUTOMÁTICA al 100%\n",
    "                                    if parar_en_100 and similitud_total >= 0.999:\n",
    "                                        tqdm.write(f\"      🎯 ¡100% SIMILITUD ENCONTRADA! Deteniendo búsqueda...\")\n",
    "                                        parada_activada = True\n",
    "                                        break\n",
    "                                \n",
    "                            except Exception as e:\n",
    "                                if mostrar_detalles:\n",
    "                                    tqdm.write(f\"      ❌ Error comparando páginas {inicio+1}-{fin}: {e}\")\n",
    "                                continue\n",
    "                \n",
    "                    # ACTUALIZAR DESCRIPCIÓN CON TOP 3 ACTUAL\n",
    "                    progress_bar_lotes.set_description(f\"📦 Lotes | {mostrar_top3_actual()}\")\n",
    "                                \n",
    "                except Exception as e:\n",
    "                    if mostrar_detalles:\n",
    "                        tqdm.write(f\"  ❌ Error procesando lote {archivo_lote.name}: {e}\")\n",
    "                    continue\n",
    "            \n",
    "            progress_bar_lotes.close()\n",
    "    else:\n",
    "        print(\"\\n⏹️ Búsqueda en lotes omitida (parada automática activada)\")\n",
    "    \n",
    "    # MOSTRAR RESULTADOS FINALES\n",
    "    print(f\"\\n\" + \"=\"*80)\n",
    "    print(f\"📊 RESULTADOS FINALES PARA: {nombre_archivo_objetivo}\")\n",
    "    print(f\"=\"*80)\n",
    "    \n",
    "    if coincidencias_encontradas:\n",
    "        # Ordenar por similitud descendente\n",
    "        coincidencias_encontradas.sort(key=lambda x: x['similitud'], reverse=True)\n",
    "        \n",
    "        print(f\"🎉 Encontradas {len(coincidencias_encontradas)} coincidencias que superan el umbral:\")\n",
    "        \n",
    "        for i, coincidencia in enumerate(coincidencias_encontradas, 1):\n",
    "            print(f\"\\n{i}. 📁 ARCHIVO: {coincidencia['archivo']}\")\n",
    "            print(f\"   📍 Ubicación: {coincidencia['tipo']}\")\n",
    "            print(f\"   📊 Similitud: {coincidencia['similitud']:.2%}\")\n",
    "            \n",
    "            if coincidencia['tipo'] == 'lote':\n",
    "                print(f\"   📄 Páginas: {coincidencia['paginas']}\")\n",
    "                print(f\"   🔢 Examen #: {coincidencia['examen_num']}\")\n",
    "            else:\n",
    "                print(f\"   📄 Páginas: {coincidencia['paginas']}\")\n",
    "            \n",
    "            print(f\"   🔗 Ruta: {coincidencia['ruta']}\")\n",
    "        \n",
    "        return coincidencias_encontradas\n",
    "    else:\n",
    "        print(\"❌ No se encontraron coincidencias que superen el umbral (85%)\")\n",
    "        return None\n",
    "\n",
    "def comparar_imagenes_paginas(imagenes1, imagenes2):\n",
    "    \"\"\"\n",
    "    Compara dos listas de imágenes página por página\n",
    "    Retorna un porcentaje de similitud promedio\n",
    "    \"\"\"\n",
    "    if len(imagenes1) != len(imagenes2):\n",
    "        return 0.0\n",
    "    \n",
    "    similitudes = []\n",
    "    \n",
    "    for img1, img2 in zip(imagenes1, imagenes2):\n",
    "        # Redimensionar a mismo tamaño si es necesario\n",
    "        if img1.size != img2.size:\n",
    "            # Usar el tamaño más pequeño\n",
    "            nuevo_tamaño = (\n",
    "                min(img1.size[0], img2.size[0]),\n",
    "                min(img1.size[1], img2.size[1])\n",
    "            )\n",
    "            img1 = img1.resize(nuevo_tamaño)\n",
    "            img2 = img2.resize(nuevo_tamaño)\n",
    "        \n",
    "        # Comparar usando diferencia de píxeles\n",
    "        diferencia = ImageChops.difference(img1, img2)\n",
    "        \n",
    "        # Convertir a array numpy\n",
    "        arr_diff = np.array(diferencia)\n",
    "        \n",
    "        # Calcular similitud (invertir la diferencia)\n",
    "        diferencia_promedio = np.mean(arr_diff) / 255.0\n",
    "        similitud = 1.0 - diferencia_promedio\n",
    "        \n",
    "        similitudes.append(similitud)\n",
    "    \n",
    "    return np.mean(similitudes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path_a_comparar = \"poner aqui pdf 1 pagina\"\n",
    "#resultado = comparar_pdfs_visuales_con_tqdm(path_a_comparar, parar_en_100=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'resultado' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[61]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Crear DataFrame con los resultados ordenado por similitud de mayor a menor\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m df_resultado = pd.DataFrame(\u001b[43mresultado\u001b[49m)\n\u001b[32m      5\u001b[39m df_resultado_ordenado = df_resultado.sort_values(\u001b[33m'\u001b[39m\u001b[33msimilitud\u001b[39m\u001b[33m'\u001b[39m, ascending=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Mostrar el DataFrame\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m#display(df_resultado_ordenado)\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'resultado' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Crear DataFrame con los resultados ordenado por similitud de mayor a menor\n",
    "df_resultado = pd.DataFrame(resultado)\n",
    "df_resultado_ordenado = df_resultado.sort_values('similitud', ascending=False)\n",
    "\n",
    "# Mostrar el DataFrame\n",
    "#display(df_resultado_ordenado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analizar_examenes_problematicos(ruta_examenes=\"../data/examenes_procesados/\", \n",
    "                                   ruta_saved=\"../data/saved/\", \n",
    "                                   parar_en_100=False,\n",
    "                                   umbral_similitud=0.85):\n",
    "    \"\"\"\n",
    "    Analiza todos los exámenes en la carpeta 'problemático' comparando SOLO con saved.\n",
    "    Muestra los 3 mejores resultados por alumno en tiempo real.\n",
    "    USA DIRECTAMENTE comparar_pdfs_visuales_con_tqdm - versión simplificada\n",
    "    \"\"\"\n",
    "    \n",
    "    ruta_problematico = Path(ruta_examenes) / \"problemático\"\n",
    "    \n",
    "    if not ruta_problematico.exists():\n",
    "        print(\"❌ No existe la carpeta 'problemático'\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    archivos_problematicos = list(ruta_problematico.glob(\"*.pdf\"))\n",
    "    \n",
    "    if not archivos_problematicos:\n",
    "        print(\"ℹ️ No hay archivos en la carpeta 'problemático'\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    print(f\"🔍 Analizando {len(archivos_problematicos)} archivos problemáticos...\")\n",
    "    print(\"💾 Solo comparando con archivos en /saved\")\n",
    "    if parar_en_100:\n",
    "        print(\"⏹️ Modo parada automática activado (se detiene al encontrar 100% similitud)\")\n",
    "    \n",
    "    resultados = []\n",
    "    \n",
    "    # Barra de progreso principal con tqdm\n",
    "    for archivo_objetivo in tqdm(archivos_problematicos, desc=\"📄 Procesando archivos\", unit=\"archivo\"):\n",
    "        try:\n",
    "            # Mostrar archivo actual\n",
    "            tqdm.write(f\"\\n📄 Procesando: {archivo_objetivo.name}\")\n",
    "            \n",
    "            # USAR DIRECTAMENTE comparar_pdfs_visuales_con_tqdm con ruta_lotes vacía\n",
    "            # para que SOLO compare con /saved\n",
    "            coincidencias = comparar_pdfs_visuales_con_tqdm_solo_saved(\n",
    "                archivo_objetivo.name,  # Solo el nombre del archivo\n",
    "                ruta_saved=ruta_saved,\n",
    "                ruta_examenes=str(ruta_problematico),  # Buscar en problemático\n",
    "                mostrar_detalles=False,  # Silencioso para no saturar output\n",
    "                parar_en_100=parar_en_100,\n",
    "                umbral_similitud=umbral_similitud\n",
    "            )\n",
    "            \n",
    "            if coincidencias:\n",
    "                # Filtrar solo coincidencias de tipo 'saved' y ordenar por similitud\n",
    "                coincidencias_saved = [c for c in coincidencias if c.get('tipo') == 'saved']\n",
    "                mejores_coincidencias = sorted(coincidencias_saved, key=lambda x: x['similitud'], reverse=True)[:3]\n",
    "                \n",
    "                # Agregar información adicional a cada coincidencia\n",
    "                for coincidencia in mejores_coincidencias:\n",
    "                    coincidencia['archivo_problematico'] = archivo_objetivo.name\n",
    "                \n",
    "                resultados.extend(mejores_coincidencias)\n",
    "                \n",
    "                # MOSTRAR RESULTADOS EN TIEMPO REAL\n",
    "                tqdm.write(\"🎯 MEJORES COINCIDENCIAS ENCONTRADAS:\")\n",
    "                tqdm.write(\"-\" * 60)\n",
    "                for j, coincidencia in enumerate(mejores_coincidencias, 1):\n",
    "                    icono = \"🥇\" if j == 1 else \"🥈\" if j == 2 else \"🥉\"\n",
    "                    \n",
    "                    tqdm.write(f\"{icono} #{j} 💾 {coincidencia['similitud']:.1%} - {coincidencia['archivo']}\")\n",
    "                    tqdm.write(f\"    📄 Páginas: {coincidencia['paginas']}\")\n",
    "                        \n",
    "                    if parar_en_100 and coincidencia['similitud'] >= 0.999:\n",
    "                        tqdm.write(\"    🎯 ¡COINCIDENCIA PERFECTA! Búsqueda detenida.\")\n",
    "                        break\n",
    "                        \n",
    "            else:\n",
    "                # Sin coincidencias\n",
    "                tqdm.write(\"❌ Sin coincidencias encontradas\")\n",
    "                reader_objetivo = PdfReader(archivo_objetivo)\n",
    "                num_paginas_objetivo = len(reader_objetivo.pages)\n",
    "                \n",
    "                resultados.append({\n",
    "                    'archivo_problematico': archivo_objetivo.name,\n",
    "                    'archivo': 'SIN_COINCIDENCIAS',\n",
    "                    'ruta': '',\n",
    "                    'tipo': 'ninguno',\n",
    "                    'similitud': 0.0,\n",
    "                    'paginas': num_paginas_objetivo\n",
    "                })\n",
    "                \n",
    "        except Exception as e:\n",
    "            tqdm.write(f\"❌ Error procesando {archivo_objetivo.name}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    # Crear DataFrame\n",
    "    df_resultados = pd.DataFrame(resultados)\n",
    "    \n",
    "    if df_resultados.empty:\n",
    "        print(\"\\n❌ No se encontraron resultados\")\n",
    "        return df_resultados\n",
    "    \n",
    "    # Extraer nombre del alumno del archivo problemático\n",
    "    df_resultados['alumno'] = df_resultados['archivo_problematico'].str.replace('.pdf', '').str.replace('_P[0-9]_.*', '', regex=True)\n",
    "    \n",
    "    # Ordenar por alumno y similitud (descendente)\n",
    "    df_resultados = df_resultados.sort_values(['alumno', 'similitud'], ascending=[True, False])\n",
    "    \n",
    "    # Reordenar columnas para mejor visualización\n",
    "    columnas_orden = ['alumno', 'archivo_problematico', 'similitud', 'archivo', 'tipo', 'paginas', 'ruta']\n",
    "    \n",
    "    df_resultados = df_resultados[columnas_orden].reset_index(drop=True)\n",
    "    \n",
    "    # RESUMEN FINAL\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"📊 RESUMEN FINAL DEL ANÁLISIS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    total_archivos = len(archivos_problematicos)\n",
    "    archivos_con_coincidencias = len(df_resultados[df_resultados['similitud'] > 0])\n",
    "    archivos_sin_coincidencias = len(df_resultados[df_resultados['similitud'] == 0])\n",
    "    \n",
    "    print(f\"📁 Total de archivos analizados: {total_archivos}\")\n",
    "    print(f\"✅ Archivos con coincidencias: {archivos_con_coincidencias}\")\n",
    "    print(f\"❌ Archivos sin coincidencias: {archivos_sin_coincidencias}\")\n",
    "    \n",
    "    # Estadísticas de similitud\n",
    "    if archivos_con_coincidencias > 0:\n",
    "        coincidencias_df = df_resultados[df_resultados['similitud'] > 0]\n",
    "        similitud_promedio = coincidencias_df['similitud'].mean()\n",
    "        similitud_maxima = coincidencias_df['similitud'].max()\n",
    "        \n",
    "        print(f\"📈 Similitud promedio: {similitud_promedio:.1%}\")\n",
    "        print(f\"🎯 Similitud máxima: {similitud_maxima:.1%}\")\n",
    "        \n",
    "        # Solo comparamos con saved, así que toda coincidencia es de tipo saved\n",
    "        print(f\"\\n💾 Todas las coincidencias son de /saved: {archivos_con_coincidencias} archivos\")\n",
    "    \n",
    "    return df_resultados\n",
    "\n",
    "def comparar_pdfs_visuales_con_tqdm_solo_saved(nombre_archivo_objetivo, \n",
    "                                               ruta_saved=\"../data/saved/\", \n",
    "                                               ruta_examenes=\"../data/examenes_procesados/problemático/\",\n",
    "                                               mostrar_detalles=False, \n",
    "                                               parar_en_100=False,\n",
    "                                               umbral_similitud=0.85):\n",
    "    \"\"\"\n",
    "    Versión modificada de comparar_pdfs_visuales_con_tqdm que SOLO compara con /saved\n",
    "    Sin comparar con lotes para optimizar el análisis de problemáticos\n",
    "    \"\"\"\n",
    "    \n",
    "    # Buscar el archivo objetivo en la ruta especificada\n",
    "    archivo_objetivo = None\n",
    "    ruta_examenes = Path(ruta_examenes)\n",
    "    \n",
    "    for archivo_pdf in ruta_examenes.glob(\"*.pdf\"):\n",
    "        if nombre_archivo_objetivo.lower() in archivo_pdf.name.lower():\n",
    "            archivo_objetivo = archivo_pdf\n",
    "            break\n",
    "    \n",
    "    if not archivo_objetivo or not archivo_objetivo.exists():\n",
    "        if mostrar_detalles:\n",
    "            print(f\"❌ No se encontró el archivo {nombre_archivo_objetivo}\")\n",
    "        return None\n",
    "    \n",
    "    if mostrar_detalles:\n",
    "        print(f\"🎯 Archivo encontrado: {archivo_objetivo}\")\n",
    "    \n",
    "    # Obtener número de páginas del objetivo\n",
    "    try:\n",
    "        reader_objetivo = PdfReader(archivo_objetivo)\n",
    "        num_paginas_objetivo = len(reader_objetivo.pages)\n",
    "        if mostrar_detalles:\n",
    "            print(f\"📄 Páginas del archivo objetivo: {num_paginas_objetivo}\")\n",
    "    except Exception as e:\n",
    "        if mostrar_detalles:\n",
    "            print(f\"❌ Error leyendo archivo objetivo: {e}\")\n",
    "        return None\n",
    "    \n",
    "    # Convertir páginas del objetivo a imágenes para comparación\n",
    "    try:\n",
    "        imagenes_objetivo = convert_from_path(\n",
    "            archivo_objetivo, \n",
    "            dpi=100,\n",
    "            fmt='jpeg'\n",
    "        )\n",
    "    except Exception as e:\n",
    "        if mostrar_detalles:\n",
    "            print(f\"❌ Error convirtiendo archivo objetivo: {e}\")\n",
    "        return None\n",
    "    \n",
    "    # Lista para almacenar similitudes\n",
    "    coincidencias_encontradas = []\n",
    "    \n",
    "    # COMPARAR SOLO CON ARCHIVOS EN /saved\n",
    "    ruta_saved = Path(ruta_saved)\n",
    "    \n",
    "    if ruta_saved.exists():\n",
    "        archivos_saved = list(ruta_saved.glob(\"*.pdf\"))\n",
    "        \n",
    "        # Usar tqdm para mostrar progreso\n",
    "        progress_bar = tqdm(archivos_saved, desc=\"💾 Comparando con /saved\", leave=False, unit=\"archivo\")\n",
    "        \n",
    "        for archivo_saved in progress_bar:\n",
    "            try:\n",
    "                reader_saved = PdfReader(archivo_saved)\n",
    "                num_paginas_saved = len(reader_saved.pages)\n",
    "                \n",
    "                # Solo comparar si tienen el mismo número de páginas\n",
    "                if num_paginas_saved == num_paginas_objetivo:\n",
    "                    # Convertir a imágenes\n",
    "                    imagenes_saved = convert_from_path(archivo_saved, dpi=100, fmt='jpeg')\n",
    "                    \n",
    "                    # Comparar cada página\n",
    "                    similitud_total = comparar_imagenes_paginas(imagenes_objetivo, imagenes_saved)\n",
    "                    \n",
    "                    if similitud_total >= umbral_similitud:  # Usar umbral personalizado\n",
    "                        similitud_info = {\n",
    "                            'archivo': archivo_saved.name,\n",
    "                            'ruta': str(archivo_saved),\n",
    "                            'tipo': 'saved',\n",
    "                            'similitud': similitud_total,\n",
    "                            'paginas': num_paginas_saved\n",
    "                        }\n",
    "                        coincidencias_encontradas.append(similitud_info)\n",
    "                        \n",
    "                        if mostrar_detalles:\n",
    "                            tqdm.write(f\"    ✅ COINCIDENCIA: {similitud_total:.2%}\")\n",
    "                        \n",
    "                        # PARADA AUTOMÁTICA al 100%\n",
    "                        if parar_en_100 and similitud_total >= 0.999:\n",
    "                            if mostrar_detalles:\n",
    "                                tqdm.write(f\"    🎯 ¡100% SIMILITUD ENCONTRADA! Deteniendo búsqueda...\")\n",
    "                            break\n",
    "                        \n",
    "            except Exception as e:\n",
    "                if mostrar_detalles:\n",
    "                    tqdm.write(f\"  ❌ Error procesando {archivo_saved.name}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        progress_bar.close()\n",
    "    \n",
    "    # Retornar coincidencias ordenadas por similitud\n",
    "    if coincidencias_encontradas:\n",
    "        coincidencias_encontradas.sort(key=lambda x: x['similitud'], reverse=True)\n",
    "    \n",
    "    return coincidencias_encontradas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Iniciando análisis RÁPIDO con parada automática...\n",
      "🔍 Analizando 15 archivos problemáticos...\n",
      "💾 Solo comparando con archivos en /saved\n",
      "⏹️ Modo parada automática activado (se detiene al encontrar 100% similitud)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📄 Procesando archivos:   0%|          | 0/15 [00:00<?, ?archivo/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📄 Procesando: CAMARA_VILKOVA_VERONICA_LUISA_P3_IWSIM11.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📄 Procesando archivos:   7%|▋         | 1/15 [00:06<01:26,  6.16s/archivo]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 MEJORES COINCIDENCIAS ENCONTRADAS:\n",
      "------------------------------------------------------------\n",
      "🥇 #1 💾 100.0% - lote_13_examen_15.pdf\n",
      "    📄 Páginas: 1\n",
      "    🎯 ¡COINCIDENCIA PERFECTA! Búsqueda detenida.\n",
      "\n",
      "📄 Procesando: FUENTE_MARTINEZ_HERNAN_GABRIEL_DE_LA_P5_IWSIM12.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📄 Procesando archivos:  13%|█▎        | 2/15 [00:26<03:07, 14.43s/archivo]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 MEJORES COINCIDENCIAS ENCONTRADAS:\n",
      "------------------------------------------------------------\n",
      "🥇 #1 💾 100.0% - lote_9_examen_50.pdf\n",
      "    📄 Páginas: 1\n",
      "    🎯 ¡COINCIDENCIA PERFECTA! Búsqueda detenida.\n",
      "\n",
      "📄 Procesando: FUERIS_FRUTOS_MANUEL_P5_IWSIT12.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📄 Procesando archivos:  20%|██        | 3/15 [00:41<02:55, 14.66s/archivo]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 MEJORES COINCIDENCIAS ENCONTRADAS:\n",
      "------------------------------------------------------------\n",
      "🥇 #1 💾 100.0% - lote_4_examen_40.pdf\n",
      "    📄 Páginas: 1\n",
      "    🎯 ¡COINCIDENCIA PERFECTA! Búsqueda detenida.\n",
      "\n",
      "📄 Procesando: HEINRICKS_GONZALEZ_BRANDON_P3_IWSIM11.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📄 Procesando archivos:  27%|██▋       | 4/15 [00:56<02:45, 15.02s/archivo]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 MEJORES COINCIDENCIAS ENCONTRADAS:\n",
      "------------------------------------------------------------\n",
      "🥇 #1 💾 100.0% - lote_4_examen_43.pdf\n",
      "    📄 Páginas: 1\n",
      "    🎯 ¡COINCIDENCIA PERFECTA! Búsqueda detenida.\n",
      "\n",
      "📄 Procesando: HEINRICKS_GONZALEZ_BRANDON_P5_IWSIM11.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📄 Procesando archivos:  33%|███▎      | 5/15 [01:13<02:34, 15.49s/archivo]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 MEJORES COINCIDENCIAS ENCONTRADAS:\n",
      "------------------------------------------------------------\n",
      "🥇 #1 💾 100.0% - lote_4_examen_43.pdf\n",
      "    📄 Páginas: 1\n",
      "    🎯 ¡COINCIDENCIA PERFECTA! Búsqueda detenida.\n",
      "\n",
      "📄 Procesando: IANCU_IANCU_GEORGIAN_SORIN_P3_IWSIM11.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📄 Procesando archivos:  40%|████      | 6/15 [01:23<02:02, 13.61s/archivo]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 MEJORES COINCIDENCIAS ENCONTRADAS:\n",
      "------------------------------------------------------------\n",
      "🥇 #1 💾 100.0% - lote_13_examen_60.pdf\n",
      "    📄 Páginas: 1\n",
      "    🎯 ¡COINCIDENCIA PERFECTA! Búsqueda detenida.\n",
      "\n",
      "📄 Procesando: IANCU_IANCU_GEORGIAN_SORIN_P5_IWSIM11.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📄 Procesando archivos:  47%|████▋     | 7/15 [01:25<01:20, 10.00s/archivo]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 MEJORES COINCIDENCIAS ENCONTRADAS:\n",
      "------------------------------------------------------------\n",
      "🥇 #1 💾 100.0% - lote_10_examen_60.pdf\n",
      "    📄 Páginas: 1\n",
      "    🎯 ¡COINCIDENCIA PERFECTA! Búsqueda detenida.\n",
      "\n",
      "📄 Procesando: NAUTIYAL_BHATT_NINAD_P3_IWSIM11.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📄 Procesando archivos:  53%|█████▎    | 8/15 [01:41<01:22, 11.77s/archivo]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 MEJORES COINCIDENCIAS ENCONTRADAS:\n",
      "------------------------------------------------------------\n",
      "🥇 #1 💾 100.0% - lote_4_examen_39.pdf\n",
      "    📄 Páginas: 1\n",
      "    🎯 ¡COINCIDENCIA PERFECTA! Búsqueda detenida.\n",
      "\n",
      "📄 Procesando: NAUTIYAL_BHATT_NINAD_P5_IWSIM11.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📄 Procesando archivos:  60%|██████    | 9/15 [01:56<01:16, 12.73s/archivo]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 MEJORES COINCIDENCIAS ENCONTRADAS:\n",
      "------------------------------------------------------------\n",
      "🥇 #1 💾 100.0% - lote_4_examen_39.pdf\n",
      "    📄 Páginas: 1\n",
      "    🎯 ¡COINCIDENCIA PERFECTA! Búsqueda detenida.\n",
      "\n",
      "📄 Procesando: PRIETO_ALVAREZ_MARIA_P5_IWSIM12.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📄 Procesando archivos:  67%|██████▋   | 10/15 [02:16<01:14, 14.98s/archivo]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 MEJORES COINCIDENCIAS ENCONTRADAS:\n",
      "------------------------------------------------------------\n",
      "🥇 #1 💾 100.0% - lote_6_examen_42.pdf\n",
      "    📄 Páginas: 1\n",
      "    🎯 ¡COINCIDENCIA PERFECTA! Búsqueda detenida.\n",
      "\n",
      "📄 Procesando: QUISBERT_CHOQUETICLLA_LEONEL_P3_IWSIM12.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📄 Procesando archivos:  73%|███████▎  | 11/15 [02:30<00:58, 14.72s/archivo]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 MEJORES COINCIDENCIAS ENCONTRADAS:\n",
      "------------------------------------------------------------\n",
      "🥇 #1 💾 100.0% - lote_3_examen_39.pdf\n",
      "    📄 Páginas: 1\n",
      "    🎯 ¡COINCIDENCIA PERFECTA! Búsqueda detenida.\n",
      "\n",
      "📄 Procesando: SANCHEZ_RODRIGUEZ_ALVARO_P3_IWSIM12.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📄 Procesando archivos:  80%|████████  | 12/15 [02:42<00:42, 14.10s/archivo]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 MEJORES COINCIDENCIAS ENCONTRADAS:\n",
      "------------------------------------------------------------\n",
      "🥇 #1 💾 100.0% - lote_3_examen_28.pdf\n",
      "    📄 Páginas: 1\n",
      "    🎯 ¡COINCIDENCIA PERFECTA! Búsqueda detenida.\n",
      "\n",
      "📄 Procesando: SANCHEZ_RODRIGUEZ_ALVARO_P5_IWSIM12.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📄 Procesando archivos:  87%|████████▋ | 13/15 [02:47<00:22, 11.10s/archivo]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 MEJORES COINCIDENCIAS ENCONTRADAS:\n",
      "------------------------------------------------------------\n",
      "🥇 #1 💾 100.0% - lote_12_examen_10.pdf\n",
      "    📄 Páginas: 1\n",
      "    🎯 ¡COINCIDENCIA PERFECTA! Búsqueda detenida.\n",
      "\n",
      "📄 Procesando: ZHENG_YIFEI_P3_IWSIM12.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📄 Procesando archivos:  93%|█████████▎| 14/15 [02:59<00:11, 11.42s/archivo]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 MEJORES COINCIDENCIAS ENCONTRADAS:\n",
      "------------------------------------------------------------\n",
      "🥇 #1 💾 100.0% - lote_3_examen_27.pdf\n",
      "    📄 Páginas: 1\n",
      "    🎯 ¡COINCIDENCIA PERFECTA! Búsqueda detenida.\n",
      "\n",
      "📄 Procesando: ZODER_MENDEZ_PABLO_JOACHIM_P5_IWSIM12.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📄 Procesando archivos: 100%|██████████| 15/15 [03:04<00:00, 12.30s/archivo]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 MEJORES COINCIDENCIAS ENCONTRADAS:\n",
      "------------------------------------------------------------\n",
      "🥇 #1 💾 100.0% - lote_12_examen_5.pdf\n",
      "    📄 Páginas: 1\n",
      "    🎯 ¡COINCIDENCIA PERFECTA! Búsqueda detenida.\n",
      "\n",
      "================================================================================\n",
      "📊 RESUMEN FINAL DEL ANÁLISIS\n",
      "================================================================================\n",
      "📁 Total de archivos analizados: 15\n",
      "✅ Archivos con coincidencias: 44\n",
      "❌ Archivos sin coincidencias: 0\n",
      "📈 Similitud promedio: 96.4%\n",
      "🎯 Similitud máxima: 100.0%\n",
      "\n",
      "💾 Todas las coincidencias son de /saved: 44 archivos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'p' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[92]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m🚀 Iniciando análisis RÁPIDO con parada automática...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m df_problematicos_rapido = analizar_examenes_problematicos(\n\u001b[32m      6\u001b[39m     parar_en_100=\u001b[38;5;28;01mTrue\u001b[39;00m,  \u001b[38;5;66;03m# ⭐ PARADA AUTOMÁTICA ACTIVADA\u001b[39;00m\n\u001b[32m      7\u001b[39m     umbral_similitud=\u001b[32m0.8\u001b[39m  \u001b[38;5;66;03m# Umbral más alto para ser más selectivo\u001b[39;00m\n\u001b[32m      8\u001b[39m )\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[43mp\u001b[49m\n",
      "\u001b[31mNameError\u001b[39m: name 'p' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# LLAMADAS DE EJEMPLO:\n",
    "\n",
    "# 1. Análisis RÁPIDO con parada automática al 100%\n",
    "print(\"🚀 Iniciando análisis RÁPIDO con parada automática...\")\n",
    "df_problematicos_rapido = analizar_examenes_problematicos(\n",
    "    parar_en_100=True,  # ⭐ PARADA AUTOMÁTICA ACTIVADA\n",
    "    umbral_similitud=0.8  # Umbral más alto para ser más selectivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from pypdf import PdfReader, PdfWriter\n",
    "import re\n",
    "\n",
    "def separar_archivo_conjunto_y_mover(archivo_path, carpeta_base=\"../data/examenes_procesados/\"):\n",
    "    \"\"\"\n",
    "    Separa un archivo PDF conjunto en dos archivos individuales y los mueve a sus carpetas correspondientes\n",
    "    \"\"\"\n",
    "    archivo_path = Path(archivo_path)\n",
    "    \n",
    "    if not archivo_path.exists():\n",
    "        print(f\"❌ El archivo {archivo_path} no existe\")\n",
    "        return\n",
    "    \n",
    "    # Extraer información del nombre del archivo\n",
    "    nombre_archivo = archivo_path.stem\n",
    "    \n",
    "    # Buscar el patrón _Y_ para separar los nombres\n",
    "    if '_Y_' not in nombre_archivo:\n",
    "        print(f\"❌ El archivo no contiene el patrón '_Y_' para separar\")\n",
    "        return\n",
    "    \n",
    "    # Separar por _Y_\n",
    "    partes = nombre_archivo.split('_Y_')\n",
    "    if len(partes) != 2:\n",
    "        print(f\"❌ El archivo no tiene exactamente dos partes separadas por '_Y_'\")\n",
    "        return\n",
    "    \n",
    "    primer_alumno = partes[0].strip()\n",
    "    segundo_alumno = partes[1].strip()\n",
    "    \n",
    "    print(f\"📄 Procesando archivo: {archivo_path.name}\")\n",
    "    print(f\"👤 Primer alumno: {primer_alumno}\")\n",
    "    print(f\"👤 Segundo alumno: {segundo_alumno}\")\n",
    "    \n",
    "    # Leer el PDF original\n",
    "    try:\n",
    "        reader = PdfReader(archivo_path)\n",
    "        total_paginas = len(reader.pages)\n",
    "        print(f\"📊 Total de páginas en el archivo: {total_paginas}\")\n",
    "        \n",
    "        if total_paginas != 4:\n",
    "            print(f\"⚠️ El archivo tiene {total_paginas} páginas, se esperaban 4 para dividir en dos archivos de 2 páginas cada uno\")\n",
    "        \n",
    "        # Crear primer archivo (páginas 1-2)\n",
    "        writer1 = PdfWriter()\n",
    "        for i in range(min(2, total_paginas)):\n",
    "            writer1.add_page(reader.pages[i])\n",
    "        \n",
    "        # Crear segundo archivo (páginas 3-4)\n",
    "        writer2 = PdfWriter()\n",
    "        for i in range(2, min(4, total_paginas)):\n",
    "            writer2.add_page(reader.pages[i])\n",
    "        \n",
    "        # Determinar rutas de destino basándose en los nombres\n",
    "        carpeta_base = Path(carpeta_base)\n",
    "        \n",
    "        # Extraer información del primer alumno\n",
    "        grupo1, practica1 = extraer_grupo_y_practica(primer_alumno)\n",
    "        archivo1_nombre = f\"{primer_alumno}.pdf\"\n",
    "        \n",
    "        if grupo1 != \"desconocido\":\n",
    "            carpeta1 = carpeta_base / grupo1 / f\"Practica_{practica1}\"\n",
    "        else:\n",
    "            carpeta1 = carpeta_base / \"problemático\"\n",
    "        \n",
    "        # Extraer información del segundo alumno  \n",
    "        grupo2, practica2 = extraer_grupo_y_practica(segundo_alumno)\n",
    "        archivo2_nombre = f\"{segundo_alumno}.pdf\"\n",
    "        \n",
    "        if grupo2 != \"desconocido\":\n",
    "            carpeta2 = carpeta_base / grupo2 / f\"Practica_{practica2}\"\n",
    "        else:\n",
    "            carpeta2 = carpeta_base / \"problemático\"\n",
    "        \n",
    "        # Crear carpetas si no existen\n",
    "        carpeta1.mkdir(parents=True, exist_ok=True)\n",
    "        carpeta2.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Guardar archivos\n",
    "        archivo1_path = carpeta1 / archivo1_nombre\n",
    "        archivo2_path = carpeta2 / archivo2_nombre\n",
    "        \n",
    "        # Evitar conflictos de nombres\n",
    "        contador1 = 2\n",
    "        while archivo1_path.exists():\n",
    "            nombre_base1 = primer_alumno\n",
    "            archivo1_path = carpeta1 / f\"{nombre_base1}_{contador1}.pdf\"\n",
    "            contador1 += 1\n",
    "        \n",
    "        contador2 = 2\n",
    "        while archivo2_path.exists():\n",
    "            nombre_base2 = segundo_alumno\n",
    "            archivo2_path = carpeta2 / f\"{nombre_base2}_{contador2}.pdf\"\n",
    "            contador2 += 1\n",
    "        \n",
    "        # Escribir archivos\n",
    "        with open(archivo1_path, 'wb') as f1:\n",
    "            writer1.write(f1)\n",
    "        \n",
    "        with open(archivo2_path, 'wb') as f2:\n",
    "            writer2.write(f2)\n",
    "        \n",
    "        print(f\"\\n✅ ARCHIVOS CREADOS EXITOSAMENTE:\")\n",
    "        print(f\"📁 Archivo 1: {archivo1_path}\")\n",
    "        print(f\"   📄 Páginas: 1-2\")\n",
    "        print(f\"   👤 Alumno: {primer_alumno}\")\n",
    "        print(f\"   🎯 Grupo: {grupo1}, Práctica: {practica1}\")\n",
    "        \n",
    "        print(f\"\\n📁 Archivo 2: {archivo2_path}\")\n",
    "        print(f\"   📄 Páginas: 3-4 (del original)\")\n",
    "        print(f\"   👤 Alumno: {segundo_alumno}\")\n",
    "        print(f\"   🎯 Grupo: {grupo2}, Práctica: {practica2}\")\n",
    "        \n",
    "        # Preguntar si eliminar el archivo original\n",
    "        print(f\"\\n🗑️ ¿Deseas eliminar el archivo original?\")\n",
    "        print(f\"   Archivo: {archivo_path}\")\n",
    "        eliminar = input(\"   Escribe 'si' para eliminarlo: \").lower().strip()\n",
    "        \n",
    "        if eliminar == 'si':\n",
    "            archivo_path.unlink()\n",
    "            print(f\"   ✅ Archivo original eliminado\")\n",
    "        else:\n",
    "            print(f\"   📄 Archivo original conservado\")\n",
    "        \n",
    "        return [archivo1_path, archivo2_path]\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error procesando el archivo: {e}\")\n",
    "        return None\n",
    "\n",
    "def extraer_grupo_y_practica(nombre_alumno):\n",
    "    \"\"\"\n",
    "    Extrae el grupo y práctica del nombre del alumno\n",
    "    \"\"\"\n",
    "    \n",
    "    # Buscar práctica (P seguido de número)\n",
    "    match_practica = re.search(r'P(\\d+)', nombre_alumno)\n",
    "    if match_practica:\n",
    "        practica = match_practica.group(1)\n",
    "    else:\n",
    "        practica = \"3\"  # Por defecto\n",
    "    \n",
    "    # Buscar grupo (patrones conocidos)\n",
    "    grupos_posibles = ['IWSIM11', 'IWSIM12', 'IWSIT11', 'IWSIT12', 'CITIM11', 'CITIM12', 'CITIT11', 'CITIT12']\n",
    "    \n",
    "    for grupo in grupos_posibles:\n",
    "        if grupo in nombre_alumno:\n",
    "            return grupo, practica\n",
    "    \n",
    "    return \"desconocido\", practica\n",
    "\n",
    "## Ejecutar la separación\n",
    "#archivo_a_separar = \"...\"\n",
    "#archivos_resultantes = separar_archivo_conjunto_y_mover(archivo_a_separar)\n",
    "\n",
    "#if archivos_resultantes:\n",
    "    #print(f\"\\n🎉 ¡Proceso completado exitosamente!\")\n",
    "    #print(f\"📊 Se crearon {len(archivos_resultantes)} archivos nuevos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
