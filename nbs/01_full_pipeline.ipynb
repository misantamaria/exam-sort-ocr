{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c650b6be",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eece59a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing required libraries\n",
    "from fastcore.all import AttrDict\n",
    "import io\n",
    "from pdf2image import convert_from_path\n",
    "from pypdf import PdfReader\n",
    "import openai\n",
    "import os\n",
    "import base64\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd \n",
    "import json\n",
    "import re\n",
    "import zipfile\n",
    "from pathlib import Path \n",
    "import unicodedata\n",
    "\n",
    "load_dotenv()  # Carga las variables de entorno desde .env"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed379e18",
   "metadata": {},
   "source": [
    "## Load moodle student information\n",
    "You must have downloaded\n",
    "- All deriverables\n",
    "- The full list of studens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fdc15791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load moodle students information\n",
    "import pandas as pd\n",
    "\n",
    "# Cargar el CSV de alumnos y grupos\n",
    "students_info = [\"./../data/courseid_422_participants.csv\", \"./../data/courseid_23101_participants.csv\"]\n",
    "dfs = [ pd.read_csv(filename) for filename in students_info ]\n",
    "\n",
    "df_students = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Puedes opcionalmente limpiar espacios y convertir a mayúsculas para facilitar coincidencias\n",
    "df_students[\"Nombre\"] = df_students[\"Nombre\"].str.strip().str.upper()\n",
    "df_students[\"Apellido(s)\"] = df_students[\"Apellido(s)\"].str.strip().str.upper()\n",
    "\n",
    "json_students = \"\\n\".join(\n",
    "    f\"{row['Nombre']} {row['Apellido(s)']} - Grupo: {row['Grupos']}\"\n",
    "    for _, row in df_students.iterrows()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20794ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = os.environ[\"OPENAI_API_KEY\"] # *\n",
    "prompt = \"\"\"Extract the last name (Apellidos in Spanish), the first name (Nombre in Spanish) and the group (Grupo in Spanish)\n",
    " from the top of the image. You will find them handwritten after the labels `Apellidos`,  `Nombre` and `Grupo` respectively. The fields of your JSON output will have those exact same label names\n",
    " Here is a list of expected students and their groups as a reference: \n",
    " {json_students}\n",
    " \"\"\" # *\n",
    "model = \"gpt-4o\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89daf133",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "  \"Content-Type\": \"application/json\",\n",
    "  \"Authorization\": f\"Bearer {api_key}\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4dd6f343",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdf_to_base64(pdf_path, crop_height=450):\n",
    "    images = convert_from_path(pdf_path)\n",
    "    images = [\n",
    "        image.crop((0, 0, image.width, crop_height))\n",
    "        for image in images\n",
    "    ]\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ad2187c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_openai_payload(image, model, prompt):\n",
    "    payload = {\n",
    "    \"model\": f'{model}',\n",
    "    \"response_format\": { \"type\": \"json_object\" },\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"system\", \n",
    "            \"content\": \"You are a helpful assistant designed to see an exam and output JSON \\\n",
    "            with the extracted information. You will be given an image of the exam.\\\n",
    "            the default group in case of empty string is extraviado\",   \n",
    "        },\n",
    "            {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": f\"{prompt}\"\n",
    "                },\n",
    "                {\n",
    "                \"type\": \"image_url\",\n",
    "                \"image_url\": {\n",
    "                    \"url\": f\"data:image/jpeg;base64,{image}\"\n",
    "                }\n",
    "                }\n",
    "            ]\n",
    "            }\n",
    "    ],\n",
    "    \"max_tokens\": 300\n",
    "    }\n",
    "    return payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ede2c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdf_openai_parser(pdf_path, model, prompt):\n",
    "    images = pdf_to_base64(pdf_path, crop_height=450)\n",
    "    \n",
    "    for i, image in enumerate(images):\n",
    "        # Convert image to base64\n",
    "        buffered = io.BytesIO()\n",
    "        image.save(buffered, format=\"JPEG\")\n",
    "        img_str = base64.b64encode(buffered.getvalue()).decode()\n",
    "        \n",
    "        # Create payload for this image\n",
    "        payload = img_openai_payload(img_str, model, prompt.format(guia_texto=guia_texto))\n",
    "        \n",
    "        # Make API request\n",
    "        response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            result = response.json()\n",
    "            try:\n",
    "                # Parse the JSON response\n",
    "                extracted_data = json.loads(result['choices'][0]['message']['content'])\n",
    "                \n",
    "                # Check if we have valid data (Apellidos, Nombre, and Grupo)\n",
    "                if all(key in extracted_data and extracted_data[key].strip() for key in ['Apellidos', 'Nombre', 'Grupo']):\n",
    "                    print(f\"Successfully extracted data from image {i+1}\")\n",
    "                    return extracted_data\n",
    "                else:\n",
    "                    print(f\"Image {i+1} missing required fields, trying next image...\")\n",
    "                    \n",
    "            except (json.JSONDecodeError, KeyError) as e:\n",
    "                print(f\"Error parsing response from image {i+1}: {e}, trying next image...\")\n",
    "        else:\n",
    "            print(f\"API request failed for image {i+1}: {response.status_code}\")\n",
    "    \n",
    "    print(\"No valid data found in any image\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b974bef",
   "metadata": {},
   "source": [
    "# Parse 1 exam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "903e31cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdf_openai_parser_safeGroup(pdf_path, model, prompt):\n",
    "    student_info = pdf_openai_parser(\n",
    "        pdf_path, \n",
    "        model = model, \n",
    "        prompt = prompt\n",
    "    )\n",
    "    if not student_info.get(\"Grupo\"):\n",
    "        student_info[\"Grupo\"] = \"extraviado\"\n",
    "    return student_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a511e4f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully extracted data from image 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Apellidos': 'RODRIGUEZ FERNANDEZ', 'Nombre': 'VICTOR', 'Grupo': 'Profesores'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_openai_parser_safeGroup(\n",
    "    pdf_path    = \"../example_data/1.pdf\",\n",
    "    model       = model,\n",
    "    prompt      = prompt.format(json_students=json_students)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656a92a7",
   "metadata": {},
   "source": [
    "# Process Scan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e629effe",
   "metadata": {},
   "source": [
    "You must have the scanneed pdf into the '../data/raw/ folder'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040a325d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para debug más fácil\n",
    "def renombrar_archivos_en_lotes(ruta=\"../data/raw/\"):\n",
    "\t\"\"\"\n",
    "\tRenombra todos los archivos en la carpeta dada como 'lote_1', 'lote_2', etc.\n",
    "\tConserva la extensión original de cada archivo.\n",
    "\t\"\"\"\n",
    "\tarchivos = sorted([f for f in os.listdir(ruta) if os.path.isfile(os.path.join(ruta, f))])\n",
    "\tfor idx, nombre_original in enumerate(archivos, start=1):\n",
    "\t\textension = os.path.splitext(nombre_original)[1]\n",
    "\t\tnuevo_nombre = f\"lote_{idx}{extension}\"\n",
    "\t\truta_origen = os.path.join(ruta, nombre_original)\n",
    "\t\truta_destino = os.path.join(ruta, nuevo_nombre)\n",
    "\t\tos.rename(ruta_origen, ruta_destino)\n",
    "\tprint(f\"Renombrados {len(archivos)} archivos en '{ruta}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86d32b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#renombrar_archivos_en_lotes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e78c0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si estás seguro de tu scanner usa esta función, lo lo recomiendo\n",
    "import os\n",
    "from pathlib import Path\n",
    "from pypdf import PdfReader, PdfWriter\n",
    "\n",
    "def crear_carpeta_examenes(base_dir=\"../data\", nombre_base=\"examenes\"):\n",
    "    \"\"\"\n",
    "    Crea una carpeta nueva para los exámenes. Si ya existe, añade un sufijo numérico.\n",
    "    \"\"\"\n",
    "    base_path = Path(base_dir)\n",
    "    carpeta = base_path / nombre_base\n",
    "    contador = 1\n",
    "    while carpeta.exists():\n",
    "        carpeta = base_path / f\"{nombre_base}_{contador}\"\n",
    "        contador += 1\n",
    "    carpeta.mkdir(parents=True)\n",
    "    return carpeta\n",
    "\n",
    "def dividir_pdf_en_examenes(pdf_path, carpeta_destino, nombre_base=\"examen\"):\n",
    "    \"\"\"\n",
    "    Divide un PDF en archivos de 2 páginas cada uno y los guarda en la carpeta destino.\n",
    "    \"\"\"\n",
    "    reader = PdfReader(pdf_path)\n",
    "    num_paginas = len(reader.pages)\n",
    "    examen_idx = 1\n",
    "    for i in range(0, num_paginas, 2):\n",
    "        writer = PdfWriter()\n",
    "        writer.add_page(reader.pages[i])\n",
    "        if i+1 < num_paginas:\n",
    "            writer.add_page(reader.pages[i+1])\n",
    "        nombre_examen = f\"{nombre_base}_{examen_idx}.pdf\"\n",
    "        ruta_examen = carpeta_destino / nombre_examen\n",
    "        with open(ruta_examen, \"wb\") as f_out:\n",
    "            writer.write(f_out)\n",
    "        examen_idx += 1\n",
    "\n",
    "def procesar_lotes_y_generar_examenes(ruta_lotes=\"../data/raw/\", base_dir=\"../data\", nombre_carpeta=\"examenes\"):\n",
    "    \"\"\"\n",
    "    Busca todos los archivos PDF en la carpeta de lotes, los divide de 2 en 2 páginas y los guarda en una carpeta nueva.\n",
    "    \"\"\"\n",
    "    carpeta_destino = crear_carpeta_examenes(base_dir, nombre_carpeta)\n",
    "    archivos_lote = sorted([f for f in os.listdir(ruta_lotes) if f.lower().endswith(\".pdf\")])\n",
    "    examen_global_idx = 1\n",
    "    for archivo in archivos_lote:\n",
    "        ruta_pdf = Path(ruta_lotes) / archivo\n",
    "        reader = PdfReader(ruta_pdf)\n",
    "        num_paginas = len(reader.pages)\n",
    "        for i in range(0, num_paginas, 2):\n",
    "            writer = PdfWriter()\n",
    "            writer.add_page(reader.pages[i])\n",
    "            if i+1 < num_paginas:\n",
    "                writer.add_page(reader.pages[i+1])\n",
    "            nombre_examen = f\"examen_{examen_global_idx}.pdf\"\n",
    "            ruta_examen = carpeta_destino / nombre_examen\n",
    "            with open(ruta_examen, \"wb\") as f_out:\n",
    "                writer.write(f_out)\n",
    "            examen_global_idx += 1\n",
    "    print(f\"Exámenes generados en: {carpeta_destino}\")\n",
    "\n",
    "# Ejemplo de uso:\n",
    "#procesar_lotes_y_generar_examenes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500aaad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from pdf2image import convert_from_path\n",
    "from pypdf import PdfReader, PdfWriter\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import Button, HBox, VBox, Output, Layout, Label, Dropdown\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "class JupyterPDFReviewer:\n",
    "    def __init__(self, pdf_path):\n",
    "        self.pdf_path = pdf_path\n",
    "        self.reader = PdfReader(pdf_path)\n",
    "        self.total_pages = len(self.reader.pages)\n",
    "        self.current_index = 0\n",
    "        self.images = {}\n",
    "        self.output_dir = Path(\"../data/saved\")\n",
    "        self.output_dir.mkdir(parents=True, exist_ok=True)\n",
    "        self.out = Output()\n",
    "        self.status = Label(value=\"\")  # Estado visual\n",
    "        self._setup_widgets()\n",
    "        self._show_pages()\n",
    "\n",
    "    def _setup_widgets(self):\n",
    "        self.btn_save1 = Button(description='Save Page 1', layout=Layout(width='120px'))\n",
    "        self.btn_save12 = Button(description='Save Pages 1&2', layout=Layout(width='120px'))\n",
    "        self.btn_save123 = Button(description='Save Pages 1-3', layout=Layout(width='120px'))\n",
    "        self.btn_next = Button(description='Next (Skip 1)', layout=Layout(width='120px'))\n",
    "        self.btn_prev = Button(description='Previous', layout=Layout(width='120px'))\n",
    "\n",
    "        self.btn_save1.on_click(lambda x: self._save_pages([0]))\n",
    "        self.btn_save12.on_click(lambda x: self._save_pages([0, 1]))\n",
    "        self.btn_save123.on_click(lambda x: self._save_pages([0, 1, 2]))\n",
    "        self.btn_next.on_click(lambda x: self._next_page())\n",
    "        self.btn_prev.on_click(lambda x: self._prev_page())\n",
    "\n",
    "        display(VBox([\n",
    "            HBox([self.btn_prev, self.btn_save1, self.btn_save12, self.btn_save123, self.btn_next]),\n",
    "            self.status,\n",
    "            self.out\n",
    "        ]))\n",
    "\n",
    "    def _get_page_image(self, idx):\n",
    "        if idx not in self.images and idx < self.total_pages:\n",
    "            self.status.value = f\"Cargando página {idx+1}...\"\n",
    "            try:\n",
    "                img = convert_from_path(\n",
    "                    self.pdf_path,\n",
    "                    first_page=idx + 1,\n",
    "                    last_page=idx + 1,\n",
    "                    dpi=50,\n",
    "                    fmt='jpeg',\n",
    "                    thread_count=1\n",
    "                )[0]\n",
    "                self.images[idx] = img\n",
    "            except Exception as e:\n",
    "                self.status.value = f\"Error cargando página {idx+1}\"\n",
    "                print(f\"Error converting page {idx+1}: {e}\")\n",
    "                return None\n",
    "        self.status.value = \"\"\n",
    "        return self.images.get(idx)\n",
    "\n",
    "    def _show_pages(self):\n",
    "        with self.out:\n",
    "            clear_output(wait=True)\n",
    "            fig, axes = plt.subplots(1, 3, figsize=(15, 8))\n",
    "            for i in range(3):\n",
    "                page_idx = self.current_index + i\n",
    "                axes[i].axis('off')\n",
    "                if page_idx < self.total_pages:\n",
    "                    img = self._get_page_image(page_idx)\n",
    "                    if img is not None:\n",
    "                        axes[i].imshow(img)\n",
    "                        axes[i].set_title(f\"Page {page_idx+1}\")\n",
    "                    else:\n",
    "                        axes[i].set_title(f\"Page {page_idx+1} (error)\")\n",
    "                else:\n",
    "                    axes[i].set_title(\"No Page\")\n",
    "            plt.show()\n",
    "\n",
    "    def _next_page(self):\n",
    "        if self.current_index + 1 < self.total_pages:\n",
    "            self.current_index += 1\n",
    "            self._show_pages()\n",
    "\n",
    "    def _prev_page(self):\n",
    "        if self.current_index >= 1:\n",
    "            self.current_index -= 1\n",
    "            self._show_pages()\n",
    "\n",
    "    def _save_pages(self, rel_indices):\n",
    "        abs_indices = [self.current_index + i for i in rel_indices if self.current_index + i < self.total_pages]\n",
    "        if not abs_indices:\n",
    "            self.status.value = \"No valid pages to save\"\n",
    "            return\n",
    "\n",
    "        base_name = Path(self.pdf_path).stem  # Ejemplo: 'lote_1'\n",
    "        lote = base_name\n",
    "        examen_n = abs_indices[0] + 1  # Primer índice de página + 1\n",
    "        output_path = self.output_dir / f\"{lote}_examen_{examen_n}.pdf\"\n",
    "\n",
    "        writer = PdfWriter()\n",
    "        for idx in abs_indices:\n",
    "            writer.add_page(self.reader.pages[idx])\n",
    "        with open(output_path, \"wb\") as f:\n",
    "            writer.write(f)\n",
    "        self.status.value = f\"Guardado: {output_path.name}\"\n",
    "\n",
    "        # Avanzar tantas páginas como se han guardado\n",
    "        avance = len(abs_indices)\n",
    "        if self.current_index + avance < self.total_pages:\n",
    "            self.current_index += avance\n",
    "            self._show_pages()\n",
    "\n",
    "def revisar_todos_los_lotes(ruta_lotes=\"../data/raw/\"):\n",
    "    archivos = sorted([f for f in os.listdir(ruta_lotes) if f.lower().endswith(\".pdf\")])\n",
    "    if not archivos:\n",
    "        print(\"No se encontraron lotes PDF en la carpeta.\")\n",
    "        return\n",
    "    dropdown = Dropdown(options=archivos, description='Lote:', layout=Layout(width='50%'))\n",
    "    out = Output()\n",
    "\n",
    "    def on_select(change):\n",
    "        with out:\n",
    "            clear_output(wait=True)\n",
    "            print(f\"Revisando: {dropdown.value}\")\n",
    "            JupyterPDFReviewer(os.path.join(ruta_lotes, dropdown.value))\n",
    "\n",
    "    dropdown.observe(on_select, names='value')\n",
    "    display(VBox([dropdown, out]))\n",
    "    # Mostrar el primero por defecto\n",
    "    on_select({'new': archivos[0]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c1c1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#revisar_todos_los_lotes(\"../data/raw/\") # --> solo cuando necesites procesar los lotes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b147cc4",
   "metadata": {},
   "source": [
    "## Procesar examenes con OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e734700d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import base64\n",
    "from pathlib import Path\n",
    "from pdf2image import convert_from_path\n",
    "from pypdf import PdfReader\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import io\n",
    "import requests\n",
    "from rapidfuzz import fuzz\n",
    "import re\n",
    "import unicodedata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "cc0ef4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpiar_texto(texto):\n",
    "    \"\"\"Elimina acentos, símbolos y deja solo letras/números/espacios en mayúsculas\"\"\"\n",
    "    if not texto:\n",
    "        return \"\"\n",
    "    texto = unicodedata.normalize('NFD', texto)\n",
    "    texto = ''.join(c for c in texto if unicodedata.category(c) != 'Mn')\n",
    "    texto = texto.upper()\n",
    "    texto = re.sub(r'[^A-Z0-9\\s]', '', texto)\n",
    "    texto = texto.strip()\n",
    "    return texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "70900574",
   "metadata": {},
   "outputs": [],
   "source": [
    "def buscar_grupo_flexible(nombre, apellidos, df, texto_ocr=None, umbral=90):\n",
    "    \"\"\"\n",
    "    Busca el grupo del alumno en el DataFrame por nombre y apellidos usando fuzzy.\n",
    "    Si no encuentra por el umbral, devuelve el grupo más parecido aunque el score sea bajo (mínimo 20%).\n",
    "    \"\"\"\n",
    "    nombre = limpiar_texto(nombre)\n",
    "    apellidos = limpiar_texto(apellidos)\n",
    "    mejor_score = -1\n",
    "    mejor_grupo = None\n",
    "    mejor_nombre = \"\"\n",
    "    mejor_apellidos = \"\"\n",
    "    for _, row in df.iterrows():\n",
    "        nombre_df = limpiar_texto(str(row[\"Nombre\"]))\n",
    "        apellidos_df = limpiar_texto(str(row[\"Apellido(s)\"]))\n",
    "        score_nombre = fuzz.ratio(nombre, nombre_df)\n",
    "        score_apellidos = fuzz.ratio(apellidos, apellidos_df)\n",
    "        score = (score_nombre + score_apellidos) / 2\n",
    "        if score > mejor_score:\n",
    "            mejor_score = score\n",
    "            mejor_grupo = row[\"Grupos\"]\n",
    "            mejor_nombre = row[\"Nombre\"]\n",
    "            mejor_apellidos = row[\"Apellido(s)\"]\n",
    "    # Si supera el umbral, devuelve el grupo y nombre exactos\n",
    "    if mejor_score >= umbral:\n",
    "        return mejor_grupo, mejor_nombre, mejor_apellidos\n",
    "    # Si no supera el umbral pero hay algún match > 20%, devuelve el más parecido\n",
    "    if mejor_score >= 20:\n",
    "        return mejor_grupo, mejor_nombre, mejor_apellidos\n",
    "    # Si no hay nada ni con 20%, busca patrón OCR\n",
    "    if texto_ocr:\n",
    "        texto_ocr = texto_ocr.upper()\n",
    "        patrones = [\n",
    "            r\"CITI[TM][1][12]\", r\"IWSI[TM][1][12]\", r\"IWSIT[1][12]\", r\"CITIT[1][12]\", r\"IWSIM[1][12]\"\n",
    "        ]\n",
    "        for patron in patrones:\n",
    "            match = re.search(patron, texto_ocr)\n",
    "            if match:\n",
    "                return match.group(0), \"\", \"\"\n",
    "    return \"extraviado\", \"\", \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "10f60b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraer_info_con_openai(base64_image, headers, df):\n",
    "    try:\n",
    "        prompt_completo = (\n",
    "            \"Extract the last name (Apellidos in Spanish), \"\n",
    "            \"the first name (Nombre in Spanish) from the top of the image. \"\n",
    "            \"Extract also the group (Grupo in Spanish) from the top of the image. \"\n",
    "            \"You will find them handwritten after the labels `Apellidos` and `Nombre` and `Group` respectively. \"\n",
    "            \"The fields of your JSON output will have those exact same label names. \"\n",
    "            \"Also determine if this is a \\\"Práctica de Listas\\\" (practice 3) or \\\"Práctica de Grafos\\\" (practice 5) based on the content. \"\n",
    "            \"Add a field called \\\"practica_detectada\\\" with value 3 for listas or 5 for grafos. \"\n",
    "            \"If you see a group label like CITIM11, CITIM12, IWSIM11, IWSIM12, CITIT11, IWSIT11, IWSIT12, include it as the field 'Grupo'.\"\n",
    "        )\n",
    "        payload = {\n",
    "            \"model\": \"gpt-4o\",\n",
    "            \"response_format\": {\"type\": \"json_object\"},\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": \"You are a helpful assistant designed to see an exam and output JSON with the extracted information.\"\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\"type\": \"text\", \"text\": prompt_completo},\n",
    "                        {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{base64_image}\"}}\n",
    "                    ]\n",
    "                }\n",
    "            ],\n",
    "            \"max_tokens\": 300\n",
    "        }\n",
    "        try:\n",
    "            response = requests.post(\n",
    "                \"https://api.openai.com/v1/chat/completions\",\n",
    "                headers=headers,\n",
    "                json=payload,\n",
    "                timeout=10\n",
    "            )\n",
    "        except requests.exceptions.Timeout:\n",
    "            return None, \"Timeout: La petición a OpenAI tardó más de 10 segundos.\"\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            return None, f\"Error de conexión con OpenAI: {e}\"\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            info_str = response.json()['choices'][0]['message']['content']\n",
    "            try:\n",
    "                info = json.loads(info_str)\n",
    "                nombre_ocr = info.get(\"Nombre\", \"\")\n",
    "                apellidos_ocr = info.get(\"Apellidos\", \"\")\n",
    "                grupo_ocr = info.get(\"Grupo\", \"\")\n",
    "                grupo, nombre, apellidos = buscar_grupo_flexible(nombre_ocr, apellidos_ocr, df, texto_ocr=grupo_ocr)\n",
    "                info[\"Grupo\"] = grupo\n",
    "                # Si se encontró en el excel, usa los nombres del excel (más limpios)\n",
    "                if grupo != \"extraviado\" and nombre and apellidos:\n",
    "                    info[\"Nombre\"] = nombre\n",
    "                    info[\"Apellidos\"] = apellidos\n",
    "                else:\n",
    "                    # Si no, limpia los nombres extraídos por OCR\n",
    "                    info[\"Nombre\"] = limpiar_texto(nombre_ocr)\n",
    "                    info[\"Apellidos\"] = limpiar_texto(apellidos_ocr)\n",
    "                if grupo == \"extraviado\" and grupo_ocr:\n",
    "                    info[\"Grupo_detectado\"] = grupo_ocr\n",
    "                return info, None\n",
    "            except json.JSONDecodeError as e:\n",
    "                return None, f\"Error parseando JSON: {e}\\nRespuesta recibida: {info_str}\"\n",
    "        else:\n",
    "            return None, f\"Error en API OpenAI: {response.status_code} - {response.text}\"\n",
    "    except Exception as e:\n",
    "        return None, f\"Error extrayendo información: {e}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0289d31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraer_solo_practica(base64_image, headers):\n",
    "    try:\n",
    "        prompt_practica = (\n",
    "            \"Look at this exam image and determine if this is a \\\"Práctica de Listas\\\" (practice 3) \"\n",
    "            \"or \\\"Práctica de Grafos\\\" (practice 5) based on the content. \"\n",
    "            \"Return JSON with fields: \\\"Apellidos\\\": \\\"\\\", \\\"Nombre\\\": \\\"\\\", \\\"Grupo\\\": \\\"extraviado\\\", \\\"practica_detectada\\\": 3 or 5\"\n",
    "        )\n",
    "        payload = {\n",
    "            \"model\": \"gpt-4o\",\n",
    "            \"response_format\": {\"type\": \"json_object\"},\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": \"You are a helpful assistant that identifies exam types and outputs JSON.\",\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\"type\": \"text\", \"text\": prompt_practica},\n",
    "                        {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{base64_image}\"}}\n",
    "                    ]\n",
    "                }\n",
    "            ],\n",
    "            \"max_tokens\": 150\n",
    "        }\n",
    "        try:\n",
    "            response = requests.post(\n",
    "                \"https://api.openai.com/v1/chat/completions\",\n",
    "                headers=headers,\n",
    "                json=payload,\n",
    "                timeout=10\n",
    "            )\n",
    "        except requests.exceptions.Timeout:\n",
    "            return None, \"Timeout: La petición a OpenAI tardó más de 10 segundos (solo práctica).\"\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            return None, f\"Error de conexión con OpenAI (solo práctica): {e}\"\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            info_str = response.json()['choices'][0]['message']['content']\n",
    "            try:\n",
    "                info = json.loads(info_str)\n",
    "                return info, None\n",
    "            except json.JSONDecodeError:\n",
    "                return None, f\"Error parseando JSON (solo práctica): {info_str}\"\n",
    "        else:\n",
    "            return None, f\"Error en API OpenAI (solo práctica): {response.status_code} - {response.text}\"\n",
    "    except Exception as e:\n",
    "        return None, f\"Error en retry de práctica: {e}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "76ac0853",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraer_numero_lote(nombre):\n",
    "    match = re.search(r\"lote_(\\d+)\", nombre)\n",
    "    return int(match.group(1)) if match else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "cf5c1580",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mover_archivo_organizado(archivo_original, info, output_path):\n",
    "    try:\n",
    "        practica = info.get('practica_detectada', 'desconocida')\n",
    "        grupo = info.get('Grupo', 'extraviado')\n",
    "        carpeta_grupo = output_path / grupo\n",
    "        carpeta_practica = carpeta_grupo / f\"Practica_{practica}\"\n",
    "        carpeta_practica.mkdir(parents=True, exist_ok=True)\n",
    "        apellidos = info.get('Apellidos', '').strip()\n",
    "        nombre = info.get('Nombre', '').strip()\n",
    "        if grupo == \"extraviado\" and not apellidos and not nombre:\n",
    "            nombre_base = Path(info.get('archivo_original', archivo_original.name)).stem\n",
    "        else:\n",
    "            apellidos = apellidos if apellidos else 'SinApellidos'\n",
    "            nombre = nombre if nombre else 'SinNombre'\n",
    "            nombre_base = f\"{apellidos.replace(' ', '_')}_{nombre.replace(' ', '_')}\"\n",
    "            if grupo == \"extraviado\" and info.get('Grupo_detectado'):\n",
    "                nombre_base += f\"_{info['Grupo_detectado']}\"\n",
    "        extension = archivo_original.suffix\n",
    "        nuevo_archivo = carpeta_practica / f\"{nombre_base}{extension}\"\n",
    "        contador = 2\n",
    "        while nuevo_archivo.exists():\n",
    "            nuevo_archivo = carpeta_practica / f\"{nombre_base}_{contador}{extension}\"\n",
    "            contador += 1\n",
    "        shutil.copy2(archivo_original, nuevo_archivo)\n",
    "        print(f\"  → Guardado en: {carpeta_grupo.name}/{carpeta_practica.name}/{nuevo_archivo.name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error organizando archivo {archivo_original.name}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "559ee159",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crear_dataframe_examenes(examenes_info, df):\n",
    "    df_base = df[['Nombre', 'Apellido(s)', 'Grupos']].copy()\n",
    "    df_base['Examen_3'] = 0\n",
    "    df_base['Comentario_Examen_3'] = 'PNP'\n",
    "    df_base['Examen_5'] = 0\n",
    "    df_base['Comentario_Examen_5'] = 'PNP'\n",
    "    for examen in examenes_info:\n",
    "        practica = examen.get('practica_detectada')\n",
    "        if practica in [3, 5, '3', '5']:\n",
    "            practica = str(practica)\n",
    "            apellidos = examen.get('Apellidos', '').upper().strip()\n",
    "            nombre = examen.get('Nombre', '').upper().strip()\n",
    "            if apellidos and nombre:\n",
    "                mask = df_base['Apellido(s)'].str.upper().str.strip() == apellidos\n",
    "                mask &= df_base['Nombre'].str.upper().str.strip() == nombre\n",
    "                if mask.any():\n",
    "                    df_base.loc[mask, f'Examen_{practica}'] = 1\n",
    "                    df_base.loc[mask, f'Comentario_Examen_{practica}'] = ''\n",
    "                    print(f\"  → Marcado como presentado: {nombre} {apellidos} - Práctica {practica}\")\n",
    "    return df_base\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9291ff2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def procesar_examenes_completo(carpeta_examenes=\"../data/saved/\", output_dir=\"../data/examenes_procesados/\"):\n",
    "    output_path = Path(output_dir)\n",
    "    output_path.mkdir(parents=True, exist_ok=True)\n",
    "    extraviados_path = output_path / \"extraviados\"\n",
    "    extraviados_path.mkdir(parents=True, exist_ok=True)\n",
    "    examenes_info = []\n",
    "    errores_openai = []\n",
    "    # Ordenar por número de lote, no alfabéticamente\n",
    "    pdf_files = sorted(Path(carpeta_examenes).glob(\"*.pdf\"), key=lambda x: extraer_numero_lote(x.name))\n",
    "    print(f\"Procesando {len(pdf_files)} exámenes...\")\n",
    "    api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {api_key}\"\n",
    "    }\n",
    "    # Cargar DataFrame de alumnos\n",
    "    students_info = [\"./../data/courseid_422_participants.csv\", \"./../data/courseid_23101_participants.csv\"]\n",
    "    dfs = [ pd.read_csv(filename) for filename in students_info ]\n",
    "    df = pd.concat(dfs, ignore_index=True)\n",
    "    df[\"Nombre\"] = df[\"Nombre\"].str.strip().str.upper()\n",
    "    df[\"Apellido(s)\"] = df[\"Apellido(s)\"].str.strip().str.upper()\n",
    "    for pdf_file in pdf_files:\n",
    "        print(f\"\\nProcesando: {pdf_file.name}\")\n",
    "        try:\n",
    "            reader = PdfReader(pdf_file)\n",
    "            num_pages = len(reader.pages)\n",
    "            info_extraida = None\n",
    "            error_detalle = None\n",
    "            for page_num in range(min(2, num_pages)):\n",
    "                images = convert_from_path(\n",
    "                    pdf_file,\n",
    "                    first_page=page_num + 1,\n",
    "                    last_page=page_num + 1,\n",
    "                    dpi=150,\n",
    "                    fmt='jpeg'\n",
    "                )\n",
    "                if not images:\n",
    "                    continue\n",
    "                buffered = io.BytesIO()\n",
    "                images[0].save(buffered, format=\"JPEG\")\n",
    "                base64_image = base64.b64encode(buffered.getvalue()).decode('utf-8')\n",
    "                info, error = extraer_info_con_openai(base64_image, headers, df)\n",
    "                if info and info.get('Apellidos') and info.get('Nombre'):\n",
    "                    info['archivo_original'] = pdf_file.name\n",
    "                    info['pagina'] = page_num + 1\n",
    "                    info_extraida = info\n",
    "                    break\n",
    "                elif info and not info.get('Apellidos'):\n",
    "                    info_retry, error_retry = extraer_solo_practica(base64_image, headers)\n",
    "                    if info_retry:\n",
    "                        info_extraida = info_retry\n",
    "                        info_extraida['archivo_original'] = pdf_file.name\n",
    "                        info_extraida['pagina'] = page_num + 1\n",
    "                        break\n",
    "                    elif error_retry:\n",
    "                        error_detalle = error_retry\n",
    "                elif error:\n",
    "                    error_detalle = error\n",
    "            if info_extraida:\n",
    "                mover_archivo_organizado(pdf_file, info_extraida, output_path)\n",
    "                examenes_info.append(info_extraida)\n",
    "                practica = info_extraida.get('practica_detectada', 'desconocida')\n",
    "                print(f\"✓ Extraído: {info_extraida.get('Nombre', 'Sin nombre')} {info_extraida.get('Apellidos', 'Sin apellidos')} - Grupo: {info_extraida.get('Grupo', 'extraviado')} - Práctica: {practica}\")\n",
    "            else:\n",
    "                shutil.copy2(pdf_file, extraviados_path / pdf_file.name)\n",
    "                print(f\"✗ No se pudo extraer información - Copiado a extraviados: {pdf_file.name}\")\n",
    "                errores_openai.append({\n",
    "                    \"archivo\": pdf_file.name,\n",
    "                    \"error\": error_detalle or \"No se pudo extraer información ni con retry\",\n",
    "                })\n",
    "        except Exception as e:\n",
    "            print(f\"✗ Error procesando {pdf_file.name}: {e}\")\n",
    "            try:\n",
    "                shutil.copy2(pdf_file, extraviados_path / pdf_file.name)\n",
    "                print(f\"  → Copiado a extraviados por error\")\n",
    "            except:\n",
    "                pass\n",
    "            errores_openai.append({\n",
    "                \"archivo\": pdf_file.name,\n",
    "                \"error\": str(e),\n",
    "            })\n",
    "            continue\n",
    "    df_examenes = crear_dataframe_examenes(examenes_info, df)\n",
    "    df_examenes.to_csv(output_path / \"seguimiento_examenes.csv\", index=False)\n",
    "    print(f\"\\n📊 Procesamiento completado:\")\n",
    "    print(f\"- Exámenes procesados: {len(examenes_info)}\")\n",
    "    print(f\"- Archivos en extraviados: {len(list(extraviados_path.glob('*.pdf')))}\")\n",
    "    print(f\"- Archivo de seguimiento guardado en: {output_path / 'seguimiento_examenes.csv'}\")\n",
    "    # Crear DataFrame de errores y mostrarlo\n",
    "    if errores_openai:\n",
    "        df_errores = pd.DataFrame(errores_openai)\n",
    "        df_errores.to_csv(output_path / \"errores_openai.csv\", index=False)\n",
    "        print(f\"\\n❗ Casos fallidos por OpenAI guardados en: {output_path / 'errores_openai.csv'}\")\n",
    "        print(df_errores)\n",
    "    else:\n",
    "        print(\"\\n✅ No hubo errores de extracción con OpenAI.\")\n",
    "    return df_examenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0cb8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejecutar el procesamiento\n",
    "#df_examenes_procesados = procesar_examenes_completo()\n",
    "print(\"\\n📊 Resumen de exámenes procesados por grupo:\")\n",
    "#print(df_examenes_procesados.groupby('Grupos')[['Examen_3', 'Examen_5']].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616fb86e",
   "metadata": {},
   "source": [
    "### Versión visual (más segura con diferencia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "852c6098",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from pdf2image import convert_from_path\n",
    "from pypdf import PdfReader\n",
    "from ipywidgets import Button, HBox, VBox, Output, Layout, Label, Combobox, Dropdown, HTML, ToggleButtons\n",
    "from IPython.display import display, clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from difflib import get_close_matches\n",
    "import re\n",
    "\n",
    "# --- Cargar el DataFrame de alumnos (ajusta la ruta si es necesario) ---\n",
    "students_info = [\"./../data/courseid_422_participants.csv\", \"./../data/courseid_23101_participants.csv\"]\n",
    "dfs = [pd.read_csv(filename) for filename in students_info]\n",
    "df = pd.concat(dfs, ignore_index=True)\n",
    "df[\"Nombre\"] = df[\"Nombre\"].str.strip().str.upper()\n",
    "df[\"Apellido(s)\"] = df[\"Apellido(s)\"].str.strip().str.upper()\n",
    "df[\"Grupos\"] = df[\"Grupos\"].astype(str).str.strip()\n",
    "\n",
    "# Lista de nombres completos para autocompletar\n",
    "nombres_completos = [\n",
    "    f\"{row['Apellido(s)']} {row['Nombre']}\" for _, row in df.iterrows()\n",
    "]\n",
    "nombre_a_grupo = {\n",
    "    f\"{row['Apellido(s)']} {row['Nombre']}\": row['Grupos'] for _, row in df.iterrows()\n",
    "}\n",
    "\n",
    "class JupyterExamReviewer:\n",
    "    def __init__(self, examenes_dir=\"../data/examenes_procesados/\"):\n",
    "        self.examenes_dir = Path(examenes_dir)\n",
    "        self.current_index = 0\n",
    "        self.exam_files = []\n",
    "        self.out = Output()\n",
    "        self.status = Label(value=\"Cargando exámenes...\")\n",
    "\n",
    "        # Cargar todos los archivos PDF\n",
    "        self._load_exam_files()\n",
    "\n",
    "        if not self.exam_files:\n",
    "            self.status.value = \"No se encontraron exámenes para revisar\"\n",
    "            return\n",
    "\n",
    "        # Configurar widgets\n",
    "        self._setup_widgets()\n",
    "        self._show_current_exam()\n",
    "\n",
    "    def _load_exam_files(self):\n",
    "        print(\"🔍 Escaneando carpetas de exámenes...\")\n",
    "        for grupo_dir in self.examenes_dir.iterdir():\n",
    "            if grupo_dir.is_dir():\n",
    "                for practica_dir in grupo_dir.iterdir():\n",
    "                    if practica_dir.is_dir():\n",
    "                        for pdf_file in practica_dir.glob(\"*.pdf\"):\n",
    "                            self.exam_files.append({\n",
    "                                'file_path': pdf_file,\n",
    "                                'carpeta_actual': grupo_dir.name,\n",
    "                                'practica': practica_dir.name if practica_dir.name.startswith(\"Practica_\") else \"\",\n",
    "                                'nombre_archivo': pdf_file.stem\n",
    "                            })\n",
    "                # También incluir PDFs sueltos en la carpeta (por si acaso)\n",
    "                for pdf_file in grupo_dir.glob(\"*.pdf\"):\n",
    "                    self.exam_files.append({\n",
    "                        'file_path': pdf_file,\n",
    "                        'carpeta_actual': grupo_dir.name,\n",
    "                        'practica': \"\",\n",
    "                        'nombre_archivo': pdf_file.stem\n",
    "                    })\n",
    "        self.exam_files.sort(key=lambda x: (x['carpeta_actual'], x['nombre_archivo']))\n",
    "        print(f\"📁 Total de exámenes encontrados: {len(self.exam_files)}\")\n",
    "\n",
    "    def _setup_widgets(self):\n",
    "        # Status (ruta de archivo) - arriba\n",
    "        self.status.layout = Layout(width='100%')\n",
    "        \n",
    "        # Nombre del alumno (principal)\n",
    "        self.combo_nombre = Combobox(\n",
    "            placeholder='Escribe o selecciona...',\n",
    "            options=nombres_completos,\n",
    "            description='Alumno:',\n",
    "            layout=Layout(width='450px')\n",
    "        )\n",
    "        self.combo_nombre.observe(self._on_nombre_change, names='value')\n",
    "\n",
    "        # Botón de aplicar cambios\n",
    "        self.btn_apply = Button(\n",
    "            description='✓ Aplicar',\n",
    "            button_style='success',\n",
    "            layout=Layout(width='80px')\n",
    "        )\n",
    "        \n",
    "        # Botón para eliminar archivo (NUEVO)\n",
    "        self.btn_delete = Button(\n",
    "            description='🗑️ Eliminar',\n",
    "            button_style='danger',\n",
    "            layout=Layout(width='90px')\n",
    "        )\n",
    "        \n",
    "        # Contador de progreso\n",
    "        self.progress_label = Label(value=\"\", layout=Layout(width='140px'))\n",
    "\n",
    "        # Widgets de grupo, práctica y carpeta\n",
    "        grupos_unicos = sorted(df[\"Grupos\"].unique())\n",
    "        self.dropdown_grupo = Dropdown(\n",
    "            options=grupos_unicos,\n",
    "            description='Grupo:',\n",
    "            layout=Layout(width='280px')  # Más ancho para que se vea bien\n",
    "        )\n",
    "\n",
    "        self.dropdown_practica = Dropdown(\n",
    "            options=['2', '3', '4', '5'],\n",
    "            description='Práctica:',\n",
    "            layout=Layout(width='180px')\n",
    "        )\n",
    "\n",
    "        # Selector de carpeta destino\n",
    "        carpetas_disponibles = [d.name for d in self.examenes_dir.iterdir() if d.is_dir()]\n",
    "        self.dropdown_carpeta = Dropdown(\n",
    "            options=carpetas_disponibles,\n",
    "            description='Carpeta:',\n",
    "            layout=Layout(width='170px')\n",
    "        )\n",
    "        self.dropdown_carpeta.observe(self._on_carpeta_change, names='value')\n",
    "\n",
    "        # HTML para mostrar sugerencias de nombres similares (horizontal)\n",
    "        self.similares_html = HTML(value=\"\", layout=Layout(width='100%', max_height='60px'))\n",
    "\n",
    "        # Botones de navegación \n",
    "        self.btn_prev = Button(description='← Anterior', layout=Layout(width='120px'))\n",
    "        self.btn_next = Button(description='Siguiente →', layout=Layout(width='120px'))\n",
    "        \n",
    "        # Selector de página ajustado (botones a la derecha del texto)\n",
    "        self.page_label = Label(value=\"Ver pág:\", layout=Layout(width='50px'))\n",
    "        self.page_selector = ToggleButtons(\n",
    "            options=[('1', 1), ('2', 2)],\n",
    "            value=1,\n",
    "            description='',  # Quitamos la descripción del control y la ponemos separada\n",
    "            style={'button_width': '30px'},\n",
    "            layout=Layout(width='80px')\n",
    "        )\n",
    "        \n",
    "        self.page_selector.observe(self._on_page_change, names='value')\n",
    "\n",
    "        # Conectar eventos\n",
    "        self.btn_prev.on_click(lambda x: self._navigate(-1))\n",
    "        self.btn_next.on_click(lambda x: self._navigate(1))\n",
    "        self.btn_apply.on_click(lambda x: self._apply_changes())\n",
    "        self.btn_delete.on_click(lambda x: self._delete_current_file())  # NUEVO\n",
    "\n",
    "        # REORGANIZACIÓN DE LA INTERFAZ:\n",
    "        \n",
    "        # Fila 1: Path/status (menos importante, arriba)\n",
    "        status_row = HBox([self.status])\n",
    "        \n",
    "        # Fila 2: Nombre + aplicar + eliminar + progreso (MODIFICADO)\n",
    "        nombre_row = HBox([\n",
    "            self.combo_nombre,\n",
    "            self.btn_apply,\n",
    "            self.btn_delete,  # NUEVO\n",
    "            self.progress_label\n",
    "        ])\n",
    "        \n",
    "        # Fila 3: Grupo, práctica, carpeta (más visibles)\n",
    "        opciones_row = HBox([\n",
    "            self.dropdown_grupo,\n",
    "            self.dropdown_practica, \n",
    "            self.dropdown_carpeta\n",
    "        ])\n",
    "        \n",
    "        # Fila 4: Sugerencias similares (a lo ancho)\n",
    "        sugerencias_row = HBox([self.similares_html])\n",
    "        \n",
    "        # Fila 5: Navegación (abajo) + selector de páginas en línea\n",
    "        page_selector_group = HBox([\n",
    "            self.page_label, \n",
    "            self.page_selector\n",
    "            ], \n",
    "            layout=Layout(width='140px')\n",
    "        )\n",
    "        nav_row = HBox([\n",
    "            self.btn_prev,\n",
    "            self.btn_next,\n",
    "            page_selector_group\n",
    "        ])  \n",
    "\n",
    "        # Layout general\n",
    "        self.interface = VBox([\n",
    "            status_row,\n",
    "            nombre_row,\n",
    "            opciones_row,\n",
    "            sugerencias_row,\n",
    "            nav_row,\n",
    "            self.out\n",
    "        ])\n",
    "\n",
    "        display(self.interface)\n",
    "\n",
    "    def _delete_current_file(self):\n",
    "        \"\"\"Elimina el archivo actual (NUEVO MÉTODO)\"\"\"\n",
    "        if not self.exam_files:\n",
    "            return\n",
    "            \n",
    "        current_exam = self.exam_files[self.current_index]\n",
    "        file_path = current_exam['file_path']\n",
    "        \n",
    "        try:\n",
    "            # Crear carpeta de eliminados si no existe\n",
    "            deleted_folder = self.examenes_dir / \"eliminados\"\n",
    "            deleted_folder.mkdir(exist_ok=True)\n",
    "            \n",
    "            # Mover a la carpeta de eliminados en lugar de eliminar permanentemente\n",
    "            deleted_path = deleted_folder / file_path.name\n",
    "            \n",
    "            # Si ya existe en eliminados, añadir sufijo numérico\n",
    "            contador = 2\n",
    "            while deleted_path.exists():\n",
    "                deleted_path = deleted_folder / f\"{file_path.stem}_{contador}{file_path.suffix}\"\n",
    "                contador += 1\n",
    "            \n",
    "            # Mover archivo\n",
    "            shutil.move(str(file_path), str(deleted_path))\n",
    "            \n",
    "            # Remover de la lista\n",
    "            self.exam_files.pop(self.current_index)\n",
    "            \n",
    "            # Ajustar índice si es necesario\n",
    "            if self.current_index >= len(self.exam_files):\n",
    "                self.current_index = max(0, len(self.exam_files) - 1)\n",
    "            \n",
    "            self.status.value = f\"🗑️ Eliminado: {file_path.name} → eliminados/{deleted_path.name}\"\n",
    "            \n",
    "            # Mostrar siguiente examen o mensaje si no hay más\n",
    "            if self.exam_files:\n",
    "                self._show_current_exam()\n",
    "            else:\n",
    "                self.status.value = \"🎉 No hay más exámenes para revisar\"\n",
    "                with self.out:\n",
    "                    clear_output(wait=True)\n",
    "                    print(\"No hay más exámenes para revisar\")\n",
    "                    \n",
    "        except Exception as e:\n",
    "            self.status.value = f\"❌ Error eliminando archivo: {e}\"\n",
    "\n",
    "    def _on_carpeta_change(self, change):\n",
    "        # Eliminado: Ya no se deshabilita el dropdown de práctica para ninguna carpeta\n",
    "        pass\n",
    "\n",
    "    def _on_nombre_change(self, change):\n",
    "        valor = change['new']\n",
    "        if valor in nombre_a_grupo:\n",
    "            self.dropdown_grupo.value = nombre_a_grupo[valor]\n",
    "            self.combo_nombre.value = valor\n",
    "        self._update_similares(valor)\n",
    "\n",
    "    def _on_page_change(self, change):\n",
    "        self._show_exam_image(self.exam_files[self.current_index]['file_path'])\n",
    "\n",
    "    def _update_similares(self, valor):\n",
    "        if valor:\n",
    "            matches = get_close_matches(valor, nombres_completos, n=4, cutoff=0)\n",
    "            # Mostrar horizontalmente (una sola fila)\n",
    "            html = \"<b>Sugerencias:</b> \"\n",
    "            if matches:\n",
    "                html += \"<span style='display:inline-block;white-space:nowrap;'>\"\n",
    "                for i, m in enumerate(matches):\n",
    "                    html += f\"<span style='display:inline-block;margin-right:20px;font-size:90%'>{m} <span style='color:#888;font-size:85%'>({nombre_a_grupo.get(m, '-')})</span></span>\"\n",
    "                html += \"</span>\"\n",
    "            else:\n",
    "                html += \"<i>No hay sugerencias</i>\"\n",
    "            self.similares_html.value = html\n",
    "        else:\n",
    "            self.similares_html.value = \"\"\n",
    "\n",
    "    def _show_current_exam(self):\n",
    "        if not self.exam_files:\n",
    "            return\n",
    "\n",
    "        current_exam = self.exam_files[self.current_index]\n",
    "        self.progress_label.value = f\"Examen {self.current_index + 1} de {len(self.exam_files)}\"\n",
    "\n",
    "        nombre_completo = current_exam['nombre_archivo'].replace('_', ' ')\n",
    "        mejor_match = None\n",
    "        for n in nombres_completos:\n",
    "            if nombre_completo.upper() in n.upper():\n",
    "                mejor_match = n\n",
    "                break\n",
    "        if mejor_match:\n",
    "            self.combo_nombre.value = mejor_match\n",
    "            self.dropdown_grupo.value = nombre_a_grupo[mejor_match]\n",
    "        else:\n",
    "            self.combo_nombre.value = nombre_completo\n",
    "            self.dropdown_grupo.value = df[\"Grupos\"].iloc[0]  # valor por defecto\n",
    "\n",
    "        self._update_similares(self.combo_nombre.value)\n",
    "\n",
    "        # Práctica\n",
    "        if current_exam['practica']:\n",
    "            practica_num = current_exam['practica'].replace('Practica_', '')\n",
    "            if practica_num in ['2', '3', '4', '5']:\n",
    "                self.dropdown_practica.value = practica_num\n",
    "            else:\n",
    "                self.dropdown_practica.value = '3'\n",
    "        else:\n",
    "            self.dropdown_practica.value = '3'\n",
    "\n",
    "        # Carpeta actual\n",
    "        self.dropdown_carpeta.value = current_exam['carpeta_actual']\n",
    "\n",
    "        # Mostrar solo la página 1 por defecto\n",
    "        self.page_selector.value = 1\n",
    "\n",
    "        # Ajustar el rango del selector de página según el número de páginas\n",
    "        reader = PdfReader(current_exam['file_path'])\n",
    "        num_pages = len(reader.pages)\n",
    "        if num_pages == 1:\n",
    "            self.dropdown_carpeta.value = \"problemático\"\n",
    "            self.page_selector.disabled = True\n",
    "        else:\n",
    "            self.page_selector.disabled = False\n",
    "\n",
    "        # Eliminado: Ya no se deshabilita el dropdown de práctica\n",
    "\n",
    "        if current_exam['practica']:\n",
    "            self.status.value = f\"📁 {current_exam['carpeta_actual']} / {current_exam['practica']} / {current_exam['nombre_archivo']}.pdf\"\n",
    "        else:\n",
    "            self.status.value = f\"📁 {current_exam['carpeta_actual']} / {current_exam['nombre_archivo']}.pdf\"\n",
    "\n",
    "        self._show_exam_image(current_exam['file_path'])\n",
    "\n",
    "    def _show_exam_image(self, pdf_path):\n",
    "        with self.out:\n",
    "            clear_output(wait=True)\n",
    "            try:\n",
    "                reader = PdfReader(pdf_path)\n",
    "                num_pages = len(reader.pages)\n",
    "                page_num = self.page_selector.value\n",
    "                if num_pages == 1:\n",
    "                    page_num = 1\n",
    "                images = convert_from_path(\n",
    "                    pdf_path,\n",
    "                    first_page=page_num,\n",
    "                    last_page=page_num,\n",
    "                    dpi=150,\n",
    "                    fmt='jpeg'\n",
    "                )\n",
    "                if images:\n",
    "                    image = images[0]\n",
    "                    # Recortar más agresivamente por arriba y por abajo (1/4 de la altura)\n",
    "                    cabecera_altura = int(min(450, image.height // 4))\n",
    "                    # Recortar un poco desde arriba también (20 píxeles)\n",
    "                    top_offset = 20\n",
    "                    cropped = image.crop((0, top_offset, image.width, cabecera_altura))\n",
    "                    plt.figure(figsize=(10, 6))  # Altura reducida\n",
    "                    plt.imshow(cropped)\n",
    "                    plt.axis('off')\n",
    "                    plt.tight_layout()\n",
    "                    plt.show()\n",
    "                else:\n",
    "                    print(\"❌ No se pudo cargar la imagen del PDF\")\n",
    "            except Exception as e:\n",
    "                print(f\"❌ Error cargando imagen: {e}\")\n",
    "\n",
    "    def _navigate(self, direction):\n",
    "        if self._has_pending_changes():\n",
    "            self._apply_changes()\n",
    "        new_index = self.current_index + direction\n",
    "        if 0 <= new_index < len(self.exam_files):\n",
    "            self.current_index = new_index\n",
    "            self._show_current_exam()\n",
    "        elif new_index >= len(self.exam_files):\n",
    "            self.status.value = \"🎉 ¡Revisión completada! Has llegado al final.\"\n",
    "        elif new_index < 0:\n",
    "            self.status.value = \"📍 Ya estás en el primer examen.\"\n",
    "\n",
    "    def _has_pending_changes(self):\n",
    "        if not self.exam_files:\n",
    "            return False\n",
    "        current_exam = self.exam_files[self.current_index]\n",
    "        nombre_actual = self.combo_nombre.value.strip().upper().replace(' ', '_')\n",
    "        nombre_archivo_actual = current_exam['nombre_archivo'].upper()\n",
    "        carpeta_cambio = self.dropdown_carpeta.value != current_exam['carpeta_actual']\n",
    "        practica_actual = current_exam['practica'].replace('Practica_', '') if current_exam['practica'] else ''\n",
    "        # Eliminado: \"and not self.dropdown_practica.disabled\" ya que nunca se deshabilita\n",
    "        practica_cambio = self.dropdown_practica.value != practica_actual\n",
    "        grupo_cambio = self.dropdown_grupo.value != nombre_a_grupo.get(self.combo_nombre.value, self.dropdown_grupo.value)\n",
    "        nombre_cambio = nombre_actual != nombre_archivo_actual\n",
    "        return carpeta_cambio or practica_cambio or grupo_cambio or nombre_cambio\n",
    "\n",
    "    def _apply_changes(self):\n",
    "        if not self.exam_files:\n",
    "            return\n",
    "        current_exam = self.exam_files[self.current_index]\n",
    "        old_path = current_exam['file_path']\n",
    "        try:\n",
    "            nombre_nuevo = self.combo_nombre.value.strip().replace(' ', '_')\n",
    "            grupo_para_nombre = self.dropdown_grupo.value\n",
    "            nueva_practica = self.dropdown_practica.value\n",
    "            carpeta_destino = self.dropdown_carpeta.value\n",
    "\n",
    "            # Nombre base: APELLIDOS_NOMBRE_P<num practica>_<Grupo>.pdf\n",
    "            nombre_base = f\"{nombre_nuevo}_P{nueva_practica}_{grupo_para_nombre}\"\n",
    "            nueva_carpeta = self.examenes_dir / carpeta_destino\n",
    "            if carpeta_destino not in [\"extraviados\", \"problemático\"]:\n",
    "                nueva_carpeta = nueva_carpeta / f\"Practica_{nueva_practica}\"\n",
    "            nueva_carpeta.mkdir(parents=True, exist_ok=True)\n",
    "            \n",
    "            # COMPROBACIÓN MEJORADA DE ARCHIVOS EXISTENTES\n",
    "            nuevo_path = nueva_carpeta / f\"{nombre_base}.pdf\"\n",
    "            \n",
    "            # Si el archivo destino es el mismo que el origen, no hacer nada\n",
    "            if nuevo_path == old_path:\n",
    "                self.status.value = \"ℹ️ Sin cambios necesarios\"\n",
    "                return\n",
    "            \n",
    "            # Si existe otro archivo con el mismo nombre, buscar sufijo disponible\n",
    "            contador = 2\n",
    "            while nuevo_path.exists():\n",
    "                # Extraer cualquier sufijo numérico existente del nombre base\n",
    "                match = re.search(r'_(\\d+)$', nombre_base)\n",
    "                if match:\n",
    "                    # Ya tiene sufijo numérico, incrementarlo\n",
    "                    numero_actual = int(match.group(1))\n",
    "                    nombre_sin_sufijo = nombre_base[:match.start()]\n",
    "                    nuevo_nombre_base = f\"{nombre_sin_sufijo}_{numero_actual + contador - 1}\"\n",
    "                else:\n",
    "                    # No tiene sufijo, añadir uno\n",
    "                    nuevo_nombre_base = f\"{nombre_base}_{contador}\"\n",
    "                \n",
    "                nuevo_path = nueva_carpeta / f\"{nuevo_nombre_base}.pdf\"\n",
    "                contador += 1\n",
    "                \n",
    "                # Seguridad: evitar bucle infinito\n",
    "                if contador > 100:\n",
    "                    self.status.value = \"❌ Error: Demasiados archivos duplicados\"\n",
    "                    return\n",
    "            \n",
    "            # Realizar el movimiento de archivo\n",
    "            try:\n",
    "                shutil.move(str(old_path), str(nuevo_path))\n",
    "                \n",
    "                # Actualizar información en la lista\n",
    "                current_exam['file_path'] = nuevo_path\n",
    "                current_exam['carpeta_actual'] = carpeta_destino\n",
    "                current_exam['practica'] = f\"Practica_{nueva_practica}\" if carpeta_destino not in [\"extraviados\", \"problemático\"] else \"\"\n",
    "                current_exam['nombre_archivo'] = nuevo_path.stem\n",
    "                \n",
    "                # Mensaje de confirmación\n",
    "                if carpeta_destino in [\"extraviados\", \"problemático\"]:\n",
    "                    self.status.value = f\"✅ Movido a: {carpeta_destino}/{nuevo_path.name}\"\n",
    "                else:\n",
    "                    self.status.value = f\"✅ Movido a: {carpeta_destino}/Practica_{nueva_practica}/{nuevo_path.name}\"\n",
    "                    \n",
    "                # Si se añadió un sufijo, avisar\n",
    "                if contador > 2:\n",
    "                    self.status.value += f\" (duplicado evitado con sufijo _{contador-2})\"\n",
    "                    \n",
    "            except PermissionError:\n",
    "                self.status.value = \"❌ Error: Archivo en uso o sin permisos\"\n",
    "            except FileNotFoundError:\n",
    "                self.status.value = \"❌ Error: Archivo origen no encontrado\"\n",
    "            except Exception as move_error:\n",
    "                self.status.value = f\"❌ Error moviendo archivo: {move_error}\"\n",
    "                \n",
    "        except Exception as e:\n",
    "            self.status.value = f\"❌ Error aplicando cambios: {e}\"\n",
    "\n",
    "def iniciar_revision_examenes(examenes_dir=\"../data/examenes_procesados/\"):\n",
    "    print(\"🚀 Iniciando revisor de exámenes...\")\n",
    "    reviewer = JupyterExamReviewer(examenes_dir)\n",
    "    return reviewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e192749c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para lanzar la interfaz:\n",
    "#reviewer = iniciar_revision_examenes()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff603be2",
   "metadata": {},
   "source": [
    "#### Backup para asegurar..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "cf07a381",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "from datetime import datetime  # AÑADIR ESTE IMPORT\n",
    "\n",
    "def crear_backup_examenes(carpeta_examenes=\"../data/examenes_procesados/\", carpeta_backup=\"../data/\"):\n",
    "    \"\"\"\n",
    "    Crea un backup completo de la carpeta de exámenes procesados\n",
    "    \"\"\"\n",
    "    carpeta_examenes = Path(carpeta_examenes)\n",
    "    carpeta_backup = Path(carpeta_backup)\n",
    "    \n",
    "    # Crear nombre del backup con timestamp\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    nombre_backup = f\"examenes_procesados_backup_{timestamp}.zip\"\n",
    "    ruta_backup = carpeta_backup / nombre_backup\n",
    "    \n",
    "    print(f\"🔄 Creando backup de: {carpeta_examenes}\")\n",
    "    print(f\"📦 Archivo de backup: {ruta_backup}\")\n",
    "    \n",
    "    try:\n",
    "        # Crear el archivo ZIP\n",
    "        with zipfile.ZipFile(ruta_backup, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "            # Recorrer todos los archivos y carpetas\n",
    "            for root, dirs, files in os.walk(carpeta_examenes):\n",
    "                for file in files:\n",
    "                    file_path = Path(root) / file\n",
    "                    # Calcular la ruta relativa para mantener la estructura\n",
    "                    arcname = file_path.relative_to(carpeta_examenes.parent)\n",
    "                    zipf.write(file_path, arcname)\n",
    "                    print(f\"  ✓ Añadido: {arcname}\")\n",
    "        \n",
    "        print(f\"\\n✅ Backup completado exitosamente!\")\n",
    "        print(f\"📁 Tamaño del backup: {ruta_backup.stat().st_size / (1024*1024):.2f} MB\")\n",
    "        print(f\"💾 Ubicación: {ruta_backup}\")\n",
    "        \n",
    "        return str(ruta_backup)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error creando backup: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "aa3f990f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#crear_backup_examenes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "779459b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def eliminar_carpetas_vacias(ruta_base=\"../data/examenes_procesados/\"):\n",
    "    \"\"\"\n",
    "    Elimina recursivamente todas las carpetas vacías en la ruta especificada\n",
    "    \"\"\"\n",
    "    ruta_base = Path(ruta_base)\n",
    "    \n",
    "    if not ruta_base.exists():\n",
    "        print(f\"❌ La ruta {ruta_base} no existe\")\n",
    "        return\n",
    "    \n",
    "    carpetas_eliminadas = []\n",
    "    \n",
    "    # Función recursiva para eliminar carpetas vacías\n",
    "    def eliminar_vacias_recursivo(directorio):\n",
    "        \"\"\"Elimina carpetas vacías de forma recursiva, empezando por las más profundas\"\"\"\n",
    "        try:\n",
    "            # Primero procesar subdirectorios\n",
    "            for item in directorio.iterdir():\n",
    "                if item.is_dir():\n",
    "                    eliminar_vacias_recursivo(item)\n",
    "            \n",
    "            # Luego verificar si el directorio actual está vacío\n",
    "            if directorio.is_dir() and not any(directorio.iterdir()):\n",
    "                directorio.rmdir()\n",
    "                carpetas_eliminadas.append(str(directorio))\n",
    "                print(f\"🗑️ Eliminada carpeta vacía: {directorio}\")\n",
    "                \n",
    "        except PermissionError:\n",
    "            print(f\"⚠️ Sin permisos para eliminar: {directorio}\")\n",
    "        except OSError as e:\n",
    "            print(f\"⚠️ Error eliminando {directorio}: {e}\")\n",
    "    \n",
    "    print(f\"🔍 Buscando carpetas vacías en: {ruta_base}\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Ejecutar la eliminación recursiva\n",
    "    eliminar_vacias_recursivo(ruta_base)\n",
    "    \n",
    "    print(\"=\" * 50)\n",
    "    print(f\"✅ Proceso completado\")\n",
    "    print(f\"📊 Total de carpetas vacías eliminadas: {len(carpetas_eliminadas)}\")\n",
    "    \n",
    "    if carpetas_eliminadas:\n",
    "        print(\"\\n📋 Carpetas eliminadas:\")\n",
    "        for carpeta in carpetas_eliminadas:\n",
    "            print(f\"  - {carpeta}\")\n",
    "    else:\n",
    "        print(\"ℹ️ No se encontraron carpetas vacías para eliminar\")\n",
    "    \n",
    "    return carpetas_eliminadas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4522b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#eliminar_carpetas_vacias()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00eb7edd",
   "metadata": {},
   "source": [
    "### Buscar practica concreta por si alguien se ha equivocado de montón"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f4f612da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def buscar_alumnos_practicas(\n",
    "        ruta_examenes=\"../data/examenes_procesados/\",\n",
    "        practicas=[\"3\", \"5\"]  # Usar strings por defecto\n",
    "):\n",
    "    \"\"\"\n",
    "    Busca alumnos que han entregado prácticas basándose en la estructura de carpetas\n",
    "    y nombres de archivos. Marca con * los que están en carpeta problemático.\n",
    "    \n",
    "    Args:\n",
    "        ruta_examenes: Ruta a la carpeta donde están los exámenes procesados\n",
    "        practicas: Lista de números de práctica como strings [\"3\", \"5\"]\n",
    "    \"\"\"\n",
    "    # Asegurar que los elementos de practicas son strings\n",
    "    practicas = [str(p) for p in practicas]\n",
    "    \n",
    "    ruta_examenes = Path(ruta_examenes)\n",
    "    \n",
    "    if not ruta_examenes.exists():\n",
    "        print(f\"❌ La ruta {ruta_examenes} no existe\")\n",
    "        return []\n",
    "    \n",
    "    alumnos_practicas = []\n",
    "    \n",
    "    \n",
    "    # Recorrer todas las carpetas de grupos\n",
    "    for carpeta_grupo in ruta_examenes.iterdir():\n",
    "        if not carpeta_grupo.is_dir():\n",
    "            continue\n",
    "            \n",
    "        # Procesar carpetas de grupos normales\n",
    "        if carpeta_grupo.name not in [\"extraviados\", \"eliminados\"]:\n",
    "            # Si es problemático, marcar con asterisco\n",
    "            asterisco = \" *\" if carpeta_grupo.name == \"problemático\" else \"\"\n",
    "            \n",
    "            if carpeta_grupo.name == \"problemático\":\n",
    "                # En problemático, buscar directamente archivos PDF\n",
    "                for archivo_pdf in carpeta_grupo.glob(\"*.pdf\"):\n",
    "                    practica = detectar_practica_del_nombre(archivo_pdf.name)\n",
    "                    if practica in practicas:\n",
    "                        info_alumno = extraer_info_alumno(archivo_pdf, practica, \"problemático\", True)\n",
    "                        if info_alumno:\n",
    "                            alumnos_practicas.append(info_alumno)\n",
    "            else:\n",
    "                # Buscar en subcarpetas de prácticas\n",
    "                for subcarpeta in carpeta_grupo.iterdir():\n",
    "                    if subcarpeta.is_dir() and subcarpeta.name.startswith(\"Practica_\"):\n",
    "                        practica_num = subcarpeta.name.replace(\"Practica_\", \"\")\n",
    "                        \n",
    "                        if practica_num in practicas:\n",
    "                            print(f\"📂 Encontrada {subcarpeta.name} en grupo {carpeta_grupo.name}\")\n",
    "                            \n",
    "                            for archivo_pdf in subcarpeta.glob(\"*.pdf\"):\n",
    "                                info_alumno = extraer_info_alumno(archivo_pdf, practica_num, carpeta_grupo.name, False)\n",
    "                                if info_alumno:\n",
    "                                    alumnos_practicas.append(info_alumno)\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(f\"📊 RESUMEN: Encontrados {len(alumnos_practicas)} alumnos con prácticas \"+str(practicas))\n",
    "    \n",
    "    if alumnos_practicas:\n",
    "        # Organizar por grupo y práctica\n",
    "        por_grupo_practica = {}\n",
    "        \n",
    "        for alumno in alumnos_practicas:\n",
    "            grupo = alumno['grupo']\n",
    "            practica = alumno['practica']\n",
    "            key = f\"{grupo}_P{practica}\"\n",
    "            \n",
    "            if key not in por_grupo_practica:\n",
    "                por_grupo_practica[key] = []\n",
    "            por_grupo_practica[key].append(alumno)\n",
    "        \n",
    "        print(f\"\\n📋 LISTADO POR GRUPO Y PRÁCTICA:\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        for key in sorted(por_grupo_practica.keys()):\n",
    "            grupo, practica_info = key.split('_P')\n",
    "            asterisco = \" *\" if any(a['problematico'] for a in por_grupo_practica[key]) else \"\"\n",
    "            \n",
    "            print(f\"\\n📚 GRUPO {grupo} - PRÁCTICA {practica_info}{asterisco}\")\n",
    "            print(\"-\" * 40)\n",
    "            \n",
    "            for alumno in sorted(por_grupo_practica[key], key=lambda x: (x['apellidos'], x['nombre'])):\n",
    "                asterisco_individual = \" *\" if alumno['problematico'] else \"\"\n",
    "                print(f\"  • {alumno['apellidos']}, {alumno['nombre']}{asterisco_individual}\")\n",
    "    \n",
    "    return alumnos_practicas\n",
    "\n",
    "def extraer_info_alumno(archivo_pdf, practica, grupo, es_problematico):\n",
    "    \"\"\"Extrae información del alumno desde el nombre del archivo\"\"\"\n",
    "    nombre_archivo = archivo_pdf.stem\n",
    "    \n",
    "    # Limpiar el nombre del archivo para extraer apellidos y nombre\n",
    "    nombre_limpio = nombre_archivo\n",
    "    \n",
    "    # Remover elementos conocidos (práctica, grupo, etc.)\n",
    "    patrones_a_remover = [\n",
    "        rf'_P{practica}', rf'P{practica}_', rf'P{practica}$',\n",
    "        rf'_{grupo}', rf'{grupo}_', rf'^{grupo}',\n",
    "        r'_CITIM\\d+', r'_IWSIM\\d+', r'_CITIT\\d+', r'_IWSIT\\d+',\n",
    "        r'CITIM\\d+_', r'IWSIM\\d+_', r'CITIT\\d+_', r'IWSIT\\d+_',\n",
    "        r'_\\d+$'  # Números al final\n",
    "    ]\n",
    "    \n",
    "    for patron in patrones_a_remover:\n",
    "        nombre_limpio = re.sub(patron, '', nombre_limpio, flags=re.IGNORECASE)\n",
    "    \n",
    "    # Limpiar guiones bajos múltiples\n",
    "    nombre_limpio = re.sub(r'_+', '_', nombre_limpio).strip('_')\n",
    "    \n",
    "    # Separar apellidos y nombre\n",
    "    partes = nombre_limpio.split('_')\n",
    "    \n",
    "    if len(partes) >= 2:\n",
    "        # Asumir que la última parte es el nombre y el resto apellidos\n",
    "        apellidos = '_'.join(partes[:-1]).replace('_', ' ')\n",
    "        nombre = partes[-1]\n",
    "    elif len(partes) == 1:\n",
    "        apellidos = partes[0]\n",
    "        nombre = ''\n",
    "    else:\n",
    "        apellidos = nombre_archivo\n",
    "        nombre = ''\n",
    "    \n",
    "    return {\n",
    "        'archivo': archivo_pdf.name,\n",
    "        'apellidos': apellidos,\n",
    "        'nombre': nombre,\n",
    "        'practica': practica,\n",
    "        'grupo': grupo,\n",
    "        'problematico': es_problematico\n",
    "    }\n",
    "\n",
    "def detectar_practica_del_nombre(nombre_archivo):\n",
    "    \"\"\"Detecta el número de práctica del nombre del archivo\"\"\"\n",
    "    nombre = nombre_archivo.upper()\n",
    "    \n",
    "    # Buscar patrones de práctica\n",
    "    patrones = [\n",
    "        r'P(\\d)',\n",
    "        r'_(\\d)_',\n",
    "        r'PRACTICA_?(\\d)',\n",
    "    ]\n",
    "    \n",
    "    for patron in patrones:\n",
    "        match = re.search(patron, nombre)\n",
    "        if match:\n",
    "            return match.group(1)\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "42171f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#buscar_alumnos_practicas(practicas=[2,4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251d8a78",
   "metadata": {},
   "source": [
    "### Buscar examenes de alumnos por grupo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "43ebfc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def detectar_grupo_del_nombre(nombre_archivo):\n",
    "    \"\"\"Detecta el grupo del nombre del archivo\"\"\"\n",
    "    nombre = nombre_archivo.upper()\n",
    "    \n",
    "    # Buscar patrones de grupo\n",
    "    grupos_posibles = ['CITIM11', 'CITIM12', 'IWSIM11', 'IWSIM12', 'CITIT11', 'CITIT12', 'IWSIT11', 'IWSIT12']\n",
    "    \n",
    "    for grupo in grupos_posibles:\n",
    "        if grupo in nombre:\n",
    "            return grupo\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe8c03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraer_info_alumno(archivo_pdf, practica, grupo, es_problematico):\n",
    "    \"\"\"\n",
    "    Extrae información del alumno desde el nombre del archivo para grupos CITIT/IWSIT\n",
    "    \"\"\"\n",
    "    nombre_archivo = archivo_pdf.stem\n",
    "    \n",
    "    # Limpiar el nombre del archivo para extraer apellidos y nombre\n",
    "    nombre_limpio = nombre_archivo\n",
    "    \n",
    "    # Remover elementos conocidos (práctica, grupo, etc.)\n",
    "    patrones_a_remover = [\n",
    "        rf'_P{practica}', rf'P{practica}_', rf'P{practica}$',\n",
    "        rf'_{grupo}', rf'{grupo}_', rf'^{grupo}',\n",
    "        r'_CITIT\\d+', r'_IWSIT\\d+', r'_CITIM\\d+', r'_IWSIM\\d+',\n",
    "        r'CITIT\\d+_', r'IWSIT\\d+_', r'CITIM\\d+_', r'IWSIM\\d+_',\n",
    "        r'_\\d+$'  # Números al final\n",
    "    ]\n",
    "    \n",
    "    for patron in patrones_a_remover:\n",
    "        nombre_limpio = re.sub(patron, '', nombre_limpio, flags=re.IGNORECASE)\n",
    "    \n",
    "    # Limpiar guiones bajos múltiples\n",
    "    nombre_limpio = re.sub(r'_+', '_', nombre_limpio).strip('_')\n",
    "    \n",
    "    # Separar apellidos y nombre\n",
    "    partes = nombre_limpio.split('_')\n",
    "    \n",
    "    if len(partes) >= 2:\n",
    "        # Asumir que la última parte es el nombre y el resto apellidos\n",
    "        apellidos = '_'.join(partes[:-1]).replace('_', ' ')\n",
    "        nombre = partes[-1]\n",
    "    elif len(partes) == 1:\n",
    "        apellidos = partes[0]\n",
    "        nombre = ''\n",
    "    else:\n",
    "        apellidos = nombre_archivo\n",
    "        nombre = ''\n",
    "    \n",
    "    return {\n",
    "        'archivo': archivo_pdf.name,\n",
    "        'apellidos': apellidos,\n",
    "        'nombre': nombre,\n",
    "        'practica': practica,\n",
    "        'grupo': grupo,\n",
    "        'problematico': es_problematico\n",
    "    }\n",
    "\n",
    "def buscar_alumnos_grupos_citit_iwsit(ruta_examenes=\"../data/examenes_procesados/\"):\n",
    "    \"\"\"\n",
    "    Busca alumnos de los grupos CITIT11, CITIT12, IWSIT11, IWSIT12 clasificados por práctica.\n",
    "    Verifica el grupo correcto consultando el DataFrame de alumnos.\n",
    "    \"\"\"\n",
    "    ruta_examenes = Path(ruta_examenes)\n",
    "    \n",
    "    if not ruta_examenes.exists():\n",
    "        print(f\"La ruta {ruta_examenes} no existe\")\n",
    "        return []\n",
    "    \n",
    "    # Grupos objetivo\n",
    "    grupos_objetivo = ['CITIT11', 'CITIT12', 'IWSIT11', 'IWSIT12']\n",
    "    alumnos_encontrados = []\n",
    "    \n",
    "    print(\"Buscando alumnos de grupos CITIT/IWSIT...\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Recorrer todas las carpetas de grupos\n",
    "    for carpeta_grupo in ruta_examenes.iterdir():\n",
    "        if not carpeta_grupo.is_dir():\n",
    "            continue\n",
    "            \n",
    "        # Verificar si es uno de los grupos objetivo O carpeta problemático\n",
    "        es_grupo_objetivo = carpeta_grupo.name in grupos_objetivo\n",
    "        es_problematico = carpeta_grupo.name == \"problemático\"\n",
    "        \n",
    "        if es_grupo_objetivo or es_problematico:\n",
    "            print(f\"\\nProcesando carpeta: {carpeta_grupo.name}\")\n",
    "            \n",
    "            if es_problematico:\n",
    "                # En problemático, buscar directamente archivos PDF y verificar si son de grupos objetivo\n",
    "                for archivo_pdf in carpeta_grupo.glob(\"*.pdf\"):\n",
    "                    grupo_detectado = detectar_grupo_del_nombre(archivo_pdf.name)\n",
    "                    practica = detectar_practica_del_nombre(archivo_pdf.name)\n",
    "                    if practica:\n",
    "                        info_alumno = extraer_info_alumno(archivo_pdf, practica, grupo_detectado or carpeta_grupo.name, True)\n",
    "                        if info_alumno:\n",
    "                            # Verificar grupo real en el DataFrame\n",
    "                            grupo_real = verificar_grupo_en_dataframe(info_alumno['apellidos'], info_alumno['nombre'])\n",
    "                            if grupo_real in grupos_objetivo:\n",
    "                                info_alumno['grupo_real'] = grupo_real\n",
    "                                info_alumno['grupo_carpeta'] = carpeta_grupo.name\n",
    "                                alumnos_encontrados.append(info_alumno)\n",
    "                                print(f\"    {info_alumno['apellidos']}, {info_alumno['nombre']} (P{practica}, {grupo_real}) *\")\n",
    "            else:\n",
    "                # Buscar en subcarpetas de prácticas\n",
    "                for subcarpeta in carpeta_grupo.iterdir():\n",
    "                    if subcarpeta.is_dir() and subcarpeta.name.startswith(\"Practica_\"):\n",
    "                        practica_num = subcarpeta.name.replace(\"Practica_\", \"\")\n",
    "                        print(f\"  {subcarpeta.name}\")\n",
    "                        \n",
    "                        for archivo_pdf in subcarpeta.glob(\"*.pdf\"):\n",
    "                            info_alumno = extraer_info_alumno(archivo_pdf, practica_num, carpeta_grupo.name, False)\n",
    "                            if info_alumno:\n",
    "                                # Verificar grupo real en el DataFrame\n",
    "                                grupo_real = verificar_grupo_en_dataframe(info_alumno['apellidos'], info_alumno['nombre'])\n",
    "                                if grupo_real in grupos_objetivo:\n",
    "                                    info_alumno['grupo_real'] = grupo_real\n",
    "                                    info_alumno['grupo_carpeta'] = carpeta_grupo.name\n",
    "                                    alumnos_encontrados.append(info_alumno)\n",
    "                                    \n",
    "                                    # Mostrar advertencia si el grupo de carpeta no coincide con el real\n",
    "                                    if grupo_real != carpeta_grupo.name:\n",
    "                                        print(f\"    {info_alumno['apellidos']}, {info_alumno['nombre']} (Grupo real: {grupo_real}, Carpeta: {carpeta_grupo.name}) ⚠️\")\n",
    "                                    else:\n",
    "                                        print(f\"    {info_alumno['apellidos']}, {info_alumno['nombre']}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(f\"RESUMEN: Encontrados {len(alumnos_encontrados)} alumnos de grupos CITIT/IWSIT\")\n",
    "    \n",
    "    if alumnos_encontrados:\n",
    "        # Organizar por práctica y luego por grupo REAL\n",
    "        por_practica = {}\n",
    "        \n",
    "        for alumno in alumnos_encontrados:\n",
    "            practica = alumno['practica']\n",
    "            if practica not in por_practica:\n",
    "                por_practica[practica] = {}\n",
    "            \n",
    "            grupo = alumno['grupo_real']  # Usar grupo real del DataFrame\n",
    "            if grupo not in por_practica[practica]:\n",
    "                por_practica[practica][grupo] = []\n",
    "            \n",
    "            por_practica[practica][grupo].append(alumno)\n",
    "        \n",
    "        print(f\"\\nLISTADO SEPARADO EN DOS LISTAS:\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        # Ordenar por número de práctica\n",
    "        for practica in sorted(por_practica.keys(), key=lambda x: int(x) if x.isdigit() else 999):\n",
    "            print(f\"\\nPractica {practica}:\")\n",
    "            print(\"-\" * 50)\n",
    "            \n",
    "            # Ordenar grupos alfabéticamente\n",
    "            for grupo in sorted(por_practica[practica].keys()):\n",
    "                alumnos_grupo = por_practica[practica][grupo]\n",
    "                \n",
    "                # Separar en problemáticos y normales\n",
    "                alumnos_normales = [alumno for alumno in alumnos_grupo if not alumno['problematico']]\n",
    "                alumnos_problematicos = [alumno for alumno in alumnos_grupo if alumno['problematico']]\n",
    "                \n",
    "                print(f\"\\nGrupo {grupo}:\")\n",
    "                \n",
    "                # Lista de alumnos normales\n",
    "                if alumnos_normales:\n",
    "                    print(\"  Alumnos normales:\")\n",
    "                    for alumno in sorted(alumnos_normales, key=lambda x: (x['apellidos'], x['nombre'])):\n",
    "                        print(f\"    {alumno['apellidos']}, {alumno['nombre']}\")\n",
    "                \n",
    "                # Lista de alumnos problemáticos (dentro del mismo grupo)\n",
    "                if alumnos_problematicos:\n",
    "                    print(\"  Alumnos problemáticos:\")\n",
    "                    for alumno in sorted(alumnos_problematicos, key=lambda x: (x['apellidos'], x['nombre'])):\n",
    "                        print(f\"    {alumno['apellidos']}, {alumno['nombre']} *\")\n",
    "        \n",
    "        print(f\"\\n\" + \"-\" * 40)\n",
    "        print(f\"RESUMEN POR GRUPO:\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        resumen_grupos = {}\n",
    "        for alumno in alumnos_encontrados:\n",
    "            grupo = alumno['grupo_real']  # Usar grupo real\n",
    "            if grupo not in resumen_grupos:\n",
    "                resumen_grupos[grupo] = {'total': 0, 'problematicos': 0}\n",
    "            resumen_grupos[grupo]['total'] += 1\n",
    "            if alumno['problematico']:\n",
    "                resumen_grupos[grupo]['problematicos'] += 1\n",
    "        \n",
    "        for grupo in sorted(resumen_grupos.keys()):\n",
    "            total = resumen_grupos[grupo]['total']\n",
    "            problematicos = resumen_grupos[grupo]['problematicos']\n",
    "            print(f\"  {grupo}: {total} alumnos (problemáticos: {problematicos})\")\n",
    "    \n",
    "    return alumnos_encontrados\n",
    "\n",
    "def verificar_grupo_en_dataframe(apellidos, nombre):\n",
    "    \"\"\"\n",
    "    Verifica el grupo real del alumno consultando el DataFrame df\n",
    "    \"\"\"\n",
    "    if 'df' not in globals():\n",
    "        print(\"⚠️ DataFrame df no está disponible\")\n",
    "        return \"GRUPO_NO_ENCONTRADO\"\n",
    "    \n",
    "    apellidos_limpio = apellidos.upper().strip()\n",
    "    nombre_limpio = nombre.upper().strip()\n",
    "    \n",
    "    # Buscar coincidencia exacta primero\n",
    "    mask_exacta = (df['Apellido(s)'].str.upper().str.strip() == apellidos_limpio) & \\\n",
    "                  (df['Nombre'].str.upper().str.strip() == nombre_limpio)\n",
    "    \n",
    "    if mask_exacta.any():\n",
    "        return df.loc[mask_exacta, 'Grupos'].iloc[0]\n",
    "    \n",
    "    # Si no hay coincidencia exacta, buscar coincidencia parcial\n",
    "    if apellidos_limpio and nombre_limpio:\n",
    "        mask_parcial = df['Apellido(s)'].str.upper().str.contains(apellidos_limpio[:5], na=False) & \\\n",
    "                       df['Nombre'].str.upper().str.contains(nombre_limpio[:3], na=False)\n",
    "        \n",
    "        if mask_parcial.any():\n",
    "            return df.loc[mask_parcial, 'Grupos'].iloc[0]\n",
    "    \n",
    "    return \"GRUPO_NO_ENCONTRADO\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "afc179db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def buscar_alumnos_grupos(df, ruta_examenes=\"../data/examenes_procesados/\", grupos_objetivo = ['CITIT11', 'CITIT12', 'IWSIT11', 'IWSIT12'] ):\n",
    "    \"\"\"\n",
    "    Busca alumnos de los grupos CITIT11, CITIT12, IWSIT11, IWSIT12 clasificados por práctica.\n",
    "    Verifica el grupo correcto consultando el DataFrame de alumnos.\n",
    "    \"\"\"\n",
    "    ruta_examenes = Path(ruta_examenes)\n",
    "    \n",
    "    if not ruta_examenes.exists():\n",
    "        print(f\"La ruta {ruta_examenes} no existe\")\n",
    "        return []\n",
    "    \n",
    "    \n",
    "    alumnos_encontrados = []\n",
    "    \n",
    "    print(\"Buscando alumnos de grupos \" + str(grupos_objetivo))\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Recorrer todas las carpetas de grupos\n",
    "    for carpeta_grupo in ruta_examenes.iterdir():\n",
    "        if not carpeta_grupo.is_dir():\n",
    "            continue\n",
    "            \n",
    "        # Verificar si es uno de los grupos objetivo O carpeta problemático\n",
    "        es_grupo_objetivo = carpeta_grupo.name in grupos_objetivo\n",
    "        es_problematico = carpeta_grupo.name == \"problemático\"\n",
    "        \n",
    "        if es_grupo_objetivo or es_problematico:\n",
    "            print(f\"\\nProcesando carpeta: {carpeta_grupo.name}\")\n",
    "            \n",
    "            if es_problematico:\n",
    "                # En problemático, buscar directamente archivos PDF y verificar si son de grupos objetivo\n",
    "                for archivo_pdf in carpeta_grupo.glob(\"*.pdf\"):\n",
    "                    grupo_detectado = detectar_grupo_del_nombre(archivo_pdf.name)\n",
    "                    practica = detectar_practica_del_nombre(archivo_pdf.name)\n",
    "                    if practica:\n",
    "                        info_alumno = extraer_info_alumno(archivo_pdf, practica, grupo_detectado or carpeta_grupo.name, True)\n",
    "                        if info_alumno:\n",
    "                            # Verificar grupo real en el DataFrame\n",
    "                            grupo_real = verificar_grupo_en_dataframe(info_alumno['apellidos'], info_alumno['nombre'])\n",
    "                            if grupo_real in grupos_objetivo:\n",
    "                                info_alumno['grupo_real'] = grupo_real\n",
    "                                info_alumno['grupo_carpeta'] = carpeta_grupo.name\n",
    "                                alumnos_encontrados.append(info_alumno)\n",
    "                                print(f\"    {info_alumno['apellidos']}, {info_alumno['nombre']} (P{practica}, {grupo_real}) *\")\n",
    "            else:\n",
    "                # Buscar en subcarpetas de prácticas\n",
    "                for subcarpeta in carpeta_grupo.iterdir():\n",
    "                    if subcarpeta.is_dir() and subcarpeta.name.startswith(\"Practica_\"):\n",
    "                        practica_num = subcarpeta.name.replace(\"Practica_\", \"\")\n",
    "                        print(f\"  {subcarpeta.name}\")\n",
    "                        \n",
    "                        for archivo_pdf in subcarpeta.glob(\"*.pdf\"):\n",
    "                            info_alumno = extraer_info_alumno(archivo_pdf, practica_num, carpeta_grupo.name, False)\n",
    "                            if info_alumno:\n",
    "                                # Verificar grupo real en el DataFrame\n",
    "                                grupo_real = verificar_grupo_en_dataframe(info_alumno['apellidos'], info_alumno['nombre'])\n",
    "                                if grupo_real in grupos_objetivo:\n",
    "                                    info_alumno['grupo_real'] = grupo_real\n",
    "                                    info_alumno['grupo_carpeta'] = carpeta_grupo.name\n",
    "                                    alumnos_encontrados.append(info_alumno)\n",
    "                                    \n",
    "                                    # Mostrar advertencia si el grupo de carpeta no coincide con el real\n",
    "                                    if grupo_real != carpeta_grupo.name:\n",
    "                                        print(f\"    {info_alumno['apellidos']}, {info_alumno['nombre']} (Grupo real: {grupo_real}, Carpeta: {carpeta_grupo.name}) ⚠️\")\n",
    "                                    else:\n",
    "                                        print(f\"    {info_alumno['apellidos']}, {info_alumno['nombre']}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(f\"RESUMEN: Encontrados {len(alumnos_encontrados)} alumnos de grupos CITIT/IWSIT\")\n",
    "    \n",
    "    if alumnos_encontrados:\n",
    "        # Organizar por práctica y luego por grupo REAL\n",
    "        por_practica = {}\n",
    "        \n",
    "        for alumno in alumnos_encontrados:\n",
    "            practica = alumno['practica']\n",
    "            if practica not in por_practica:\n",
    "                por_practica[practica] = {}\n",
    "            \n",
    "            grupo = alumno['grupo_real']  # Usar grupo real del DataFrame\n",
    "            if grupo not in por_practica[practica]:\n",
    "                por_practica[practica][grupo] = []\n",
    "            \n",
    "            por_practica[practica][grupo].append(alumno)\n",
    "        \n",
    "        print(f\"\\nLISTADO SEPARADO EN DOS LISTAS:\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        # Ordenar por número de práctica\n",
    "        for practica in sorted(por_practica.keys(), key=lambda x: int(x) if x.isdigit() else 999):\n",
    "            print(f\"\\nPractica {practica}:\")\n",
    "            print(\"-\" * 50)\n",
    "            \n",
    "            # Ordenar grupos alfabéticamente\n",
    "            for grupo in sorted(por_practica[practica].keys()):\n",
    "                alumnos_grupo = por_practica[practica][grupo]\n",
    "                \n",
    "                # Separar en problemáticos y normales\n",
    "                alumnos_normales = [alumno for alumno in alumnos_grupo if not alumno['problematico']]\n",
    "                alumnos_problematicos = [alumno for alumno in alumnos_grupo if alumno['problematico']]\n",
    "                \n",
    "                print(f\"\\nGrupo {grupo}:\")\n",
    "                \n",
    "                # Lista de alumnos normales\n",
    "                if alumnos_normales:\n",
    "                    print(\"  Alumnos normales:\")\n",
    "                    for alumno in sorted(alumnos_normales, key=lambda x: (x['apellidos'], x['nombre'])):\n",
    "                        print(f\"    {alumno['apellidos']}, {alumno['nombre']}\")\n",
    "                \n",
    "                # Lista de alumnos problemáticos (dentro del mismo grupo)\n",
    "                if alumnos_problematicos:\n",
    "                    print(\"  Alumnos problemáticos:\")\n",
    "                    for alumno in sorted(alumnos_problematicos, key=lambda x: (x['apellidos'], x['nombre'])):\n",
    "                        print(f\"    {alumno['apellidos']}, {alumno['nombre']} *\")\n",
    "        \n",
    "        print(f\"\\n\" + \"-\" * 40)\n",
    "        print(f\"RESUMEN POR GRUPO:\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        resumen_grupos = {}\n",
    "        for alumno in alumnos_encontrados:\n",
    "            grupo = alumno['grupo_real']  # Usar grupo real\n",
    "            if grupo not in resumen_grupos:\n",
    "                resumen_grupos[grupo] = {'total': 0, 'problematicos': 0}\n",
    "            resumen_grupos[grupo]['total'] += 1\n",
    "            if alumno['problematico']:\n",
    "                resumen_grupos[grupo]['problematicos'] += 1\n",
    "        \n",
    "        for grupo in sorted(resumen_grupos.keys()):\n",
    "            total = resumen_grupos[grupo]['total']\n",
    "            problematicos = resumen_grupos[grupo]['problematicos']\n",
    "            print(f\"  {grupo}: {total} alumnos (problemáticos: {problematicos})\")\n",
    "    \n",
    "    return alumnos_encontrados\n",
    "\n",
    "def verificar_grupo_en_dataframe(apellidos, nombre):\n",
    "    \"\"\"\n",
    "    Verifica el grupo real del alumno consultando el DataFrame df\n",
    "    \"\"\"\n",
    "    if 'df' not in globals():\n",
    "        print(\"⚠️ DataFrame df no está disponible\")\n",
    "        return \"GRUPO_NO_ENCONTRADO\"\n",
    "    \n",
    "    apellidos_limpio = apellidos.upper().strip()\n",
    "    nombre_limpio = nombre.upper().strip()\n",
    "    \n",
    "    # Buscar coincidencia exacta primero\n",
    "    mask_exacta = (df['Apellido(s)'].str.upper().str.strip() == apellidos_limpio) & \\\n",
    "                  (df['Nombre'].str.upper().str.strip() == nombre_limpio)\n",
    "    \n",
    "    if mask_exacta.any():\n",
    "        return df.loc[mask_exacta, 'Grupos'].iloc[0]\n",
    "    \n",
    "    # Si no hay coincidencia exacta, buscar coincidencia parcial\n",
    "    if apellidos_limpio and nombre_limpio:\n",
    "        mask_parcial = df['Apellido(s)'].str.upper().str.contains(apellidos_limpio[:5], na=False) & \\\n",
    "                       df['Nombre'].str.upper().str.contains(nombre_limpio[:3], na=False)\n",
    "        \n",
    "        if mask_parcial.any():\n",
    "            return df.loc[mask_parcial, 'Grupos'].iloc[0]\n",
    "    \n",
    "    return \"GRUPO_NO_ENCONTRADO\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "f864a25c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buscando alumnos de grupos ['CITIT12']\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "RESUMEN: Encontrados 0 alumnos de grupos CITIT/IWSIT\n"
     ]
    }
   ],
   "source": [
    "alumnos_citit_iwsit = buscar_alumnos_grupos(\n",
    "    df_students, grupos_objetivo=['CITIT12']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14555ba5",
   "metadata": {},
   "source": [
    "### Analizar origen ficheros en 'problematico' (pdf original) \n",
    "Objetivo: ver en los físicos si tienen hoja en blanco o ha sido error de la impresora\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "19494a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm \n",
    "def analizar_examenes_problematicos(ruta_examenes=\"../data/examenes_procesados/\", \n",
    "                                   ruta_saved=\"../data/saved/\", \n",
    "                                   parar_en_100=False,\n",
    "                                   umbral_similitud=0.85):\n",
    "    \"\"\"\n",
    "    Analiza todos los exámenes en la carpeta 'problemático' comparando SOLO con saved.\n",
    "    Muestra los 3 mejores resultados por alumno en tiempo real.\n",
    "    USA DIRECTAMENTE comparar_pdfs_visuales_con_tqdm - versión simplificada\n",
    "    \"\"\"\n",
    "    \n",
    "    ruta_problematico = Path(ruta_examenes) / \"problemático\"\n",
    "    \n",
    "    if not ruta_problematico.exists():\n",
    "        print(\"❌ No existe la carpeta 'problemático'\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    archivos_problematicos = list(ruta_problematico.glob(\"*.pdf\"))\n",
    "    \n",
    "    if not archivos_problematicos:\n",
    "        print(\"ℹ️ No hay archivos en la carpeta 'problemático'\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    print(f\"🔍 Analizando {len(archivos_problematicos)} archivos problemáticos...\")\n",
    "    print(\"💾 Solo comparando con archivos en /saved\")\n",
    "    if parar_en_100:\n",
    "        print(\"⏹️ Modo parada automática activado (se detiene al encontrar 100% similitud)\")\n",
    "    \n",
    "    resultados = []\n",
    "    \n",
    "    # Barra de progreso principal con tqdm\n",
    "    for archivo_objetivo in tqdm(archivos_problematicos, desc=\"📄 Procesando archivos\", unit=\"archivo\"):\n",
    "        try:\n",
    "            # Mostrar archivo actual\n",
    "            tqdm.write(f\"\\n📄 Procesando: {archivo_objetivo.name}\")\n",
    "            \n",
    "            # USAR DIRECTAMENTE comparar_pdfs_visuales_con_tqdm con ruta_lotes vacía\n",
    "            # para que SOLO compare con /saved\n",
    "            coincidencias = comparar_pdfs_visuales_con_tqdm_solo_saved(\n",
    "                archivo_objetivo.name,  # Solo el nombre del archivo\n",
    "                ruta_saved=ruta_saved,\n",
    "                ruta_examenes=str(ruta_problematico),  # Buscar en problemático\n",
    "                mostrar_detalles=False,  # Silencioso para no saturar output\n",
    "                parar_en_100=parar_en_100,\n",
    "                umbral_similitud=umbral_similitud\n",
    "            )\n",
    "            \n",
    "            if coincidencias:\n",
    "                # Filtrar solo coincidencias de tipo 'saved' y ordenar por similitud\n",
    "                coincidencias_saved = [c for c in coincidencias if c.get('tipo') == 'saved']\n",
    "                mejores_coincidencias = sorted(coincidencias_saved, key=lambda x: x['similitud'], reverse=True)[:3]\n",
    "                \n",
    "                # Agregar información adicional a cada coincidencia\n",
    "                for coincidencia in mejores_coincidencias:\n",
    "                    coincidencia['archivo_problematico'] = archivo_objetivo.name\n",
    "                \n",
    "                resultados.extend(mejores_coincidencias)\n",
    "                \n",
    "                # MOSTRAR RESULTADOS EN TIEMPO REAL\n",
    "                tqdm.write(\"🎯 MEJORES COINCIDENCIAS ENCONTRADAS:\")\n",
    "                tqdm.write(\"-\" * 60)\n",
    "                for j, coincidencia in enumerate(mejores_coincidencias, 1):\n",
    "                    icono = \"🥇\" if j == 1 else \"🥈\" if j == 2 else \"🥉\"\n",
    "                    \n",
    "                    tqdm.write(f\"{icono} #{j} 💾 {coincidencia['similitud']:.1%} - {coincidencia['archivo']}\")\n",
    "                    tqdm.write(f\"    📄 Páginas: {coincidencia['paginas']}\")\n",
    "                        \n",
    "                    if parar_en_100 and coincidencia['similitud'] >= 0.999:\n",
    "                        tqdm.write(\"    🎯 ¡COINCIDENCIA PERFECTA! Búsqueda detenida.\")\n",
    "                        break\n",
    "                        \n",
    "            else:\n",
    "                # Sin coincidencias\n",
    "                tqdm.write(\"❌ Sin coincidencias encontradas\")\n",
    "                reader_objetivo = PdfReader(archivo_objetivo)\n",
    "                num_paginas_objetivo = len(reader_objetivo.pages)\n",
    "                \n",
    "                resultados.append({\n",
    "                    'archivo_problematico': archivo_objetivo.name,\n",
    "                    'archivo': 'SIN_COINCIDENCIAS',\n",
    "                    'ruta': '',\n",
    "                    'tipo': 'ninguno',\n",
    "                    'similitud': 0.0,\n",
    "                    'paginas': num_paginas_objetivo\n",
    "                })\n",
    "                \n",
    "        except Exception as e:\n",
    "            tqdm.write(f\"❌ Error procesando {archivo_objetivo.name}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    # Crear DataFrame\n",
    "    df_resultados = pd.DataFrame(resultados)\n",
    "    \n",
    "    if df_resultados.empty:\n",
    "        print(\"\\n❌ No se encontraron resultados\")\n",
    "        return df_resultados\n",
    "    \n",
    "    # Extraer nombre del alumno del archivo problemático\n",
    "    df_resultados['alumno'] = df_resultados['archivo_problematico'].str.replace('.pdf', '').str.replace('_P[0-9]_.*', '', regex=True)\n",
    "    \n",
    "    # Ordenar por alumno y similitud (descendente)\n",
    "    df_resultados = df_resultados.sort_values(['alumno', 'similitud'], ascending=[True, False])\n",
    "    \n",
    "    # Reordenar columnas para mejor visualización\n",
    "    columnas_orden = ['alumno', 'archivo_problematico', 'similitud', 'archivo', 'tipo', 'paginas', 'ruta']\n",
    "    \n",
    "    df_resultados = df_resultados[columnas_orden].reset_index(drop=True)\n",
    "    \n",
    "    # RESUMEN FINAL\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"📊 RESUMEN FINAL DEL ANÁLISIS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    total_archivos = len(archivos_problematicos)\n",
    "    archivos_con_coincidencias = len(df_resultados[df_resultados['similitud'] > 0])\n",
    "    archivos_sin_coincidencias = len(df_resultados[df_resultados['similitud'] == 0])\n",
    "    \n",
    "    print(f\"📁 Total de archivos analizados: {total_archivos}\")\n",
    "    print(f\"✅ Archivos con coincidencias: {archivos_con_coincidencias}\")\n",
    "    print(f\"❌ Archivos sin coincidencias: {archivos_sin_coincidencias}\")\n",
    "    \n",
    "    # Estadísticas de similitud\n",
    "    if archivos_con_coincidencias > 0:\n",
    "        coincidencias_df = df_resultados[df_resultados['similitud'] > 0]\n",
    "        similitud_promedio = coincidencias_df['similitud'].mean()\n",
    "        similitud_maxima = coincidencias_df['similitud'].max()\n",
    "        \n",
    "        print(f\"📈 Similitud promedio: {similitud_promedio:.1%}\")\n",
    "        print(f\"🎯 Similitud máxima: {similitud_maxima:.1%}\")\n",
    "        \n",
    "        # Solo comparamos con saved, así que toda coincidencia es de tipo saved\n",
    "        print(f\"\\n💾 Todas las coincidencias son de /saved: {archivos_con_coincidencias} archivos\")\n",
    "    \n",
    "    return df_resultados\n",
    "\n",
    "def comparar_pdfs_visuales_con_tqdm_solo_saved(nombre_archivo_objetivo, \n",
    "                                               ruta_saved=\"../data/saved/\", \n",
    "                                               ruta_examenes=\"../data/examenes_procesados/problemático/\",\n",
    "                                               mostrar_detalles=False, \n",
    "                                               parar_en_100=False,\n",
    "                                               umbral_similitud=0.85):\n",
    "    \"\"\"\n",
    "    Versión modificada de comparar_pdfs_visuales_con_tqdm que SOLO compara con /saved\n",
    "    Sin comparar con lotes para optimizar el análisis de problemáticos\n",
    "    \"\"\"\n",
    "    \n",
    "    # Buscar el archivo objetivo en la ruta especificada\n",
    "    archivo_objetivo = None\n",
    "    ruta_examenes = Path(ruta_examenes)\n",
    "    \n",
    "    for archivo_pdf in ruta_examenes.glob(\"*.pdf\"):\n",
    "        if nombre_archivo_objetivo.lower() in archivo_pdf.name.lower():\n",
    "            archivo_objetivo = archivo_pdf\n",
    "            break\n",
    "    \n",
    "    if not archivo_objetivo or not archivo_objetivo.exists():\n",
    "        if mostrar_detalles:\n",
    "            print(f\"❌ No se encontró el archivo {nombre_archivo_objetivo}\")\n",
    "        return None\n",
    "    \n",
    "    if mostrar_detalles:\n",
    "        print(f\"🎯 Archivo encontrado: {archivo_objetivo}\")\n",
    "    \n",
    "    # Obtener número de páginas del objetivo\n",
    "    try:\n",
    "        reader_objetivo = PdfReader(archivo_objetivo)\n",
    "        num_paginas_objetivo = len(reader_objetivo.pages)\n",
    "        if mostrar_detalles:\n",
    "            print(f\"📄 Páginas del archivo objetivo: {num_paginas_objetivo}\")\n",
    "    except Exception as e:\n",
    "        if mostrar_detalles:\n",
    "            print(f\"❌ Error leyendo archivo objetivo: {e}\")\n",
    "        return None\n",
    "    \n",
    "    # Convertir páginas del objetivo a imágenes para comparación\n",
    "    try:\n",
    "        imagenes_objetivo = convert_from_path(\n",
    "            archivo_objetivo, \n",
    "            dpi=100,\n",
    "            fmt='jpeg'\n",
    "        )\n",
    "    except Exception as e:\n",
    "        if mostrar_detalles:\n",
    "            print(f\"❌ Error convirtiendo archivo objetivo: {e}\")\n",
    "        return None\n",
    "    \n",
    "    # Lista para almacenar similitudes\n",
    "    coincidencias_encontradas = []\n",
    "    \n",
    "    # COMPARAR SOLO CON ARCHIVOS EN /saved\n",
    "    ruta_saved = Path(ruta_saved)\n",
    "    \n",
    "    if ruta_saved.exists():\n",
    "        archivos_saved = list(ruta_saved.glob(\"*.pdf\"))\n",
    "        \n",
    "        # Usar tqdm para mostrar progreso\n",
    "        progress_bar = tqdm(archivos_saved, desc=\"💾 Comparando con /saved\", leave=False, unit=\"archivo\")\n",
    "        \n",
    "        for archivo_saved in progress_bar:\n",
    "            try:\n",
    "                reader_saved = PdfReader(archivo_saved)\n",
    "                num_paginas_saved = len(reader_saved.pages)\n",
    "                \n",
    "                # Solo comparar si tienen el mismo número de páginas\n",
    "                if num_paginas_saved == num_paginas_objetivo:\n",
    "                    # Convertir a imágenes\n",
    "                    imagenes_saved = convert_from_path(archivo_saved, dpi=100, fmt='jpeg')\n",
    "                    \n",
    "                    # Comparar cada página\n",
    "                    similitud_total = comparar_imagenes_paginas(imagenes_objetivo, imagenes_saved)\n",
    "                    \n",
    "                    if similitud_total >= umbral_similitud:  # Usar umbral personalizado\n",
    "                        similitud_info = {\n",
    "                            'archivo': archivo_saved.name,\n",
    "                            'ruta': str(archivo_saved),\n",
    "                            'tipo': 'saved',\n",
    "                            'similitud': similitud_total,\n",
    "                            'paginas': num_paginas_saved\n",
    "                        }\n",
    "                        coincidencias_encontradas.append(similitud_info)\n",
    "                        \n",
    "                        if mostrar_detalles:\n",
    "                            tqdm.write(f\"    ✅ COINCIDENCIA: {similitud_total:.2%}\")\n",
    "                        \n",
    "                        # PARADA AUTOMÁTICA al 100%\n",
    "                        if parar_en_100 and similitud_total >= 0.999:\n",
    "                            if mostrar_detalles:\n",
    "                                tqdm.write(f\"    🎯 ¡100% SIMILITUD ENCONTRADA! Deteniendo búsqueda...\")\n",
    "                            break\n",
    "                        \n",
    "            except Exception as e:\n",
    "                if mostrar_detalles:\n",
    "                    tqdm.write(f\"  ❌ Error procesando {archivo_saved.name}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        progress_bar.close()\n",
    "    \n",
    "    # Retornar coincidencias ordenadas por similitud\n",
    "    if coincidencias_encontradas:\n",
    "        coincidencias_encontradas.sort(key=lambda x: x['similitud'], reverse=True)\n",
    "    \n",
    "    return coincidencias_encontradas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "8d3ba83d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Iniciando análisis RÁPIDO con parada automática...\n",
      "❌ No existe la carpeta 'problemático'\n"
     ]
    }
   ],
   "source": [
    "print(\"🚀 Iniciando análisis RÁPIDO con parada automática...\")\n",
    "df_problematicos_rapido = analizar_examenes_problematicos(\n",
    "    parar_en_100=True,  # ⭐ PARADA AUTOMÁTICA ACTIVADA\n",
    "    umbral_similitud=0.8  # Umbral más alto para ser más selectivo\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dba14ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Juntar pdfs\n",
    "import os\n",
    "from pathlib import Path\n",
    "from pypdf import PdfReader, PdfWriter\n",
    "import re\n",
    "\n",
    "def organizar_pdfs_por_carpetas(ruta_examenes=\"../data/examenes_procesados/\", \n",
    "                               pdfs_por_archivo=1,  # Cambiado a 1\n",
    "                               grupos_objetivo=None):\n",
    "    \"\"\"\n",
    "    Organiza los PDFs de exámenes juntándolos en grupos de N archivos por carpeta,\n",
    "    ordenados alfabéticamente como aparecen en el filesystem.\n",
    "    \n",
    "    Args:\n",
    "        ruta_examenes: Ruta base de los exámenes procesados\n",
    "        pdfs_por_archivo: Número de PDFs a juntar en cada archivo resultante\n",
    "        grupos_objetivo: Lista de grupos específicos a procesar (None = todos)\n",
    "    \"\"\"\n",
    "    \n",
    "    ruta_base = Path(ruta_examenes)\n",
    "    \n",
    "    if not ruta_base.exists():\n",
    "        print(f\"❌ La ruta {ruta_base} no existe\")\n",
    "        return\n",
    "    \n",
    "    # Si no se especifican grupos, procesar todos\n",
    "    if grupos_objetivo is None:\n",
    "        grupos_objetivo = ['IWSIM11', 'IWSIM12', 'CITIM11', 'CITIM12']\n",
    "    \n",
    "    print(f\"🔍 Organizando PDFs - 1 PDF por archivo de práctica y grupo\")\n",
    "    print(f\"📁 Grupos a procesar: {', '.join(grupos_objetivo)}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for grupo in grupos_objetivo:\n",
    "        carpeta_grupo = ruta_base / grupo\n",
    "        \n",
    "        if not carpeta_grupo.exists():\n",
    "            print(f\"⚠️ La carpeta {grupo} no existe, saltando...\")\n",
    "            continue\n",
    "            \n",
    "        print(f\"\\n📂 Procesando grupo: {grupo}\")\n",
    "        \n",
    "        # Buscar subcarpetas de prácticas\n",
    "        subcarpetas_practica = []\n",
    "        for item in carpeta_grupo.iterdir():\n",
    "            if item.is_dir() and item.name.startswith(\"Practica_\"):\n",
    "                subcarpetas_practica.append(item)\n",
    "        \n",
    "        # Ordenar subcarpetas alfabéticamente\n",
    "        subcarpetas_practica.sort(key=lambda x: x.name)\n",
    "        \n",
    "        for subcarpeta in subcarpetas_practica:\n",
    "            print(f\"  📁 Procesando {subcarpeta.name}\")\n",
    "            \n",
    "            # Obtener todos los PDFs y ordenarlos alfabéticamente\n",
    "            archivos_pdf = list(subcarpeta.glob(\"*.pdf\"))\n",
    "            # Filtrar archivos que NO sean de lotes (para evitar duplicados)\n",
    "            archivos_pdf = [pdf for pdf in archivos_pdf if not re.search(r'_Lote\\d+\\.pdf$', pdf.name)]\n",
    "            archivos_pdf.sort(key=lambda x: x.name.lower())  # Orden alfabético\n",
    "            \n",
    "            if not archivos_pdf:\n",
    "                print(f\"    ℹ️ No hay PDFs en {subcarpeta.name}\")\n",
    "                continue\n",
    "            \n",
    "            print(f\"    📄 Encontrados {len(archivos_pdf)} PDFs\")\n",
    "            \n",
    "            # Crear UN solo archivo por práctica y grupo\n",
    "            practica_num = subcarpeta.name.replace(\"Practica_\", \"\")\n",
    "            nombre_resultado = f\"{grupo}_P{practica_num}.pdf\"\n",
    "            ruta_resultado = subcarpeta / nombre_resultado\n",
    "            \n",
    "            print(f\"    🔗 Creando archivo único: {nombre_resultado}\")\n",
    "            print(f\"       📝 Archivos incluidos:\")\n",
    "            \n",
    "            # Crear el PDF combinado\n",
    "            writer = PdfWriter()\n",
    "            \n",
    "            for archivo in archivos_pdf:\n",
    "                print(f\"         • {archivo.name}\")\n",
    "                \n",
    "                try:\n",
    "                    reader = PdfReader(archivo)\n",
    "                    for page in reader.pages:\n",
    "                        writer.add_page(page)\n",
    "                except Exception as e:\n",
    "                    print(f\"         ❌ Error leyendo {archivo.name}: {e}\")\n",
    "                    continue\n",
    "            \n",
    "            # Guardar el archivo combinado\n",
    "            try:\n",
    "                with open(ruta_resultado, 'wb') as archivo_salida:\n",
    "                    writer.write(archivo_salida)\n",
    "                \n",
    "                total_paginas = len(writer.pages)\n",
    "                print(f\"       ✅ Creado: {total_paginas} páginas totales\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"       ❌ Error guardando {nombre_resultado}: {e}\")\n",
    "    \n",
    "    print(f\"\\n🎉 ¡Proceso completado!\")\n",
    "\n",
    "def listar_archivos_resultantes(ruta_examenes=\"../data/examenes_procesados/\",\n",
    "                               grupos_objetivo=None):\n",
    "    \"\"\"\n",
    "    Lista los archivos creados para verificar el resultado\n",
    "    \"\"\"\n",
    "    \n",
    "    ruta_base = Path(ruta_examenes)\n",
    "    \n",
    "    if grupos_objetivo is None:\n",
    "        grupos_objetivo = ['IWSIM11', 'IWSIM12', 'CITIM11', 'CITIM12']\n",
    "    \n",
    "    print(\"📋 ARCHIVOS CREADOS:\")   \n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    for grupo in grupos_objetivo:\n",
    "        carpeta_grupo = ruta_base / grupo\n",
    "        \n",
    "        if not carpeta_grupo.exists():\n",
    "            continue\n",
    "            \n",
    "        print(f\"\\n📂 {grupo}:\")\n",
    "        \n",
    "        for subcarpeta in carpeta_grupo.iterdir():\n",
    "            if subcarpeta.is_dir() and subcarpeta.name.startswith(\"Practica_\"):\n",
    "                # Buscar el archivo único por práctica\n",
    "                archivo_practica = list(subcarpeta.glob(f\"{grupo}_P*.pdf\"))\n",
    "                archivo_practica = [f for f in archivo_practica if not re.search(r'_Lote\\d+\\.pdf$', f.name)]\n",
    "                \n",
    "                if archivo_practica:\n",
    "                    print(f\"  📁 {subcarpeta.name}:\")\n",
    "                    \n",
    "                    for archivo in archivo_practica:\n",
    "                        try:\n",
    "                            reader = PdfReader(archivo)\n",
    "                            num_paginas = len(reader.pages)\n",
    "                            tamaño_mb = archivo.stat().st_size / (1024 * 1024)\n",
    "                            \n",
    "                            print(f\"    📄 {archivo.name}\")\n",
    "                            print(f\"       • Páginas: {num_paginas}\")\n",
    "                            print(f\"       • Tamaño: {tamaño_mb:.1f} MB\")\n",
    "                        except Exception as e:\n",
    "                            print(f\"    ❌ Error leyendo {archivo.name}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc3f430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejecutar la organización\n",
    "#organizar_pdfs_por_carpetas(ruta_examenes=\"../data/examenes_procesados/\")\n",
    "\n",
    "# Mostrar resumen de archivos creados\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "#listar_archivos_resultantes()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a41e89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7d6b4578",
   "metadata": {},
   "source": [
    "# Check completed deriverables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e07d0a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizar_texto(texto):\n",
    "    \"\"\"Normaliza texto eliminando acentos y caracteres especiales\"\"\"\n",
    "    texto = unicodedata.normalize('NFD', texto)\n",
    "    texto = ''.join(char for char in texto if unicodedata.category(char) != 'Mn')\n",
    "    texto = texto.upper().strip()\n",
    "    texto = re.sub(r'[^A-Z0-9\\s]', '', texto)\n",
    "    return texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a34e38e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def buscar_practica_en_zips(apellidos, nombre, practica_num=3, ruta_data=\"./../data/\"):\n",
    "    \"\"\"\n",
    "    Busca si existe una práctica para un alumno en los archivos ZIP\n",
    "    \n",
    "    Args:\n",
    "        apellidos: Apellidos del alumno\n",
    "        nombre: Nombre del alumno\n",
    "        practica_num: Número de práctica (3 o 5)\n",
    "        ruta_data: Ruta base a la carpeta data\n",
    "    \"\"\"\n",
    "    ruta_practica = Path(ruta_data) / f\"Practica{practica_num}\"\n",
    "    \n",
    "    if not ruta_practica.exists():\n",
    "        return False\n",
    "    \n",
    "    # Normalizar apellidos y nombre\n",
    "    apellidos_norm = normalizar_texto(apellidos)\n",
    "    nombre_norm = normalizar_texto(nombre)\n",
    "    \n",
    "    # Buscar en todos los archivos ZIP\n",
    "    for archivo_zip in ruta_practica.glob(\"*.zip\"):\n",
    "        try:\n",
    "            with zipfile.ZipFile(archivo_zip, 'r') as zip_ref:\n",
    "                for archivo in zip_ref.namelist():\n",
    "                    archivo_norm = normalizar_texto(archivo)\n",
    "                    \n",
    "                    # Verificar si el archivo contiene apellidos y nombre\n",
    "                    if apellidos_norm in archivo_norm and nombre_norm in archivo_norm:\n",
    "                        return True\n",
    "        except Exception as e:\n",
    "            continue\n",
    "    \n",
    "    return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f1bdc720",
   "metadata": {},
   "outputs": [],
   "source": [
    "def buscar_examen_procesado(\n",
    "        apellidos, \n",
    "        nombre, \n",
    "        grupo, \n",
    "        practica_num=3,\n",
    "        ruta_data=\"./../data\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Busca si existe un examen procesado para un alumno\n",
    "    \n",
    "    Args:\n",
    "        apellidos: Apellidos del alumno\n",
    "        nombre: Nombre del alumno\n",
    "        grupo: Grupo del alumno\n",
    "        practica_num: Número de práctica (3 o 5)\n",
    "    \n",
    "    Returns:\n",
    "        Boolean indicando si se encontró el examen\n",
    "    \"\"\"\n",
    "    # Ruta donde se guardan los exámenes procesados\n",
    "    ruta_examenes = Path(ruta_data+\"/examenes_procesados\") / grupo / f\"Practica_{practica_num}\"\n",
    "    print(f\"Buscando en: {ruta_examenes}\")\n",
    "    # Si la ruta no existe, no hay exámenes para ese grupo/práctica\n",
    "    if not ruta_examenes.exists():\n",
    "        return False\n",
    "    \n",
    "    # Normalizar apellidos y nombre\n",
    "    apellidos_norm = normalizar_texto(apellidos)\n",
    "    nombre_norm = normalizar_texto(nombre)\n",
    "    \n",
    "    # Patrones para buscar en los nombres de archivo\n",
    "    patrones = [\n",
    "        # Patrón: Apellidos_Nombre\n",
    "        f\"{apellidos_norm}_{nombre_norm}\",\n",
    "        # Patrón: Apellidos Nombre\n",
    "        f\"{apellidos_norm} {nombre_norm}\",\n",
    "        # Patrón: Nombre_Apellidos\n",
    "        f\"{nombre_norm}_{apellidos_norm}\",\n",
    "        # Patrón: Nombre Apellidos\n",
    "        f\"{nombre_norm} {apellidos_norm}\",\n",
    "        # Patrón simplemente buscar ambos\n",
    "        apellidos_norm\n",
    "    ]\n",
    "    \n",
    "    # Buscar en todos los archivos de la carpeta\n",
    "    for archivo in ruta_examenes.glob(\"*.*\"):\n",
    "        nombre_archivo_norm = normalizar_texto(archivo.stem)\n",
    "        \n",
    "        # Verificar si algún patrón coincide con el nombre del archivo\n",
    "        for patron in patrones:\n",
    "            if patron in nombre_archivo_norm:\n",
    "                # Si además del apellido también está el nombre, es una coincidencia más fiable\n",
    "                if nombre_norm in nombre_archivo_norm:\n",
    "                    return True\n",
    "                # Si solo coincide con el apellido y este es poco común, también se considera válido\n",
    "                elif len(apellidos_norm) > 5:  # Apellidos largos son menos comunes\n",
    "                    return True\n",
    "    \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "88d24383",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imprimir_estado_ruta(ruta: Path, descripcion: str) -> bool:\n",
    "    \"\"\"Imprime la existencia de una ruta con una descripción y devuelve si existe.\"\"\"\n",
    "    print(f\"{descripcion}: {ruta.absolute()} {'✅' if ruta.exists() else '❌'}\")\n",
    "    return ruta.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f416aee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verificar_practicas(ruta_base: Path, practicas: list[str]) -> dict[str, bool]:\n",
    "    \"\"\"Verifica una lista de carpetas de prácticas dentro de ruta_base.\"\"\"\n",
    "    estados = {}\n",
    "    print(\"\\nCarpetas de prácticas:\")\n",
    "    for nombre in practicas:\n",
    "        ruta = ruta_base / nombre\n",
    "        existe = imprimir_estado_ruta(ruta, f\"- {nombre}\")\n",
    "        estados[nombre] = existe\n",
    "    return estados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f1940abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def listar_grupos_en_examenes(ruta_examenes: Path) -> list[str]:\n",
    "    \"\"\"Si existe la carpeta de exámenes, lista subcarpetas (grupos).\"\"\"\n",
    "    grupos = []\n",
    "    if ruta_examenes.exists():\n",
    "        for d in ruta_examenes.iterdir():\n",
    "            if d.is_dir():\n",
    "                grupos.append(d.name)\n",
    "        print(f\"Grupos disponibles ({len(grupos)}): {', '.join(grupos) if grupos else 'ninguno'}\")\n",
    "    return grupos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b86c17ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verificar_rutas(ruta_data: str = \"../data\") -> bool:\n",
    "    \"\"\"\n",
    "    Función principal: verifica existencia de ruta base, \n",
    "    carpetas de prácticas y carpeta de exámenes, listando grupos.\n",
    "    \"\"\"\n",
    "    ruta_base = Path(ruta_data)\n",
    "    print(f\"Verificando ruta base: {ruta_base.absolute()}\")\n",
    "    base_ok = imprimir_estado_ruta(ruta_base, \"¿Existe ruta base?\")\n",
    "    \n",
    "    practicas = [\"Practica3\", \"Practica5\"]\n",
    "    estados_practicas = verificar_practicas(ruta_base, practicas)\n",
    "    \n",
    "    ruta_examenes = ruta_base / \"examenes_procesados\"\n",
    "    print(f\"\\nCarpeta de exámenes:\")\n",
    "    examen_ok = imprimir_estado_ruta(ruta_examenes, \"¿Existe carpeta de exámenes?\")\n",
    "    \n",
    "    grupos = listar_grupos_en_examenes(ruta_examenes)\n",
    "    \n",
    "    return base_ok, estados_practicas, examen_ok, grupos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5efdb2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#verificar_rutas(\"../data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5ebbe711",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contar_examenes_por_grupo(ruta_data=\"../data\"):\n",
    "    \"\"\"Cuenta cuántos exámenes hay por grupo y práctica\"\"\"\n",
    "    ruta_examenes = Path(ruta_data) / \"examenes_procesados\"\n",
    "    \n",
    "    if not ruta_examenes.exists():\n",
    "        print(f\"La ruta {ruta_examenes.absolute()} no existe\")\n",
    "        return\n",
    "    \n",
    "    total = 0\n",
    "    resultados = {}\n",
    "    \n",
    "    grupos = [d for d in ruta_examenes.iterdir() if d.is_dir()]\n",
    "    for grupo in grupos:\n",
    "        resultados[grupo.name] = {}\n",
    "        \n",
    "        for practica in [\"Practica_3\", \"Practica_5\"]:\n",
    "            ruta_practica = grupo / practica\n",
    "            if ruta_practica.exists():\n",
    "                try:\n",
    "                    archivos = list(ruta_practica.glob(\"*.*\"))\n",
    "                    n_archivos = len(archivos)\n",
    "                    resultados[grupo.name][practica] = n_archivos\n",
    "                    total += n_archivos\n",
    "                except Exception as e:\n",
    "                    resultados[grupo.name][practica] = f\"Error: {e}\"\n",
    "            else:\n",
    "                resultados[grupo.name][practica] = 0\n",
    "    \n",
    "    # Mostrar resultados\n",
    "    print(f\"Total exámenes encontrados: {total}\")\n",
    "    print(\"\\nDesglose por grupo y práctica:\")\n",
    "    \n",
    "    for grupo, practicas in resultados.items():\n",
    "        print(f\"\\n{grupo}:\")\n",
    "        for practica, cantidad in practicas.items():\n",
    "            print(f\"  - {practica}: {cantidad}\")\n",
    "    \n",
    "    return resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ba0448eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#contar_examenes_por_grupo(\"../data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f57b34f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame original cargado:\n",
      "Total alumnos: 444\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_students[\"Nombre\"] = df_students[\"Nombre\"].str.strip().str.upper()\n",
    "df_students[\"Apellido(s)\"] = df_students[\"Apellido(s)\"].str.strip().str.upper()\n",
    "print(\"DataFrame original cargado:\")\n",
    "print(f\"Total alumnos: {len(df_students)}\")\n",
    "#print(df_students.head())\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3ee8e31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def probar_busqueda_examenes(apellidos, nombre, grupo, ruta_data=\"../data\"):\n",
    "    \"\"\"Prueba la búsqueda de exámenes para un estudiante específico\"\"\"\n",
    "    print(f\"Probando búsqueda para: {apellidos}, {nombre} (Grupo: {grupo})\")\n",
    "    \n",
    "    # Normalizar para mostrar\n",
    "    apellidos_norm = normalizar_texto(apellidos)\n",
    "    nombre_norm = normalizar_texto(nombre)\n",
    "    print(f\"Texto normalizado: {apellidos_norm}, {nombre_norm}\")\n",
    "    \n",
    "    # Probar prácticas 3 y 5\n",
    "    for practica_num in [3, 5]:\n",
    "        # Ruta donde se guardan los exámenes procesados\n",
    "        ruta_examenes = Path(ruta_data) / \"examenes_procesados\" / grupo / f\"Practica_{practica_num}\"\n",
    "        print(f\"\\nPráctica {practica_num}:\")\n",
    "        print(f\"Ruta: {ruta_examenes}\")\n",
    "        \n",
    "        if not ruta_examenes.exists():\n",
    "            print(f\"  ❌ La ruta no existe\")\n",
    "            continue\n",
    "            \n",
    "        print(f\"  ✅ La ruta existe\")\n",
    "        \n",
    "        # Listar todos los archivos en la carpeta\n",
    "        print(\"  Archivos en la carpeta:\")\n",
    "        archivos = list(ruta_examenes.glob(\"*.*\"))\n",
    "        \n",
    "        if not archivos:\n",
    "            print(\"    (Carpeta vacía)\")\n",
    "        \n",
    "        for archivo in archivos[:10]:  # Limitar a 10 para no saturar la salida\n",
    "            print(f\"    - {archivo.name}\")\n",
    "        \n",
    "        if len(archivos) > 10:\n",
    "            print(f\"    ... y {len(archivos)-10} archivos más\")\n",
    "        \n",
    "        # Probar búsqueda\n",
    "        resultado = buscar_examen_procesado(apellidos, nombre, grupo, practica_num, ruta_data)\n",
    "        print(f\"\\n  Resultado de búsqueda: {'✅ Encontrado' if resultado else '❌ No encontrado'}\")\n",
    "        \n",
    "        # Si no se encontró, mostrar los patrones que se buscaron\n",
    "        if not resultado:\n",
    "            print(\"\\n  Patrones buscados:\")\n",
    "            patrones = [\n",
    "                f\"{apellidos_norm}_{nombre_norm}\",\n",
    "                f\"{apellidos_norm} {nombre_norm}\",\n",
    "                f\"{nombre_norm}_{apellidos_norm}\",\n",
    "                f\"{nombre_norm} {apellidos_norm}\",\n",
    "                apellidos_norm\n",
    "            ]\n",
    "            for patron in patrones:\n",
    "                print(f\"    - '{patron}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4275df7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def listar_ejemplos_examenes(ruta_data=\"../data\", max_por_grupo=5):\n",
    "    \"\"\"Lista ejemplos de nombres de archivos de exámenes por grupo\"\"\"\n",
    "    ruta_examenes = Path(ruta_data) / \"examenes_procesados\"\n",
    "    \n",
    "    if not ruta_examenes.exists():\n",
    "        print(f\"La ruta {ruta_examenes.absolute()} no existe\")\n",
    "        return\n",
    "    \n",
    "    grupos = [d for d in ruta_examenes.iterdir() if d.is_dir()]\n",
    "    print(f\"Ejemplos de nombres de archivos por grupo:\")\n",
    "    \n",
    "    for grupo in grupos:\n",
    "        print(f\"\\n{grupo.name}:\")\n",
    "        \n",
    "        for practica in [\"Practica_3\", \"Practica_5\"]:\n",
    "            ruta_practica = grupo / practica\n",
    "            if ruta_practica.exists():\n",
    "                print(f\"  {practica}:\")\n",
    "                try:\n",
    "                    archivos = list(ruta_practica.glob(\"*.*\"))[:max_por_grupo]\n",
    "                    if not archivos:\n",
    "                        print(\"    (Carpeta vacía)\")\n",
    "                    for archivo in archivos:\n",
    "                        print(f\"    - {archivo.name}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"    Error al listar archivos: {e}\")\n",
    "            else:\n",
    "                print(f\"  {practica}: No existe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a379735e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def listar_grupos_disponibles(ruta_data=\"../data\"):\n",
    "    \"\"\"Lista los nombres exactos de las carpetas de grupos disponibles\"\"\"\n",
    "    ruta_examenes = Path(ruta_data) / \"examenes_procesados\"\n",
    "    \n",
    "    if not ruta_examenes.exists():\n",
    "        print(f\"La ruta {ruta_examenes.absolute()} no existe\")\n",
    "        return []\n",
    "    \n",
    "    grupos = [d.name for d in ruta_examenes.iterdir() if d.is_dir()]\n",
    "    print(f\"Grupos disponibles ({len(grupos)}): {', '.join(grupos)}\")\n",
    "    \n",
    "    return grupos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4fff1397",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El grupo de SOFIA AGAPITO DELGADO es: IWSIT11\n",
      "\n",
      "Información completa:\n",
      "Nombre     Apellido(s)  Grupos\n",
      " SOFIA AGAPITO DELGADO IWSIT11\n"
     ]
    }
   ],
   "source": [
    "# Buscar el grupo de AGAPITO DELGADO, SOFIA en df_students_full\n",
    "resultado = df_students_full[\n",
    "    (df_students_full['Apellido(s)'] == 'AGAPITO DELGADO') & \n",
    "    (df_students_full['Nombre'] == 'SOFIA')\n",
    "]\n",
    "\n",
    "if not resultado.empty:\n",
    "    grupo = resultado['Grupos'].iloc[0]\n",
    "    print(f\"El grupo de SOFIA AGAPITO DELGADO es: {grupo}\")\n",
    "    print(\"\\nInformación completa:\")\n",
    "    print(resultado[['Nombre', 'Apellido(s)', 'Grupos']].to_string(index=False))\n",
    "else:\n",
    "    print(\"No se encontró a SOFIA AGAPITO DELGADO en el DataFrame\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6a212e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapear_grupos_a_carpetas(ruta_data=\"../data\"):\n",
    "    \"\"\"\n",
    "    Crea un mapeo de códigos de grupo a nombres de carpetas reales\n",
    "    \n",
    "    Args:\n",
    "        ruta_data: Ruta base a la carpeta data\n",
    "    \n",
    "    Returns:\n",
    "        Diccionario que mapea códigos de grupo a nombres de carpeta\n",
    "    \"\"\"\n",
    "    ruta_examenes = Path(ruta_data) / \"examenes_procesados\"\n",
    "    \n",
    "    if not ruta_examenes.exists():\n",
    "        return {}\n",
    "    \n",
    "    # Obtener las carpetas de grupos disponibles\n",
    "    carpetas_grupos = [d.name for d in ruta_examenes.iterdir() if d.is_dir()]\n",
    "    \n",
    "    # Crear un mapeo de códigos de grupos a carpetas\n",
    "    mapeo = {}\n",
    "    for carpeta in carpetas_grupos:\n",
    "        mapeo[carpeta] = carpeta  # Mapeo directo para coincidencias exactas\n",
    "        \n",
    "        # También mapear códigos que estén contenidos en nombres de carpeta\n",
    "        for codigo in ['IWSIM11', 'IWSIM12', 'CITIM11', 'CITIM12', 'CITIT11', 'IWSIT12']:\n",
    "            if codigo in carpeta and codigo not in mapeo:\n",
    "                mapeo[codigo] = carpeta\n",
    "    \n",
    "    return mapeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d733dbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def buscar_examen_mejorado(apellidos, nombre, grupo, practica_num, ruta_data=\"../data\", verbose=False):\n",
    "    \"\"\"\n",
    "    Función mejorada para buscar exámenes con patrones más flexibles\n",
    "    \n",
    "    Args:\n",
    "        apellidos: Apellidos del alumno\n",
    "        nombre: Nombre del alumno\n",
    "        grupo: Grupo del alumno (nombre de carpeta)\n",
    "        practica_num: Número de práctica (3 o 5)\n",
    "        ruta_data: Ruta base a la carpeta data\n",
    "        verbose: Si es True, muestra información detallada de la búsqueda\n",
    "    \n",
    "    Returns:\n",
    "        Boolean indicando si se encontró el examen\n",
    "    \"\"\"\n",
    "    # Ruta donde se guardan los exámenes procesados\n",
    "    ruta_examenes = Path(ruta_data) / \"examenes_procesados\" / grupo / f\"Practica_{practica_num}\"\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"Buscando en: {ruta_examenes}\")\n",
    "    \n",
    "    # Si la ruta no existe, no hay exámenes para ese grupo/práctica\n",
    "    if not ruta_examenes.exists():\n",
    "        if verbose:\n",
    "            print(f\"La ruta {ruta_examenes} no existe\")\n",
    "        return False\n",
    "    \n",
    "    # Normalizar textos\n",
    "    apellidos_norm = normalizar_texto(apellidos)\n",
    "    nombre_norm = normalizar_texto(nombre)\n",
    "    \n",
    "    # Separar apellidos si hay varios\n",
    "    apellidos_lista = apellidos_norm.split()\n",
    "    \n",
    "    # Patrones para buscar en los nombres de archivo\n",
    "    patrones = [\n",
    "        f\"{apellidos_norm}_{nombre_norm}\",         # Apellidos_Nombre\n",
    "        f\"{apellidos_norm} {nombre_norm}\",         # Apellidos Nombre\n",
    "        f\"{nombre_norm}_{apellidos_norm}\",         # Nombre_Apellidos\n",
    "        f\"{nombre_norm} {apellidos_norm}\",         # Nombre Apellidos\n",
    "        apellidos_norm,                            # Solo apellidos\n",
    "    ]\n",
    "    \n",
    "    # Añadir patrones específicos para el formato P5_GRUPO\n",
    "    patrones_practica = [\n",
    "        f\"{apellidos_norm}_{nombre_norm}_P{practica_num}_{grupo}\",\n",
    "        f\"{apellidos_norm}_{nombre_norm}_P{practica_num}\",\n",
    "        f\"{nombre_norm}_{apellidos_norm}_P{practica_num}\"\n",
    "    ]\n",
    "    \n",
    "    todos_patrones = patrones + patrones_practica\n",
    "    \n",
    "    # Buscar en todos los archivos de la carpeta\n",
    "    for archivo in ruta_examenes.glob(\"*.*\"):\n",
    "        nombre_archivo_norm = normalizar_texto(archivo.stem)\n",
    "        \n",
    "        # Verificar si algún patrón coincide con el nombre del archivo\n",
    "        for patron in todos_patrones:\n",
    "            if patron in nombre_archivo_norm:\n",
    "                if verbose:\n",
    "                    print(f\"✅ Encontrado con patrón '{patron}': {archivo.name}\")\n",
    "                return True\n",
    "                \n",
    "        # Si no hay coincidencia exacta con los patrones, probar si están presentes \n",
    "        # tanto el nombre como al menos un apellido (para el formato libre)\n",
    "        if nombre_norm in nombre_archivo_norm:\n",
    "            for apellido in apellidos_lista:\n",
    "                if len(apellido) > 3 and apellido in nombre_archivo_norm:  # Apellido con longitud razonable\n",
    "                    if verbose:\n",
    "                        print(f\"✅ Encontrado parcial: {archivo.name}\")\n",
    "                    return True\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"❌ No se encontró ninguna coincidencia para {apellidos_norm}, {nombre_norm}\")\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "202a49f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verificar_todas_las_practicas(df, ruta_data=\"../data\", grupo_filtro=None, verbose=False):\n",
    "    \"\"\"\n",
    "    Añade columnas de verificación de prácticas y exámenes al DataFrame existente\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame con columnas 'Nombre' y 'Apellido(s)'\n",
    "        ruta_data: Ruta base a la carpeta data\n",
    "        grupo_filtro: Opcional, nombre del grupo para filtrar (ej. \"IWSIM11\")\n",
    "        verbose: Si es True, muestra información detallada\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame modificado con las nuevas columnas\n",
    "    \"\"\"\n",
    "    # Obtener el mapeo de grupos a carpetas\n",
    "    mapeo_grupos = mapear_grupos_a_carpetas(ruta_data)\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"Mapeo de grupos a carpetas: {mapeo_grupos}\")\n",
    "    \n",
    "    # Filtrar el DataFrame por grupo si se especificó\n",
    "    if grupo_filtro:\n",
    "        if verbose:\n",
    "            print(f\"Filtrando por grupo: {grupo_filtro}\")\n",
    "        df = df[df['Grupos'].str.contains(grupo_filtro, case=False, na=False)]\n",
    "        print(f\"Encontrados {len(df)} estudiantes del grupo {grupo_filtro}\")\n",
    "    \n",
    "    # Crear copias para evitar warnings\n",
    "    df_resultado = df.copy()\n",
    "    \n",
    "    # Inicializar las nuevas columnas para prácticas\n",
    "    df_resultado['Presentada_3'] = 0\n",
    "    df_resultado['Comentario_3'] = 'NP'\n",
    "    df_resultado['Presentada_5'] = 0\n",
    "    df_resultado['Comentario_5'] = 'NP'\n",
    "    \n",
    "    # Inicializar las nuevas columnas para exámenes\n",
    "    df_resultado['Examen Practica 3'] = None\n",
    "    df_resultado['Examen Practica 5'] = None\n",
    "    df_resultado['Examen Practica 3 entregado'] = 0\n",
    "    df_resultado['Examen Practica 5 entregado'] = 0\n",
    "    \n",
    "    print(\"Verificando entregas de prácticas y exámenes...\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Contadores para estadísticas\n",
    "    practicas_3_encontradas = 0\n",
    "    practicas_5_encontradas = 0\n",
    "    examenes_3_encontrados = 0\n",
    "    examenes_5_encontrados = 0\n",
    "    total_alumnos = len(df_resultado)\n",
    "    \n",
    "    # Para cada alumno en el DataFrame\n",
    "    for idx, row in df_resultado.iterrows():\n",
    "        nombre = str(row['Nombre'])\n",
    "        apellidos = str(row['Apellido(s)'])\n",
    "        grupo_codigo = str(row.get('Grupos', 'extraviado'))\n",
    "        \n",
    "        # Obtener la carpeta real del grupo (si existe)\n",
    "        grupo_carpeta = mapeo_grupos.get(grupo_codigo, grupo_codigo)\n",
    "        \n",
    "        # Verificar Práctica 3\n",
    "        tiene_practica3 = buscar_practica_en_zips(apellidos, nombre, 3, ruta_data)\n",
    "        if tiene_practica3:\n",
    "            df_resultado.loc[idx, 'Presentada_3'] = 1\n",
    "            df_resultado.loc[idx, 'Comentario_3'] = ''\n",
    "            practicas_3_encontradas += 1\n",
    "        \n",
    "        # Verificar Práctica 5\n",
    "        tiene_practica5 = buscar_practica_en_zips(apellidos, nombre, 5, ruta_data)\n",
    "        if tiene_practica5:\n",
    "            df_resultado.loc[idx, 'Presentada_5'] = 1\n",
    "            df_resultado.loc[idx, 'Comentario_5'] = ''\n",
    "            practicas_5_encontradas += 1\n",
    "        \n",
    "        # Verificar Examen de Práctica 3\n",
    "        tiene_examen3 = buscar_examen_mejorado(\n",
    "            apellidos, nombre, grupo_carpeta, 3, ruta_data, verbose=False\n",
    "        )\n",
    "        if tiene_examen3:\n",
    "            df_resultado.loc[idx, 'Examen Practica 3 entregado'] = 1\n",
    "            examenes_3_encontrados += 1\n",
    "            # Si no tiene práctica pero sí examen, poner 0\n",
    "            if not tiene_practica3:\n",
    "                df_resultado.loc[idx, 'Examen Practica 3'] = 0\n",
    "        else:\n",
    "            # No ha presentado el examen\n",
    "            if df_resultado.loc[idx, 'Comentario_3']:\n",
    "                df_resultado.loc[idx, 'Comentario_3'] += '. Examen no presentado'\n",
    "            else:\n",
    "                df_resultado.loc[idx, 'Comentario_3'] = 'Examen no presentado'\n",
    "        \n",
    "        # Verificar Examen de Práctica 5\n",
    "        tiene_examen5 = buscar_examen_mejorado(\n",
    "            apellidos, nombre, grupo_carpeta, 5, ruta_data, verbose=False\n",
    "        )\n",
    "        if tiene_examen5:\n",
    "            df_resultado.loc[idx, 'Examen Practica 5 entregado'] = 1\n",
    "            examenes_5_encontrados += 1\n",
    "            # Si no tiene práctica pero sí examen, poner 0\n",
    "            if not tiene_practica5:\n",
    "                df_resultado.loc[idx, 'Examen Practica 5'] = 0\n",
    "        else:\n",
    "            # No ha presentado el examen\n",
    "            if df_resultado.loc[idx, 'Comentario_5']:\n",
    "                df_resultado.loc[idx, 'Comentario_5'] += '. Examen no presentado'\n",
    "            else:\n",
    "                df_resultado.loc[idx, 'Comentario_5'] = 'Examen no presentado'\n",
    "        \n",
    "        # Mostrar progreso\n",
    "        status_3_practica = \"✓\" if tiene_practica3 else \"✗\"\n",
    "        status_5_practica = \"✓\" if tiene_practica5 else \"✗\"\n",
    "        status_3_examen = \"📝\" if tiene_examen3 else \"❌\"\n",
    "        status_5_examen = \"📝\" if tiene_examen5 else \"❌\"\n",
    "        \n",
    "        print(f\"{status_3_practica}P3 {status_3_examen}E3 | {status_5_practica}P5 {status_5_examen}E5 | {apellidos}, {nombre} ({grupo_carpeta})\")\n",
    "    \n",
    "    print(\"=\"*50)\n",
    "    print(f\"RESUMEN:\")\n",
    "    print(f\"Total alumnos verificados: {total_alumnos}\")\n",
    "    print(f\"Práctica 3 - Entregadas: {practicas_3_encontradas} | No entregadas: {total_alumnos - practicas_3_encontradas}\")\n",
    "    print(f\"Práctica 5 - Entregadas: {practicas_5_encontradas} | No entregadas: {total_alumnos - practicas_5_encontradas}\")\n",
    "    print(f\"Examen 3 - Presentados: {examenes_3_encontrados} | No presentados: {total_alumnos - examenes_3_encontrados}\")\n",
    "    print(f\"Examen 5 - Presentados: {examenes_5_encontrados} | No presentados: {total_alumnos - examenes_5_encontrados}\")\n",
    "    \n",
    "    return df_resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0b85c259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verificando entregas de prácticas y exámenes...\n",
      "==================================================\n",
      "✗P3 ❌E3 | ✓P5 ❌E5 | AGAPITO DELGADO, SOFIA (IWSIT11)\n",
      "✗P3 ❌E3 | ✓P5 ❌E5 | AGUILAR DESIAR, LLOYD DAREN (IWSIM12)\n",
      "✗P3 ❌E3 | ✓P5 📝E5 | AGUIRRE HERVIAS, JAVIER (IWSIM12)\n",
      "✗P3 ❌E3 | ✓P5 ❌E5 | ALBRIZIO, MATEO (IWSIM12)\n",
      "✗P3 ❌E3 | ✗P5 ❌E5 | ALONSO FERNANDEZ, NICOLAS (IWSIM12)\n",
      "✗P3 📝E3 | ✓P5 ❌E5 | ALVAREZ AREVALO, MIGUEL (IWSIM12)\n",
      "✗P3 ❌E3 | ✓P5 ❌E5 | APUNTE SIERRA, AARON ALEJANDRO (IWSIM12)\n",
      "✗P3 ❌E3 | ✗P5 ❌E5 | ARTACHO BORDINO, JORGE (IWSIM12)\n",
      "✗P3 ❌E3 | ✓P5 📝E5 | AUSIN MORENO, MARCOS (IWSIM12)\n",
      "✗P3 ❌E3 | ✓P5 📝E5 | AYALA MAYA, JULIO (IWSIM12)\n",
      "✗P3 ❌E3 | ✓P5 ❌E5 | AYDIN CONDE, ALP ASLAN (IWSIT12)\n",
      "✓P3 ❌E3 | ✓P5 ❌E5 | BABYN BABYN, DAVID (IWSIT11)\n",
      "✗P3 ❌E3 | ✓P5 ❌E5 | BALLESTEROS LESMES, JAVIER (IWSIT11)\n",
      "✓P3 ❌E3 | ✓P5 ❌E5 | BARRERA VELASQUEZ, ESAU EZEQUIEL (IWSIM11)\n",
      "✓P3 📝E3 | ✓P5 📝E5 | BEAUTELL NAVARRO, HUGO (IWSIM11)\n",
      "✗P3 ❌E3 | ✗P5 ❌E5 | BELTRAN PRADOS, CARLOS (IWSIT11)\n",
      "✓P3 ❌E3 | ✗P5 ❌E5 | BENJELLOUN, GHITA (IWSIT12)\n",
      "✗P3 ❌E3 | ✓P5 📝E5 | BLANCO MARCHAL, SIMON (IWSIM11)\n",
      "✗P3 ❌E3 | ✓P5 ❌E5 | BLANCO VAZQUEZ, XABIER (IWSIT11)\n",
      "✓P3 ❌E3 | ✓P5 ❌E5 | BLASCO RIVAS, SERGIO (IWSIT11)\n",
      "✗P3 ❌E3 | ✓P5 📝E5 | BRAVO CUEVA, ALVARO (IWSIM11)\n",
      "✗P3 ❌E3 | ✓P5 ❌E5 | BUENO MORENO, ISMAEL (IWSIT11)\n",
      "✗P3 ❌E3 | ✓P5 ❌E5 | CABRAS BLASCO, DANIEL (IWSIT12)\n",
      "✗P3 ❌E3 | ✓P5 ❌E5 | CAMARA VILKOVA, VERONICA LUISA (IWSIM11)\n",
      "✓P3 ❌E3 | ✓P5 ❌E5 | CARO ANCOCHEA, RAFAEL (IWSIT11)\n",
      "✓P3 📝E3 | ✓P5 📝E5 | CARRASCO PARDO, SERGIO (IWSIM11)\n",
      "✗P3 ❌E3 | ✗P5 ❌E5 | CARRETERO TERRONES, GUILLERMO (IWSIT11)\n",
      "✗P3 ❌E3 | ✗P5 ❌E5 | CASANOVA MATEO, CARLOS (Profesores)\n",
      "✗P3 ❌E3 | ✓P5 ❌E5 | CEREZO LLEDO, ALVARO (IWSIT11)\n",
      "✗P3 ❌E3 | ✓P5 ❌E5 | CEREZO RODRIGUEZ, JERONIMO (IWSIT11)\n",
      "✗P3 ❌E3 | ✓P5 ❌E5 | CHEN, HAOYU (IWSIT11)\n",
      "✗P3 ❌E3 | ✓P5 ❌E5 | CHEN, NUO (IWSIT11)\n",
      "✗P3 ❌E3 | ✗P5 ❌E5 | CHEN, WENJUN (nan)\n",
      "✗P3 ❌E3 | ✓P5 ❌E5 | CIUCA, DENNIS ANDREI (IWSIT11)\n",
      "✓P3 ❌E3 | ✓P5 ❌E5 | COLINAS GARCIA, DIEGO (IWSIT11)\n",
      "✗P3 ❌E3 | ✓P5 ❌E5 | CONDE IZQUIERDO, SANTIAGO (IWSIT11)\n",
      "✗P3 ❌E3 | ✗P5 ❌E5 | CONEJERO NOVELO-CASANOVA, ALONSO (IWSIT12)\n",
      "✗P3 ❌E3 | ✗P5 ❌E5 | CORUT, NICOLAS ROBERT (IWSIT11)\n",
      "✗P3 ❌E3 | ✓P5 ❌E5 | CRESPO LAFUENTE, JUAN (IWSIT11)\n",
      "✗P3 ❌E3 | ✓P5 ❌E5 | CRUZ REAL, SEBASTIAN (IWSIT11)\n",
      "✗P3 ❌E3 | ✓P5 ❌E5 | DE ANTONIO BARON, SAUL (IWSIT11)\n",
      "✗P3 ❌E3 | ✓P5 ❌E5 | DE LA VEGA RODRIGUEZ, IGNACIO (IWSIT11)\n",
      "✗P3 ❌E3 | ✓P5 📝E5 | DE LOS MOZOS DE LA CRUZ, DIEGO (IWSIM12)\n",
      "✗P3 ❌E3 | ✗P5 ❌E5 | DE VICENTE SALAZAR, FERNANDO (IWSIT11)\n",
      "✗P3 ❌E3 | ✗P5 ❌E5 | DEL CAZ SANZ, DIEGO (IWSIT11)\n",
      "✗P3 ❌E3 | ✓P5 ❌E5 | DELGADO GONZALEZ, VICTOR (IWSIT11)\n",
      "✗P3 ❌E3 | ✗P5 ❌E5 | DIAZ MARTINEZ, MIGUEL ANGEL (Profesores)\n",
      "✓P3 ❌E3 | ✓P5 ❌E5 | DIAZ PEÑA, JORGE (IWSIT12)\n",
      "✗P3 ❌E3 | ✓P5 ❌E5 | DIAZ SANTIAGO, JOEL (IWSIT11)\n",
      "✓P3 ❌E3 | ✓P5 ❌E5 | DIAZ SERRANO, MARIA JOSE (IWSIT11)\n",
      "✗P3 ❌E3 | ✓P5 📝E5 | DOMINGUEZ ALVAREZ, JAVIER (IWSIM12)\n",
      "✗P3 ❌E3 | ✓P5 ❌E5 | DONG, JINGHONG (IWSIT11)\n",
      "✗P3 ❌E3 | ✓P5 ❌E5 | DRAGAN, ELISA ELENA (IWSIT11)\n",
      "✗P3 ❌E3 | ✗P5 ❌E5 | ELESPE CHELI, TOMAS (IWSIT11)\n",
      "✗P3 ❌E3 | ✗P5 ❌E5 | ELICES HERNANDEZ, MARTA (IWSIT11)\n",
      "✗P3 ❌E3 | ✓P5 ❌E5 | ELMJABBAD ESPINEL, OMAR (IWSIT11)\n",
      "✗P3 ❌E3 | ✓P5 ❌E5 | ELVIRA PEREZ, SAMUEL (IWSIT12)\n",
      "✗P3 ❌E3 | ✓P5 ❌E5 | EMILOV RADKOV, DANIEL (IWSIT11)\n",
      "✗P3 ❌E3 | ✓P5 ❌E5 | ESPADA GARCIA, MARCO ANIBAL (IWSIT11)\n",
      "✗P3 ❌E3 | ✓P5 ❌E5 | ESTRADA SARANGO, EDUARDO (IWSIT11)\n",
      "✗P3 ❌E3 | ✗P5 ❌E5 | EVALUADOR EXTERNO, DOCENTIA (nan)\n",
      "✗P3 ❌E3 | ✓P5 ❌E5 | FERNANDES SIMOES, ANDRES EDUARDO (IWSIT11)\n",
      "✗P3 ❌E3 | ✓P5 ❌E5 | FERNANDEZ CARRASCO, LAURA (IWSIT11)\n",
      "✗P3 ❌E3 | ✓P5 ❌E5 | FERNANDEZ DE LUZ RODRIGUEZ, JULIO (IWSIT11)\n",
      "✗P3 📝E3 | ✓P5 ❌E5 | FERNANDEZ HERRERO, DIEGO (IWSIM12)\n",
      "✗P3 ❌E3 | ✓P5 ❌E5 | FIDALGO TAPIA, FROILAN (IWSIT11)\n",
      "✗P3 ❌E3 | ✓P5 ❌E5 | FRANCESCH COLOMER, DANIEL (IWSIT11)\n",
      "✗P3 ❌E3 | ✗P5 ❌E5 | FRUTOS VELASCO, JUAN ALBERTO DE (nan)\n",
      "✓P3 ❌E3 | ✓P5 ❌E5 | FUENTE MARTINEZ, HERNAN GABRIEL DE LA (IWSIM12)\n",
      "✗P3 ❌E3 | ✗P5 ❌E5 | FUERIS FRUTOS, MANUEL (IWSIT12)\n",
      "✗P3 ❌E3 | ✓P5 ❌E5 | GALLEGO GARCIA, ALEJANDRO (IWSIT11)\n",
      "✗P3 ❌E3 | ✗P5 ❌E5 | GARCIA ALVAREZ, NEMESIO (IWSIT12)\n",
      "✗P3 ❌E3 | ✓P5 ❌E5 | GARCIA AZCARRETA, MIGUEL (IWSIT11)\n",
      "✗P3 ❌E3 | ✓P5 ❌E5 | GARCIA GARCIA, VICTOR (IWSIT12)\n",
      "✗P3 ❌E3 | ✓P5 ❌E5 | GARCIA GARCIA-NAVAS, ALESSANDRO (IWSIT11)\n",
      "✗P3 ❌E3 | ✓P5 ❌E5 | GARCIA HERNANDEZ, ALEJANDRO (IWSIT11)\n",
      "✗P3 📝E3 | ✓P5 📝E5 | GARCIA LEON, HUGO (IWSIM11)\n",
      "✗P3 ❌E3 | ✗P5 ❌E5 | GARCIA MARTINEZ, DANIEL (IWSIT12)\n",
      "✗P3 ❌E3 | ✗P5 ❌E5 | GARCIA SIMARRRO, JAVIER (IWSIT11)\n",
      "✗P3 ❌E3 | ✓P5 ❌E5 | GARCIA SOTO, ADRIAN (IWSIT11)\n",
      "✓P3 ❌E3 | ✗P5 ❌E5 | GARCIA VIDAL, ANTON (IWSIT11)\n",
      "✗P3 ❌E3 | ✗P5 ❌E5 | GARCIA-MINGUILLAN FERNANDEZ, DAVID (IWSIT11)\n",
      "✗P3 ❌E3 | ✗P5 ❌E5 | GHEORGHITA CARAPET, LUCAS (IWSIT11)\n",
      "✗P3 ❌E3 | ✓P5 ❌E5 | GIL ESTEBAN, DAVID (IWSIT11)\n",
      "✗P3 📝E3 | ✓P5 ❌E5 | GONZALEZ BENITO, ANDRES (IWSIM12)\n",
      "✗P3 ❌E3 | ✓P5 ❌E5 | GONZALEZ RAMON, ANDRES (IWSIT11)\n",
      "✗P3 ❌E3 | ✓P5 ❌E5 | GUEVARA BERRUGA, JAIME (IWSIT11)\n",
      "✗P3 ❌E3 | ✓P5 ❌E5 | GUINEA RODRIGUEZ LOSADA, SANTIAGO (IWSIT11)\n",
      "✗P3 ❌E3 | ✗P5 ❌E5 | HARVEY MARTIN, DAVID (IWSIM11)\n",
      "✓P3 ❌E3 | ✓P5 📝E5 | HEINRICKS GONZALEZ, BRANDON (IWSIM11)\n",
      "✗P3 ❌E3 | ✗P5 ❌E5 | HERNANDEZ DORADO, ANA (IWSIM11)\n",
      "✗P3 ❌E3 | ✓P5 ❌E5 | HERNANDEZ GARNACHO, JOSE ANGEL (IWSIM11)\n",
      "✗P3 ❌E3 | ✓P5 📝E5 | HERNANDEZ MONTERO, LUCIA (IWSIM11)\n",
      "✗P3 ❌E3 | ✗P5 ❌E5 | HERRAN CEREZO, FRANCISCO (IWSIT11)\n",
      "✗P3 ❌E3 | ✓P5 ❌E5 | HERRERA GALERA, PEDRO ALEJANDRO (IWSIM11)\n",
      "✗P3 ❌E3 | ✓P5 📝E5 | HIDALGO PARIENTE, MARCO (IWSIM11)\n",
      "✗P3 ❌E3 | ✗P5 ❌E5 | HUANG, JING (IWSIM12)\n",
      "✗P3 ❌E3 | ✓P5 ❌E5 | HUERTAS DIAZ, ALVARO (IWSIT11)\n",
      "✗P3 ❌E3 | ✓P5 ❌E5 | IANCU IANCU, GEORGIAN SORIN (IWSIM11)\n",
      "✓P3 ❌E3 | ✓P5 ❌E5 | IGLESIAS ALCAZAR, CARLOS (IWSIT12)\n",
      "✗P3 ❌E3 | ✓P5 📝E5 | ILIYANOVA ATANASOVA, ALICIA (IWSIM12)\n",
      "✗P3 ❌E3 | ✗P5 ❌E5 | IÑIGO LAHERA, MATEO (IWSIM11)\n",
      "✗P3 ❌E3 | ✓P5 ❌E5 | IONESCU SOARE, ALEJANDRO RAFAEL (IWSIM11)\n",
      "✓P3 ❌E3 | ✓P5 📝E5 | IVASIV KOSYK, MAXYM (IWSIM11)\n",
      "✗P3 ❌E3 | ✗P5 ❌E5 | JIANG ZHU, QIN HAO (IWSIT11)\n",
      "✗P3 ❌E3 | ✓P5 📝E5 | JIMENEZ GARCIA, ANGELA (IWSIM12)\n",
      "✗P3 ❌E3 | ✓P5 📝E5 | JIMENEZ JIMENEZ, ANDREA (IWSIM12)\n",
      "✗P3 ❌E3 | ✓P5 ❌E5 | JIMENEZ JIMENEZ, DIEGO (IWSIT12)\n",
      "✗P3 ❌E3 | ✓P5 📝E5 | JIMENEZ RAMOS, DANIEL (IWSIM11)\n",
      "✗P3 ❌E3 | ✓P5 📝E5 | JUAREZ GELARDO, TOMAS (IWSIM11)\n",
      "✗P3 ❌E3 | ✓P5 ❌E5 | JUSUE ZAVALA, JOSE RAMON (IWSIM11)\n",
      "✗P3 ❌E3 | ✓P5 📝E5 | KE, TAILI (IWSIM11)\n",
      "✗P3 ❌E3 | ✗P5 ❌E5 | LABRADA MEDINA, JAVIER (IWSIM11)\n",
      "✗P3 ❌E3 | ✓P5 📝E5 | LAFUENTE SANZ, ALICIA (IWSIM11)\n",
      "✗P3 ❌E3 | ✓P5 ❌E5 | LEFTERACHE RAILEANU, NICOLAS ANDRES (IWSIM11)\n",
      "✗P3 ❌E3 | ✓P5 📝E5 | LENCERO CARRILLO, OSCAR (IWSIM11)\n",
      "✗P3 ❌E3 | ✓P5 📝E5 | LI, JILING (IWSIM11)\n",
      "✓P3 ❌E3 | ✗P5 ❌E5 | LIN, CRISTIAN (IWSIT12)\n",
      "✗P3 ❌E3 | ✗P5 ❌E5 | LIN, YUSHAN (IWSIT12)\n",
      "✗P3 ❌E3 | ✓P5 📝E5 | LLORENTE VAQUERO, CARLOS (IWSIM11)\n",
      "✗P3 ❌E3 | ✓P5 📝E5 | LOPEZ COLMENERO, ROSALIA (IWSIM11)\n",
      "✗P3 ❌E3 | ✓P5 📝E5 | LOPEZ DE LA MANZANARA GARCIA, PABLO (IWSIM11)\n",
      "✗P3 ❌E3 | ✓P5 ❌E5 | LOPEZ HERNANDEZ, ANDRES (IWSIM11)\n",
      "✗P3 ❌E3 | ✗P5 ❌E5 | LOPEZ SOSA, JORGE (IWSIT11)\n",
      "✗P3 ❌E3 | ✓P5 ❌E5 | LORENZO MORO, ADRIAN (IWSIM11)\n",
      "✗P3 ❌E3 | ✓P5 📝E5 | LOZANO MARCOS, MARTA (IWSIM11)\n",
      "✗P3 ❌E3 | ✗P5 ❌E5 | LU DONG, LUIS (IWSIM11)\n",
      "✗P3 📝E3 | ✓P5 📝E5 | MA, ANNI (IWSIM11)\n",
      "✗P3 ❌E3 | ✗P5 ❌E5 | MADRIDEJOS CHAMORRO, TELLO (IWSIT12)\n",
      "✗P3 ❌E3 | ✓P5 📝E5 | MAHER FAIQ AL RAWE, MAHMOOD (IWSIM11)\n",
      "✓P3 ❌E3 | ✓P5 ❌E5 | MANZANARO CARABALLO, PABLO (IWSIT11)\n",
      "✗P3 ❌E3 | ✓P5 📝E5 | MARINA NAVARRO, PAULA (IWSIM11)\n",
      "✗P3 ❌E3 | ✓P5 📝E5 | MARQUEZ SANTAMARIA, ALVARO (IWSIM11)\n",
      "✗P3 📝E3 | ✓P5 📝E5 | MARTIN BALLESTER, DANIEL (IWSIM11)\n",
      "✗P3 ❌E3 | ✓P5 📝E5 | MARTIN ESPAÑA, ANTONIO (IWSIM11)\n",
      "✗P3 ❌E3 | ✓P5 📝E5 | MARTIN MARTIN, JORGE (IWSIM11)\n",
      "✓P3 📝E3 | ✓P5 📝E5 | MARTIN VERDUGO, CRISTINA (IWSIM11)\n",
      "✗P3 📝E3 | ✓P5 📝E5 | MARTINEZ, PAULA (IWSIM11)\n",
      "✗P3 ❌E3 | ✗P5 ❌E5 | MARTINEZ GARCIA, PILAR (Profesores)\n",
      "✗P3 ❌E3 | ✓P5 📝E5 | MARTINEZ LOPEZ TERCERO, JESUS (IWSIM11)\n",
      "✓P3 📝E3 | ✓P5 📝E5 | MARTINEZ SEBASTIA, NACHO (IWSIM11)\n",
      "✓P3 ❌E3 | ✓P5 ❌E5 | MATEOS ABAD, HUGO (IWSIT12)\n",
      "✗P3 ❌E3 | ✓P5 ❌E5 | MATHEUS GONCALVEZ, DANIEL ALEJANDRO (IWSIM11)\n",
      "✓P3 ❌E3 | ✓P5 ❌E5 | MEDRANO MORATA, IGNACIO (IWSIT11)\n",
      "✗P3 ❌E3 | ✓P5 📝E5 | MENOYO PEREZ, ALVARO (IWSIM11)\n",
      "✗P3 ❌E3 | ✓P5 📝E5 | MERINO FERNANDEZ, SOFIA (IWSIM11)\n",
      "✗P3 ❌E3 | ✓P5 ❌E5 | MOLERO GONZALEZ, SIMON (IWSIM11)\n",
      "✓P3 📝E3 | ✓P5 📝E5 | MONEDERO ANGULO, JAVIER (IWSIM11)\n",
      "✗P3 ❌E3 | ✓P5 📝E5 | MONTARELO PADILLA, ALBERTO (IWSIM11)\n",
      "✗P3 ❌E3 | ✗P5 ❌E5 | MONTES BORJABAD, CLAUDIA (IWSIM11)\n",
      "✗P3 ❌E3 | ✗P5 ❌E5 | MORAIS MANRIQUE, SWAMY (IWSIT11)\n",
      "✗P3 ❌E3 | ✓P5 📝E5 | MORALEDA SALGUERO, DAVID (IWSIM11)\n",
      "✗P3 ❌E3 | ✓P5 📝E5 | MORALES DE LUIS, HECTOR (IWSIM11)\n",
      "✗P3 ❌E3 | ✗P5 ❌E5 | MORANT FERRANDO, OSCAR (IWSIM11)\n",
      "✗P3 ❌E3 | ✗P5 ❌E5 | MOREJON CANCHO, ALEJANDRO (IWSIM11)\n",
      "✗P3 ❌E3 | ✓P5 📝E5 | MORENO VIRUETE, IGNACIO (IWSIM11)\n",
      "✗P3 ❌E3 | ✓P5 📝E5 | MORENO-PALANCAS CEBALLOS, LUCAS (IWSIM11)\n",
      "✗P3 ❌E3 | ✓P5 ❌E5 | MOYA BLANCO, JESUS FRANCISCO (IWSIM11)\n",
      "✗P3 ❌E3 | ✓P5 📝E5 | MOYA RIVERA, PABLO (IWSIM11)\n",
      "✗P3 ❌E3 | ✗P5 ❌E5 | MOYONERO ESPINOZA, VALENTINA NICOLLE (IWSIT11)\n",
      "✗P3 ❌E3 | ✗P5 ❌E5 | MOZO DE RIVAS, SARA (IWSIM11)\n",
      "✗P3 ❌E3 | ✗P5 ❌E5 | MUCIENTES CABALLO, ALBERTO (nan)\n",
      "✗P3 ❌E3 | ✓P5 ❌E5 | MUÑOZ FERNANDEZ, MIGUEL ANGEL (IWSIM11)\n",
      "✗P3 ❌E3 | ✓P5 📝E5 | NARANJO MUÑOZ, ISMAEL (IWSIM11)\n",
      "✗P3 ❌E3 | ✓P5 📝E5 | NAUTIYAL BHATT, NINAD (IWSIM11)\n",
      "✗P3 ❌E3 | ✓P5 📝E5 | NAVARRETE HURTADO, IMANOL (IWSIM11)\n",
      "✗P3 ❌E3 | ✓P5 ❌E5 | NEIRA HERNANDEZ, HECTOR (IWSIT11)\n",
      "✗P3 ❌E3 | ✓P5 ❌E5 | NGOMO NCHAMA, ANTONIO ELA (IWSIM11)\n",
      "✓P3 ❌E3 | ✓P5 ❌E5 | OCAÑA MARTIN, MIGUEL (IWSIT12)\n",
      "✗P3 ❌E3 | ✗P5 ❌E5 | OCHOA GOMEZ, LUIS EMIRO (IWSIM11)\n",
      "✗P3 ❌E3 | ✗P5 ❌E5 | OFICIALDEGUI GONZALEZ-UBEDA, NICOLAS (IWSIM12)\n",
      "✗P3 ❌E3 | ✓P5 📝E5 | ORTIZ PASAMONTES, MARCOS (IWSIM12)\n",
      "✓P3 📝E3 | ✓P5 ❌E5 | OTERO MORENO, EKAITZ (IWSIM12)\n",
      "✗P3 ❌E3 | ✓P5 📝E5 | PANTOJA FIGUEROA, ALEJANDRO (IWSIM12)\n",
      "✗P3 ❌E3 | ✓P5 ❌E5 | PARIS FERNANDEZ, JORGE (IWSIM12)\n",
      "✗P3 ❌E3 | ✗P5 ❌E5 | PASTOR GALINDO, JAVIER (Profesores)\n",
      "✗P3 ❌E3 | ✓P5 ❌E5 | PERALTA BARLE, LUCILA (IWSIM12)\n",
      "✗P3 ❌E3 | ✗P5 ❌E5 | PEREZ DIAZ, RODRIGO (IWSIT12)\n",
      "✗P3 ❌E3 | ✓P5 ❌E5 | PEREZ DIMAS, IZAN (IWSIM12)\n",
      "✗P3 ❌E3 | ✗P5 ❌E5 | PEREZ GONZALEZ, AGUEDA (IWSIM11)\n",
      "✗P3 ❌E3 | ✓P5 📝E5 | PIÑA RODRIGUEZ, RODRIGO (IWSIM12)\n",
      "✓P3 📝E3 | ✗P5 ❌E5 | PINILLOS ARELLANO, SERGIO (IWSIM11)\n",
      "✗P3 ❌E3 | ✓P5 📝E5 | POENARU, TIMOTEI LUCIAN (IWSIM12)\n",
      "✗P3 ❌E3 | ✓P5 📝E5 | PRIETO ALVAREZ, MARIA (IWSIM12)\n",
      "✓P3 📝E3 | ✗P5 ❌E5 | QUISBERT CHOQUETICLLA, LEONEL (IWSIM12)\n",
      "✗P3 ❌E3 | ✓P5 ❌E5 | RAZZAK AKTER, TARIQUL ISLAM (IWSIM12)\n",
      "✓P3 ❌E3 | ✗P5 ❌E5 | REDONDO GUDE, JUAN JOSE (IWSIM12)\n",
      "✗P3 ❌E3 | ✗P5 ❌E5 | RIPOLL CARMONA, MARCO (IWSIT12)\n",
      "✗P3 ❌E3 | ✓P5 ❌E5 | ROBLES MARTIN, ALEJANDRO (IWSIM12)\n",
      "✗P3 ❌E3 | ✓P5 📝E5 | ROCHA BENATTI, ENRIQUE (IWSIM12)\n",
      "✗P3 ❌E3 | ✓P5 ❌E5 | RODA ALVAREZ, FERNANDO (IWSIT12)\n",
      "✗P3 ❌E3 | ✓P5 📝E5 | RODRIGUEZ BARRIO, SANTIAGO (IWSIM12)\n",
      "✗P3 ❌E3 | ✗P5 ❌E5 | RODRIGUEZ FERNANDEZ, VICTOR (Profesores)\n",
      "✗P3 ❌E3 | ✓P5 ❌E5 | RODRIGUEZ LOPEZ, DANIEL (IWSIM12)\n",
      "✗P3 ❌E3 | ✓P5 📝E5 | RODRIGUEZ MARTIN, DAVID (IWSIM12)\n",
      "✗P3 ❌E3 | ✓P5 📝E5 | RODRIGUEZ ROMAN, DIEGO (IWSIM12)\n",
      "✓P3 📝E3 | ✓P5 📝E5 | RODRIGUEZ SANCHEZ, VICTOR (IWSIM11)\n",
      "✓P3 📝E3 | ✓P5 📝E5 | ROJAS ILLESCAS, GABRIEL (IWSIM12)\n",
      "✗P3 ❌E3 | ✗P5 ❌E5 | ROMAN ROSALES, JORGE ANDRES (IWSIM12)\n",
      "✓P3 📝E3 | ✓P5 📝E5 | ROMEO PEREZ, ALEJANDRO (IWSIM11)\n",
      "✗P3 ❌E3 | ✗P5 ❌E5 | ROZADILLAS VIDAL, JULIAN (IWSIT12)\n",
      "✗P3 ❌E3 | ✓P5 📝E5 | RUIZ PEREZ, CLAUDIA (IWSIM12)\n",
      "✓P3 ❌E3 | ✓P5 ❌E5 | RUSSO PEREZ, ALEJANDRO ISAAC (IWSIM12)\n",
      "✗P3 ❌E3 | ✓P5 📝E5 | SAIZ MOLINA, DAVID (IWSIM12)\n",
      "✓P3 📝E3 | ✓P5 📝E5 | SAN JUAN FERNANDEZ, MARIO (IWSIM12)\n",
      "✗P3 ❌E3 | ✓P5 ❌E5 | SANCHEZ ALCAZAR, RAUL (IWSIT12)\n",
      "✗P3 ❌E3 | ✓P5 📝E5 | SANCHEZ DEL CAMPO, HUGO (IWSIM12)\n",
      "✗P3 ❌E3 | ✗P5 ❌E5 | SANCHEZ DONAIRE, MARCOS (IWSIT12)\n",
      "✗P3 ❌E3 | ✓P5 ❌E5 | SANCHEZ HERRERA, ALEJANDRO (IWSIT12)\n",
      "✓P3 ❌E3 | ✓P5 ❌E5 | SANCHEZ LOSA, CARLOS (IWSIT12)\n",
      "✗P3 ❌E3 | ✗P5 ❌E5 | SANCHEZ MARTIN, MARCO (IWSIT12)\n",
      "✗P3 📝E3 | ✓P5 📝E5 | SANCHEZ NUÑO, JORGE (IWSIM12)\n",
      "✓P3 📝E3 | ✓P5 📝E5 | SANCHEZ PINA, JORGE (IWSIM12)\n",
      "✗P3 📝E3 | ✗P5 📝E5 | SANCHEZ RODRIGUEZ, ALVARO (IWSIM12)\n",
      "✗P3 ❌E3 | ✓P5 📝E5 | SANCHEZ TAPIADOR, PABLO (IWSIM12)\n",
      "✗P3 ❌E3 | ✗P5 ❌E5 | SANTAMARIA VALENZUELA, MARIA INMACULADA (Profesores)\n",
      "✓P3 📝E3 | ✓P5 📝E5 | SANZ AVILA, DANIEL (IWSIM12)\n",
      "✗P3 ❌E3 | ✓P5 ❌E5 | SEBASTIANI DAMAS, SANTIAGO DANIEL (IWSIM12)\n",
      "✓P3 ❌E3 | ✗P5 ❌E5 | SHU, LIN (IWSIT12)\n",
      "✗P3 ❌E3 | ✓P5 📝E5 | SICILIA BALAS, DANIELA (IWSIM11)\n",
      "✗P3 ❌E3 | ✗P5 📝E5 | SILVA CASTRO, JUAN (IWSIM12)\n",
      "✗P3 ❌E3 | ✓P5 📝E5 | SORET EL HARTI, SARAH (IWSIM12)\n",
      "✗P3 ❌E3 | ✓P5 ❌E5 | SOUTO RUSSO, ALINA SUSANA (IWSIT12)\n",
      "✗P3 ❌E3 | ✓P5 📝E5 | STRAUS PEÑAFIEL, ALVARO (IWSIM12)\n",
      "✗P3 ❌E3 | ✓P5 ❌E5 | TAIPE TICSE, LUIS IÑAKI (IWSIM12)\n",
      "✗P3 ❌E3 | ✓P5 📝E5 | TAMAKI MORENO, ALVARO (IWSIM12)\n",
      "✗P3 ❌E3 | ✓P5 ❌E5 | TITUAÑA SOTALIN, BRANDON ALEXIS (IWSIM12)\n",
      "✗P3 ❌E3 | ✗P5 ❌E5 | TRANA, VALENTIN VASILE (IWSIT12)\n",
      "✗P3 ❌E3 | ✓P5 ❌E5 | VALLEJO NYS, JOSE LUIS (IWSIM12)\n",
      "✗P3 ❌E3 | ✓P5 📝E5 | VAQUEIRO JIMENEZ, DAVID (IWSIM12)\n",
      "✗P3 ❌E3 | ✓P5 ❌E5 | VELARDE ROMERO, ALVARO (IWSIT12)\n",
      "✓P3 ❌E3 | ✓P5 ❌E5 | VELISLAVOVA TSEKOVA, CRISTIANA (IWSIT12)\n",
      "✗P3 ❌E3 | ✓P5 📝E5 | VERDIN DOMINGUEZ, LARA (IWSIM12)\n",
      "✗P3 ❌E3 | ✓P5 📝E5 | VICENTE MIGUEL, CELIA (IWSIM12)\n",
      "✗P3 ❌E3 | ✓P5 📝E5 | VILLA MARTIN, PABLO (IWSIM12)\n",
      "✗P3 ❌E3 | ✓P5 📝E5 | VINDEL DOMINGUEZ, JORGE (IWSIM12)\n",
      "✗P3 ❌E3 | ✓P5 📝E5 | YANG, JINXIAN (IWSIM12)\n",
      "✗P3 📝E3 | ✓P5 ❌E5 | YE, JUNQIN (IWSIM12)\n",
      "✓P3 📝E3 | ✓P5 ❌E5 | ZHENG, YIFEI (IWSIM12)\n",
      "✗P3 ❌E3 | ✓P5 📝E5 | ZHOU, YUHANG (IWSIM12)\n",
      "✗P3 ❌E3 | ✗P5 ❌E5 | ZHOU ZHENG, JIA CHENG (IWSIT12)\n",
      "✓P3 📝E3 | ✓P5 📝E5 | ZHU, XIANG LE (IWSIM12)\n",
      "✗P3 ❌E3 | ✓P5 📝E5 | ZODER MENDEZ, ANA (IWSIM12)\n",
      "✗P3 ❌E3 | ✓P5 ❌E5 | ZODER MENDEZ, PABLO JOACHIM (IWSIM12)\n",
      "✗P3 ❌E3 | ✓P5 📝E5 | AGUIRRIZABAL MARTINEZ, HUGO (CITIM11)\n",
      "✗P3 ❌E3 | ✓P5 ❌E5 | ALHEJA BERMEJO, ALEJANDRO (CITIT11)\n",
      "✗P3 ❌E3 | ✗P5 ❌E5 | ALONSO RUIZ, JAIME (CITIM12)\n",
      "✓P3 ❌E3 | ✓P5 ❌E5 | ALVAREZ CABRERA, LUIS (CITIT11)\n",
      "✗P3 ❌E3 | ✗P5 ❌E5 | ANCAJIMA QUISPE, FABIOLA (CITIM12)\n",
      "✓P3 📝E3 | ✓P5 📝E5 | ARIAS CASADO, ALBA (CITIM11)\n",
      "✗P3 ❌E3 | ✗P5 ❌E5 | ARRANZ CAMPINS, SERGIO (CITIT11)\n",
      "✗P3 ❌E3 | ✗P5 ❌E5 | BALBOA MORILLO, MARCO (CITIT11)\n",
      "✗P3 ❌E3 | ✗P5 ❌E5 | BARBERO BARRERO, MIGUEL (CITIT11)\n",
      "✓P3 ❌E3 | ✓P5 ❌E5 | BASSO MARTINEZ, CHRISTIAN (CITIM11)\n",
      "✗P3 ❌E3 | ✗P5 ❌E5 | BERNARDINO TEBA, DANIEL (CITIT11)\n",
      "✗P3 ❌E3 | ✓P5 ❌E5 | BERRAL MARTIN, GONZALO (CITIT11)\n",
      "✗P3 ❌E3 | ✗P5 ❌E5 | BERTOLISSI, LUCIA ESTHER (CITIM11)\n",
      "✗P3 ❌E3 | ✗P5 ❌E5 | BOATELLA BENITEZ-DONOSO, MARIA (CITIT11)\n",
      "✗P3 ❌E3 | ✗P5 ❌E5 | BRANDO PARRA, LUIS CARLOS (CITIT11)\n",
      "✗P3 ❌E3 | ✓P5 ❌E5 | CABELLO MARTIN, BRUNO (CITIT11)\n",
      "✗P3 ❌E3 | ✓P5 ❌E5 | CAI, ZESHENG (CITIT11)\n",
      "✗P3 ❌E3 | ✓P5 ❌E5 | CALERO CORRAL, CARLOS (CITIT11)\n",
      "✓P3 📝E3 | ✓P5 📝E5 | CARMONA OCAÑA, DANIEL (CITIM11)\n",
      "✗P3 ❌E3 | ✗P5 ❌E5 | CARRERAS GONZALEZ, LIDIA (CITIT11)\n",
      "✗P3 ❌E3 | ✓P5 ❌E5 | CASADO MORCUENDE, PABLO (CITIT11)\n",
      "✗P3 ❌E3 | ✗P5 ❌E5 | CHAMOSO DE URBIZU, JAVIER (CITIT11)\n",
      "✓P3 ❌E3 | ✓P5 ❌E5 | CHAVARRIA PALOMO, DAVID (CITIT11)\n",
      "✗P3 ❌E3 | ✓P5 📝E5 | CHIFOR, NICOLAS MARIUS (CITIM12)\n",
      "✗P3 ❌E3 | ✗P5 ❌E5 | CONCHA LOPEZ, MATTEO (CITIT11)\n",
      "✗P3 ❌E3 | ✓P5 📝E5 | CRAUS SANTA CATALINA, NICOLAS (CITIM11)\n",
      "✗P3 ❌E3 | ✓P5 ❌E5 | CRIALES CARRANZA, LUIS MATHIAS (CITIT11)\n",
      "✗P3 ❌E3 | ✓P5 ❌E5 | CUTOLO SPADARO, ROSANGELA MARIA (CITIM11)\n",
      "✓P3 ❌E3 | ✓P5 ❌E5 | DE LA IGLESIA NUÑEZ, PEDRO JOSE (CITIM11)\n",
      "✗P3 ❌E3 | ✗P5 ❌E5 | DE LOMBAS LOPEZ, JAVIER (CITIT11)\n",
      "✗P3 ❌E3 | ✓P5 📝E5 | DEL CAMPO GONZALEZ, ALVARO (CITIM11)\n",
      "✗P3 ❌E3 | ✓P5 ❌E5 | DEL POZUELO ESCALONA, PABLO (CITIM11)\n",
      "✗P3 ❌E3 | ✓P5 ❌E5 | DUMITRESCU, ALEXANDRU RAZVAN (CITIT11)\n",
      "✗P3 ❌E3 | ✗P5 ❌E5 | ECIJA SANCHEZ, GONZALO (CITIT11)\n",
      "✗P3 ❌E3 | ✗P5 ❌E5 | EHLE, AMELIE KATHARINA (CITIT11)\n",
      "✗P3 ❌E3 | ✓P5 ❌E5 | ESCUDERO MATEOS, JAVIER (CITIT11)\n",
      "✗P3 ❌E3 | ✓P5 ❌E5 | ESPINOZA ALONSO, JUAN VIDAL (CITIT11)\n",
      "✗P3 ❌E3 | ✓P5 ❌E5 | ESTEPA ROBLES, ANDREA (CITIT11)\n",
      "✗P3 ❌E3 | ✗P5 ❌E5 | ESTEVEZ BOSSO, MARIANELA (CITIT11)\n",
      "✓P3 ❌E3 | ✓P5 ❌E5 | EXPOSITO SONO, HARITZ ENDIKA (CITIM11)\n",
      "✗P3 ❌E3 | ✗P5 ❌E5 | FAN, ZHIYING (CITIT11)\n",
      "✓P3 📝E3 | ✓P5 📝E5 | FERNANDEZ NIETO, DAVID (CITIM11)\n",
      "✗P3 ❌E3 | ✓P5 📝E5 | FERREIRA SOUZA, JHONATAN (CITIM11)\n",
      "✓P3 📝E3 | ✓P5 ❌E5 | FILALI BELHADJ CHAQROUNE, YASSIR (CITIT11)\n",
      "✓P3 ❌E3 | ✓P5 ❌E5 | FORONDA IRAIZOS, PABLO RAMIRO (CITIM11)\n",
      "✗P3 ❌E3 | ✗P5 ❌E5 | FRUTOS VELASCO, JUAN ALBERTO DE (CITIM11, Profesores)\n",
      "✗P3 ❌E3 | ✓P5 📝E5 | GARCIA CARRETERO, SAMUEL (CITIM12)\n",
      "✗P3 ❌E3 | ✗P5 ❌E5 | GARCIA CESPEDES, OSCAR (CITIT11)\n",
      "✓P3 📝E3 | ✓P5 📝E5 | GARCIA FERNANDEZ, LORENZO (CITIM11)\n",
      "✗P3 ❌E3 | ✓P5 📝E5 | GARCIA GARCIA, MARCOS (CITIM11)\n",
      "✓P3 ❌E3 | ✓P5 ❌E5 | GARCIA GUZMAN, ADRIAN (CITIT11)\n",
      "✓P3 ❌E3 | ✓P5 ❌E5 | GARCIA HERNANDEZ, MARCOS (CITIT11)\n",
      "✗P3 ❌E3 | ✗P5 ❌E5 | GARCIA NIETO, FERNANDO (CITIT11)\n",
      "✗P3 ❌E3 | ✗P5 ❌E5 | GARCIA SANCHEZ, PAULA (CITIM11)\n",
      "✗P3 ❌E3 | ✓P5 ❌E5 | GARCIA-PRIETO CASTELLS, MARIA JOSE (CITIT11)\n",
      "✓P3 ❌E3 | ✓P5 ❌E5 | GOMEZ GONZALEZ, LUCAS MATEO (CITIT11)\n",
      "✗P3 ❌E3 | ✓P5 ❌E5 | GOMEZ MORENO, CARLOS (CITIT11)\n",
      "✗P3 ❌E3 | ✓P5 📝E5 | GOMEZ ROBLEDANO, PABLO (CITIM12)\n",
      "✓P3 ❌E3 | ✓P5 ❌E5 | GOMEZ ROMERO, MIGUEL (CITIT11)\n",
      "✗P3 ❌E3 | ✗P5 ❌E5 | GONZALEZ ABUSHAREB, JANO ALI (CITIT11)\n",
      "✓P3 ❌E3 | ✓P5 ❌E5 | GONZALEZ MONTERO, PABLO (CITIT11)\n",
      "✗P3 ❌E3 | ✗P5 ❌E5 | GONZALEZ MORENO, DARIO (CITIT11)\n",
      "✓P3 📝E3 | ✓P5 📝E5 | GONZALEZ RODRIGUEZ, RUBEN (CITIM12)\n",
      "✗P3 ❌E3 | ✓P5 ❌E5 | GONZALEZ SANCHEZ, LUIS (CITIT11)\n",
      "✗P3 ❌E3 | ✓P5 ❌E5 | GUOZHANG, HAOQI (CITIM12)\n",
      "✗P3 ❌E3 | ✓P5 ❌E5 | GUTIERREZ MARTIN, ROBERTO (CITIT11)\n",
      "✗P3 ❌E3 | ✓P5 ❌E5 | HERRERA BAUTISTE, ALVARO (CITIM11)\n",
      "✓P3 ❌E3 | ✓P5 ❌E5 | HERVAS FERNANDEZ, JOSE (CITIT11)\n",
      "✗P3 ❌E3 | ✓P5 📝E5 | HIDALGO POZAS, MIGUEL (CITIM11)\n",
      "✓P3 📝E3 | ✓P5 📝E5 | HUERGA GIL, JAVIER (CITIM11)\n",
      "✗P3 ❌E3 | ✗P5 ❌E5 | JAREK JAREK, WIOLETTA (CITIM11)\n",
      "✗P3 ❌E3 | ✓P5 ❌E5 | JIA LIU, ZHENGPENG (CITIM11)\n",
      "✗P3 ❌E3 | ✓P5 📝E5 | JIMENEZ DIAZ, MARCOS (CITIM11)\n",
      "✗P3 ❌E3 | ✓P5 📝E5 | JIMENEZ SANZ, SERGIO (CITIM12)\n",
      "✓P3 ❌E3 | ✓P5 📝E5 | LAZARO DIAZ, MARCOS (CITIM11)\n",
      "✗P3 ❌E3 | ✗P5 📝E5 | LIN, CUNXI (CITIM11)\n",
      "✓P3 ❌E3 | ✗P5 📝E5 | LIN, JIANTENG (CITIM11)\n",
      "✗P3 ❌E3 | ✓P5 ❌E5 | LINARES CASTILLO, ALVARO (CITIT11)\n",
      "✓P3 📝E3 | ✓P5 📝E5 | LIU, JIAYI (CITIM12)\n",
      "✗P3 ❌E3 | ✗P5 ❌E5 | LIZ LOPEZ, HELENA (CITIT11, Profesores)\n",
      "✗P3 ❌E3 | ✗P5 ❌E5 | LOPEZ ELBAL, HECTOR (CITIM12)\n",
      "✗P3 ❌E3 | ✓P5 📝E5 | LOPEZ GARCIA, ANDRES (CITIM11)\n",
      "✗P3 ❌E3 | ✗P5 ❌E5 | LOPEZ PEREZ, IGNACIO (CITIM11)\n",
      "✗P3 ❌E3 | ✓P5 📝E5 | LOPEZ RODRIGUEZ, NICOLAS (CITIM11)\n",
      "✓P3 ❌E3 | ✓P5 ❌E5 | LOVICARIO RODRIGUEZ, SEBASTIAN (CITIM11)\n",
      "✗P3 ❌E3 | ✗P5 ❌E5 | LOZANO FUENTES, JULEN (CITIM11)\n",
      "✗P3 ❌E3 | ✗P5 ❌E5 | LOZANO JUAREZ, ALVARO (CITIM11)\n",
      "✓P3 📝E3 | ✓P5 📝E5 | LUCERO PRADA, IRENE (CITIM11)\n",
      "✗P3 ❌E3 | ✗P5 ❌E5 | LUQUE FERNANDEZ, IVAN (CITIM11)\n",
      "✓P3 ❌E3 | ✓P5 ❌E5 | MAESO BALLANO, ALVARO (CITIT11)\n",
      "✗P3 ❌E3 | ✗P5 ❌E5 | MAGANTO PABLO, SERGIO (CITIM11)\n",
      "✗P3 ❌E3 | ✓P5 📝E5 | MAQUEDA IRUN, HECTOR (CITIM11)\n",
      "✓P3 ❌E3 | ✓P5 ❌E5 | MARTIN CORCHON, ANTONIO (CITIT11)\n",
      "✗P3 ❌E3 | ✓P5 ❌E5 | MARTIN OLIVERO, IRENE (CITIM11)\n",
      "✗P3 ❌E3 | ✗P5 ❌E5 | MARTIN SANCHEZ, SERGIO (CITIM11)\n",
      "✗P3 ❌E3 | ✗P5 ❌E5 | MARTIN SEPULVEDA, ADRIAN (CITIM11)\n",
      "✓P3 📝E3 | ✓P5 📝E5 | MASSERA SALCEDO, GUILLERMO (CITIM11)\n",
      "✓P3 ❌E3 | ✓P5 ❌E5 | MATEOS SOLIS, ALVARO (CITIT11)\n",
      "✗P3 ❌E3 | ✓P5 ❌E5 | MEDINA GONZALEZ, ENRIQUE (CITIM11)\n",
      "✗P3 ❌E3 | ✗P5 ❌E5 | MELENDEZ PEREYRA, SANDRA CAROLINA (CITIM11)\n",
      "✗P3 ❌E3 | ✓P5 📝E5 | MIER DIAZ DE ARCAYA, JUAN (CITIM11)\n",
      "✓P3 ❌E3 | ✓P5 ❌E5 | MILANES VIDAL, MANUEL ALEJANDRO (CITIM11)\n",
      "✗P3 ❌E3 | ✓P5 📝E5 | MILLAN ARRANZ, DAVID (CITIM11)\n",
      "✗P3 ❌E3 | ✗P5 ❌E5 | MIRANZO HERRAIZ, ALVARO (CITIM11)\n",
      "✗P3 ❌E3 | ✓P5 ❌E5 | MOLERO RUIZ, MOISES (CITIT11)\n",
      "✗P3 ❌E3 | ✗P5 ❌E5 | MONTOYA RAMOS, DENIS ORLANDO (CITIT11)\n",
      "✗P3 ❌E3 | ✓P5 📝E5 | MORALES DE LUIS, JAVIER (CITIM11)\n",
      "✓P3 📝E3 | ✓P5 📝E5 | MORAN RUIZ, JAIME (CITIM11)\n",
      "✗P3 ❌E3 | ✗P5 ❌E5 | MORENO GONZALEZ, LUIS (CITIM11)\n",
      "✗P3 ❌E3 | ✗P5 📝E5 | MORENO MARTIN, ADRIAN (CITIM11)\n",
      "✗P3 ❌E3 | ✓P5 📝E5 | MORENO PULIDO, ADRIAN (CITIM11)\n",
      "✗P3 ❌E3 | ✓P5 📝E5 | MORENO SANCHO, SANDRA (CITIM11)\n",
      "✗P3 ❌E3 | ✓P5 ❌E5 | MUÑOZ FANDIÑO, ALEJANDRA MARIA (CITIM11)\n",
      "✗P3 ❌E3 | ✗P5 ❌E5 | MUQUINCHE CUMBAL, ANDY RUBEN (CITIM11)\n",
      "✗P3 ❌E3 | ✗P5 ❌E5 | NAVARRO MUÑOZ, JAVIER (CITIM11)\n",
      "✓P3 📝E3 | ✓P5 📝E5 | NAZARENKO, KSENIA (CITIM11)\n",
      "✓P3 📝E3 | ✓P5 ❌E5 | NIETO HERNANDEZ, JAVIER (CITIM11)\n",
      "✗P3 ❌E3 | ✓P5 ❌E5 | NUÑEZ GONZALEZ, ARANCHA (CITIM11)\n",
      "✗P3 ❌E3 | ✓P5 📝E5 | OLIVA RODRIGUEZ, EDUARDO (CITIM11)\n",
      "✗P3 ❌E3 | ✗P5 ❌E5 | OLMEDO GUERRA, JAVIER (CITIT11)\n",
      "✗P3 ❌E3 | ✗P5 ❌E5 | ORS RODRIGUEZ, ALEJANDRO (CITIM11)\n",
      "✓P3 ❌E3 | ✓P5 ❌E5 | ORTEGA RODRIGUEZ, CRISTINA (CITIT11)\n",
      "✗P3 ❌E3 | ✗P5 ❌E5 | PALOMARES JUNQUERA, JOAN (CITIM11)\n",
      "✗P3 ❌E3 | ✓P5 📝E5 | PALOMERA MARTIN, CARLOS (CITIM12)\n",
      "✗P3 ❌E3 | ✓P5 📝E5 | PANIS MARAMBA, TRISHALYN (CITIM12)\n",
      "✓P3 📝E3 | ✓P5 📝E5 | PAREJAS LAMBAN, DAVID (CITIM12)\n",
      "✓P3 ❌E3 | ✓P5 📝E5 | PARIENTE CARRIAZO, ANTONIO (CITIM11)\n",
      "✗P3 ❌E3 | ✗P5 ❌E5 | PASTOR GALINDO, JAVIER (CITIT11, Profesores)\n",
      "✗P3 ❌E3 | ✓P5 ❌E5 | PAZ MENDEZ, SANTIAGO ALEXANDER (CITIM11)\n",
      "✗P3 ❌E3 | ✗P5 ❌E5 | PELAEZ RODRIGUEZ, TERESA (CITIT11)\n",
      "✗P3 ❌E3 | ✓P5 ❌E5 | PEÑAS PIQUERAS, LORENA (CITIT11)\n",
      "✗P3 ❌E3 | ✓P5 ❌E5 | PEREZ GARCIA, CARLOS (CITIT11)\n",
      "✗P3 ❌E3 | ✓P5 ❌E5 | PEREZ SALDAÑA, ADRIAN (CITIT11)\n",
      "✗P3 ❌E3 | ✗P5 ❌E5 | PILLAJO SANCHEZ, VICTOR ADRIAN (CITIM11)\n",
      "✗P3 ❌E3 | ✗P5 ❌E5 | PINTO NIETO, CARLOS (CITIM11)\n",
      "✗P3 ❌E3 | ✓P5 ❌E5 | PLAZA GONZALO, PABLO (CITIT11)\n",
      "✗P3 📝E3 | ✗P5 📝E5 | PLAZA PASCUAL, LUCAS (CITIM12)\n",
      "✓P3 ❌E3 | ✓P5 ❌E5 | POSE COSTA, JUAN FRANCISCO (CITIM12)\n",
      "✗P3 ❌E3 | ✗P5 ❌E5 | PRIETO HERNANDEZ, MIGUEL (CITIT11)\n",
      "✗P3 ❌E3 | ✗P5 ❌E5 | PUEBLA LOPEZ, JAVIER (CITIM12)\n",
      "✓P3 📝E3 | ✓P5 📝E5 | PUEBLA MARTINEZ, FELIX (CITIM12)\n",
      "✗P3 ❌E3 | ✓P5 ❌E5 | QEFALIA PULACI, ALBA (CITIT11)\n",
      "✗P3 ❌E3 | ✗P5 ❌E5 | QIU, KAIYI (CITIT11)\n",
      "✗P3 ❌E3 | ✓P5 ❌E5 | REIG GUERRERO, JOSE LUIS (CITIT11)\n",
      "✗P3 ❌E3 | ✗P5 ❌E5 | REQUENA ARECHABALA, MIGUEL (CITIM12)\n",
      "✗P3 ❌E3 | ✓P5 ❌E5 | RIESGO MARTIN, JAIME (CITIT11)\n",
      "✓P3 📝E3 | ✓P5 📝E5 | RODRIGUES ARROYO, HECTOR (CITIM12)\n",
      "✗P3 ❌E3 | ✗P5 ❌E5 | RODRIGUEZ APARICIO, PEDRO (CITIM11)\n",
      "✗P3 ❌E3 | ✗P5 ❌E5 | RODRIGUEZ DIAZ, HUGO (CITIM12)\n",
      "✗P3 ❌E3 | ✗P5 ❌E5 | RODRIGUEZ FERNANDEZ, VICTOR (CITIM12, Profesores)\n",
      "✗P3 ❌E3 | ✗P5 ❌E5 | RODRIGUEZ GIMENEZ, MARCOS (CITIM12)\n",
      "✗P3 ❌E3 | ✓P5 ❌E5 | RODRIGUEZ HORCAJO, PAULA (CITIM12)\n",
      "✗P3 ❌E3 | ✗P5 ❌E5 | RODRIGUEZ MARTIN, MARIO DANIEL (CITIT11)\n",
      "✗P3 ❌E3 | ✓P5 📝E5 | RODRIGUEZ MARTIN, RUBEN (CITIM11)\n",
      "✓P3 📝E3 | ✗P5 📝E5 | RODRIGUEZ RAMOS, CARLOS (CITIM11)\n",
      "✓P3 ❌E3 | ✗P5 ❌E5 | RODRIGUEZ SOGORB, VIRGINIA (CITIM12)\n",
      "✓P3 ❌E3 | ✓P5 ❌E5 | ROJAS TENA, LUCAS (CITIT11)\n",
      "✗P3 ❌E3 | ✗P5 ❌E5 | ROMERO KAUSS, ALVARO DANIEL (CITIM11)\n",
      "✗P3 ❌E3 | ✓P5 📝E5 | ROMO TAMAME, EVA (CITIM12)\n",
      "✓P3 ❌E3 | ✗P5 ❌E5 | SAEZ TENORIO, MAURO (CITIM12)\n",
      "✓P3 📝E3 | ✓P5 📝E5 | SALVADOR GARCIA, MARCOS (CITIM12)\n",
      "✗P3 ❌E3 | ✗P5 ❌E5 | SANCHEZ FERNANDEZ, LUCIA (CITIM12)\n",
      "✗P3 ❌E3 | ✓P5 ❌E5 | SANCHEZ GONZALEZ, SERGIO (CITIM11)\n",
      "✗P3 ❌E3 | ✗P5 ❌E5 | SANCHEZ HERRERA, MIGUEL (CITIM12)\n",
      "✗P3 ❌E3 | ✗P5 ❌E5 | SANCHEZ LUCENA, ANGEL (CITIM12)\n",
      "✗P3 ❌E3 | ✗P5 ❌E5 | SANCHEZ PRIETO, IVAN (CITIM12)\n",
      "✓P3 ❌E3 | ✓P5 ❌E5 | SANCHEZ PRUDENCIO, RICARDO (CITIT11)\n",
      "✗P3 ❌E3 | ✓P5 ❌E5 | SANCHEZ SANTANA, JHON LEUDY (CITIM12)\n",
      "✗P3 ❌E3 | ✗P5 ❌E5 | SANTAMARIA VALENZUELA, MARIA INMACULADA (CITIM11, CITIM12, Profesores)\n",
      "✓P3 ❌E3 | ✓P5 ❌E5 | SANTILLANA VIZCAYA, DIEGO (CITIM12)\n",
      "✗P3 ❌E3 | ✓P5 📝E5 | SANZ COLON, ADRIANA (CITIM12)\n",
      "✓P3 📝E3 | ✓P5 📝E5 | SANZ PASTOR, SANTIAGO (CITIM12)\n",
      "✗P3 ❌E3 | ✗P5 ❌E5 | SAONER PLOMER, ALBERTO (CITIM12)\n",
      "✓P3 📝E3 | ✓P5 📝E5 | SEGOVIA GUTIERREZ, ANGEL (CITIM12)\n",
      "✓P3 📝E3 | ✓P5 📝E5 | SEÑORANS DAVILA, JAVIER (CITIM12)\n",
      "✓P3 ❌E3 | ✓P5 ❌E5 | SERNA QUINTERO, JUAN JOSE (CITIM12)\n",
      "✗P3 ❌E3 | ✗P5 ❌E5 | SIMARRO PINES, LUCAS (CITIT11)\n",
      "✗P3 ❌E3 | ✓P5 ❌E5 | SUAREZ SALGADO, SOFIA MENGYUAN (CITIM11)\n",
      "✗P3 ❌E3 | ✓P5 ❌E5 | TARRILLO MUNDACA, JORGE AUGUSTO (CITIM11)\n",
      "✗P3 ❌E3 | ✗P5 ❌E5 | TAYPE MUNDACA, MARIO FERNANDO (CITIT11)\n",
      "✗P3 ❌E3 | ✓P5 📝E5 | TERESO SILVA, LUIS (CITIM11)\n",
      "✓P3 📝E3 | ✓P5 📝E5 | TORRES SAN FELIPE, GUILLERMO (CITIM12)\n",
      "✗P3 ❌E3 | ✓P5 📝E5 | TRUBITSIN GAVRILOV, ALEX (CITIM12)\n",
      "✓P3 📝E3 | ✓P5 📝E5 | TRULL GONZALEZ, SARA (CITIM11)\n",
      "✗P3 ❌E3 | ✗P5 ❌E5 | TSUTSUI GEY, KEISHI (CITIT11)\n",
      "✗P3 ❌E3 | ✗P5 ❌E5 | VARELA SERROUKH, ELIAS (CITIM12)\n",
      "✗P3 ❌E3 | ✗P5 ❌E5 | VAZQUEZ MASERO, SERGIO (CITIM11)\n",
      "✗P3 ❌E3 | ✓P5 ❌E5 | VICENTE NAVARRE, MARIO (CITIT11)\n",
      "✗P3 ❌E3 | ✗P5 ❌E5 | WANG, TIANLE (CITIM12)\n",
      "✗P3 ❌E3 | ✗P5 ❌E5 | WU, YA-PENG (CITIM11)\n",
      "✗P3 ❌E3 | ✗P5 📝E5 | XIA, OSCAR (CITIM12)\n",
      "✗P3 ❌E3 | ✓P5 📝E5 | XU, HAOYUAN (CITIM11)\n",
      "✓P3 ❌E3 | ✓P5 ❌E5 | YE, SHU LAI (CITIT11)\n",
      "✗P3 ❌E3 | ✓P5 ❌E5 | YIN, JUNJIE (CITIM11)\n",
      "✗P3 ❌E3 | ✗P5 ❌E5 | ZEGGAF EL MRABET, OMAR (CITIM12)\n",
      "✗P3 ❌E3 | ✗P5 ❌E5 | ZHANG, HAOQING (CITIT11)\n",
      "✓P3 ❌E3 | ✓P5 📝E5 | ZHANG, JIONGHAO (CITIM12)\n",
      "✗P3 ❌E3 | ✓P5 ❌E5 | ZHANG XIA, STEVEN WEI (CITIT11)\n",
      "✗P3 ❌E3 | ✓P5 ❌E5 | ZHOU, YI (CITIT11)\n",
      "✗P3 ❌E3 | ✓P5 📝E5 | ZOU, XURUI (CITIM12)\n",
      "==================================================\n",
      "RESUMEN:\n",
      "Total alumnos verificados: 444\n",
      "Práctica 3 - Entregadas: 92 | No entregadas: 352\n",
      "Práctica 5 - Entregadas: 302 | No entregadas: 142\n",
      "Examen 3 - Presentados: 50 | No presentados: 394\n",
      "Examen 5 - Presentados: 143 | No presentados: 301\n"
     ]
    }
   ],
   "source": [
    "df_students_info_full = verificar_todas_las_practicas(\n",
    "    df_students,\n",
    "    ruta_data=\"../data\",\n",
    "    #grupo_filtro=\"IWSIM11\",\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fce67fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_students_info_full.to_excel(\n",
    "    \"../data/df_students_info_full.xlsx\",\n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b7ed9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
