{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# core\n",
    "\n",
    "> Fill in a module description here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import base64\n",
    "import tiktoken\n",
    "import base64\n",
    "import io\n",
    "import json\n",
    "import os\n",
    "from pdf2image import convert_from_path\n",
    "import PyPDF2\n",
    "import requests\n",
    "import shutil\n",
    "from fastcore.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def split_pdf(file_path, every=1, until=None, output_folder=None):\n",
    "    \"\"\"\n",
    "    Split a PDF file into multiple smaller PDF files.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): The path to the input PDF file.\n",
    "        every (int, optional): The interval at which to split the PDF. Default is 1.\n",
    "        until (int, optional): The page number until which to split the PDF. Default is None.\n",
    "        output_folder (str, optional): The folder where the split PDF files will be saved. Default is None.\n",
    "\n",
    "    Returns:\n",
    "        int: The number of splits performed.\n",
    "\n",
    "    \"\"\"\n",
    "    pdf_file = PyPDF2.PdfFileReader(file_path)\n",
    "    pdf_writer = PyPDF2.PdfFileWriter()\n",
    "\n",
    "    num_splits = 0\n",
    "    for page in range(pdf_file.getNumPages()):\n",
    "        pdf_writer.addPage(pdf_file.getPage(page))\n",
    "\n",
    "        # If it's the n page or the 'until' page, save the current selection\n",
    "        if until is None:\n",
    "            until = pdf_file.getNumPages()\n",
    "        if output_folder is None:\n",
    "            output_folder = os.path.dirname(file_path)\n",
    "        basename = os.path.splitext(os.path.basename(file_path))[0]\n",
    "        if page % every == 0 or page == until:\n",
    "            output_file = f\"{output_folder}/{basename}_page_{page}.pdf\"\n",
    "            with open(output_file, \"wb\") as out:\n",
    "                pdf_writer.write(out)\n",
    "            pdf_writer = PyPDF2.PdfFileWriter()\n",
    "            num_splits += 1\n",
    "    return num_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "path = '../example_data/1.pdf'\n",
    "foo = split_pdf(path, 1)\n",
    "test_eq(foo, 2)\n",
    "# remove temporary files\n",
    "for f in os.listdir(os.path.dirname(path)):\n",
    "    if f.startswith('1_page_'):\n",
    "        os.remove(f'{os.path.dirname(path)}/{f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def encode_image(image_path):\n",
    "  \"\"\"Function to encode the image\"\"\"\n",
    "  with open(image_path, \"rb\") as image_file:\n",
    "    return base64.b64encode(image_file.read()).decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "image_path = '../example_data/1.jpg'\n",
    "image_base64 = encode_image(image_path)\n",
    "test_eq_type(type(image_base64), str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def num_tokens_from_messages(messages, model=\"gpt-3.5-turbo-0613\"):\n",
    "  \"\"\"Returns the number of tokens used by a list of messages.\"\"\"\n",
    "  try:\n",
    "      encoding = tiktoken.encoding_for_model(model)\n",
    "  except KeyError:\n",
    "      encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "  if model == \"gpt-3.5-turbo-0613\":  # note: future models may deviate from this\n",
    "      num_tokens = 0\n",
    "      for message in messages:\n",
    "          num_tokens += 4  # every message follows <im_start>{role/name}\\n{content}<im_end>\\n\n",
    "          for key, value in message.items():\n",
    "              num_tokens += len(encoding.encode(value))\n",
    "              if key == \"name\":  # if there's a name, the role is omitted\n",
    "                  num_tokens += -1  # role is always required and always 1 token\n",
    "      num_tokens += 2  # every reply is primed with <im_start>assistant\n",
    "      return num_tokens\n",
    "  else:\n",
    "      raise NotImplementedError(f\"\"\"num_tokens_from_messages() is not presently implemented for model {model}.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "351620"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test\n",
    "image_path = '../example_data/1.jpg'\n",
    "base64_image = encode_image(image_path)\n",
    "messages = [{\"role\": \"user\", \"content\": \"Hello, how are you?\", \"image\": base64_image}]\n",
    "num_tokens = num_tokens_from_messages(messages)\n",
    "num_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "DEFAULT_SYSTEM_PROMPT = (\"You are a helpful assistant designed to see an exam and output JSON \\\n",
    "with the extracted information. You will be given an image of the exam.\")\n",
    "\n",
    "DEFAULT_USER_PROMPT = (\"Extract the last name (Apellidos in Spanish) and the first name \\\n",
    "(Nombre in Spanish) from the top of the image, and turn them into upper case. \\\n",
    "You will find them handwritten after the labels `Apellidos` and `Nombre` respectively. \\\n",
    "The fields of your JSON output will have those exact same label names\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def extract_student_info(path_pdf: str, crop=None, api_key = None, \n",
    "                 model=\"gpt-4o\", prompt=DEFAULT_USER_PROMPT, \n",
    "                 system_prompt=DEFAULT_SYSTEM_PROMPT, verbose=False):\n",
    "    \"\"\"\n",
    "    Extracts student information from a PDF file using OpenAI's chatGPT.\n",
    "\n",
    "    Args:\n",
    "        path_pdf (str): The path to the PDF file.\n",
    "        crop (tuple, optional): Tuple with the coordinates of the crop (left, top, right, bottom).\n",
    "        api_key (str, optional): The API key for accessing the OpenAI API. If \n",
    "            not provided, the function will try to use the OPENAI_API_KEY environment variable.\n",
    "        model (str, optional): The model to use for generating responses.\n",
    "        prompt (str, optional): The user prompt to start the conversation.\n",
    "        system_prompt (str, optional): The system prompt to provide context to the model.\n",
    "        verbose (bool, optional): Whether to print information about the process.\n",
    "\n",
    "    Returns:\n",
    "        str: The extracted information from the PDF.\n",
    "\n",
    "    Raises:\n",
    "        KeyError: If the OPENAI_API_KEY environment variable is not set.\n",
    "        IndexError: If the response from the OpenAI API does not contain any choices.\n",
    "\n",
    "    \"\"\"\n",
    "    with open(path_pdf, 'rb') as file:\n",
    "        pdf = PyPDF2.PdfFileReader(file)\n",
    "\n",
    "        # Check if the PDF has more than one page\n",
    "        if pdf.getNumPages() > 1 and verbose:\n",
    "            print(\"The PDF has more than one page. Only the first page will be \\\n",
    "                  converted to an image.\")\n",
    "        \n",
    "        # Convert the PDF to images and get the first one\n",
    "        image = convert_from_path(path_pdf, last_page=1, first_page=0, fmt='jpeg')[0]\n",
    "\n",
    "        # Crop the image\n",
    "        if crop:\n",
    "            image = image.crop(crop)\n",
    "        \n",
    "        # Convert to base64\n",
    "        buffered = io.BytesIO()\n",
    "        image.save(buffered, format=\"JPEG\")\n",
    "        base64_image = base64.b64encode(buffered.getvalue()).decode('utf-8')\n",
    "\n",
    "        headers = {\n",
    "            \"Content-Type\": \"application/json\",\n",
    "            \"Authorization\": f\"Bearer {ifnone(api_key, os.environ.get('OPENAI_API_KEY'))}\"\n",
    "        }\n",
    "        payload = {\n",
    "            \"model\": f'{model}',\n",
    "            \"response_format\": { \"type\": \"json_object\" },\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"system\", \n",
    "                    \"content\": f\"{system_prompt}\",   \n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\n",
    "                            \"type\": \"text\",\n",
    "                            \"text\": f\"{prompt}\"\n",
    "                        },\n",
    "                        {\n",
    "                            \"type\": \"image_url\",\n",
    "                            \"image_url\": {\n",
    "                                \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "                            }\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "            ],\n",
    "            \"max_tokens\": 300\n",
    "        }\n",
    "        response = requests.post(\"https://api.openai.com/v1/chat/completions\", \n",
    "                                 headers=headers, json=payload)\n",
    "        \n",
    "        return json.loads(response.json()['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Apellidos': 'RODRIGUEZ FERNANDEZ', 'Nombre': 'VICTOR'}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test\n",
    "path_pdf = '../example_data/1.pdf'\n",
    "info = extract_student_info(path_pdf)\n",
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@delegates(extract_student_info)\n",
    "def rename_exam_file(pdf_path: str, output_path: str, keep_old=True, **kwargs):\n",
    "    \"\"\"\n",
    "    Extracts student information from an exam PDF file using OpenAI's chatGPT and renames that\n",
    "    file with the extracted information as the name.\n",
    "\n",
    "    Parameters:\n",
    "    - pdf_path (str): The path to the input PDF file.\n",
    "    - output_path (str): The path to the directory where the renamed file will be saved.\n",
    "    - **kwargs: Additional keyword arguments to be passed to the `extract_student_info` function.\n",
    "    - keep_old (bool): Whether to keep the old file or not.\n",
    "\n",
    "    Returns:\n",
    "    - new_name (str): The new name of the renamed file.\n",
    "\n",
    "    Example:\n",
    "    >>> rename_exam_file('/path/to/input.pdf', '/path/to/output', option1='value1', option2='value2')\n",
    "    'Doe_John.pdf'\n",
    "    \"\"\"\n",
    "    info = extract_student_info(pdf_path, **kwargs)\n",
    "    new_name = f\"{info['Apellidos']}_{info['Nombre']}.pdf\"\n",
    "    new_file_path = os.path.join(output_path, new_name)\n",
    "    if not keep_old:\n",
    "        os.rename(pdf_path, new_file_path)\n",
    "    else:\n",
    "        os.makedirs(output_path, exist_ok=True)\n",
    "        shutil.copy(pdf_path, new_file_path)\n",
    "        \n",
    "    return new_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RODRIGUEZ FERNANDEZ_VICTOR.pdf'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test renaming without keeping old file\n",
    "path_pdf = '../example_data/1.pdf'\n",
    "output_path = '../example_data'\n",
    "new_name = rename_exam_file(pdf_path=path_pdf, output_path=output_path, keep_old=False)\n",
    "new_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
