{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# core\n",
    "\n",
    "> Fill in a module description here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import tiktoken\n",
    "import base64\n",
    "import io\n",
    "import json\n",
    "from pdf2image import convert_from_path\n",
    "import PyPDF2\n",
    "import os\n",
    "import base64\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def encode_image(image_path):\n",
    "  \"\"\"Function to encode the image\"\"\"\n",
    "  with open(image_path, \"rb\") as image_file:\n",
    "    return base64.b64encode(image_file.read()).decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "image_path = '../example_data/1.jpg'\n",
    "image_base64 = encode_image(image_path)\n",
    "test_eq_type(type(image_base64), str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def num_tokens_from_messages(messages, model=\"gpt-3.5-turbo-0613\"):\n",
    "  \"\"\"Returns the number of tokens used by a list of messages.\"\"\"\n",
    "  try:\n",
    "      encoding = tiktoken.encoding_for_model(model)\n",
    "  except KeyError:\n",
    "      encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "  if model == \"gpt-3.5-turbo-0613\":  # note: future models may deviate from this\n",
    "      num_tokens = 0\n",
    "      for message in messages:\n",
    "          num_tokens += 4  # every message follows <im_start>{role/name}\\n{content}<im_end>\\n\n",
    "          for key, value in message.items():\n",
    "              num_tokens += len(encoding.encode(value))\n",
    "              if key == \"name\":  # if there's a name, the role is omitted\n",
    "                  num_tokens += -1  # role is always required and always 1 token\n",
    "      num_tokens += 2  # every reply is primed with <im_start>assistant\n",
    "      return num_tokens\n",
    "  else:\n",
    "      raise NotImplementedError(f\"\"\"num_tokens_from_messages() is not presently implemented for model {model}.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "351620"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test\n",
    "image_path = '../example_data/1.jpg'\n",
    "base64_image = encode_image(image_path)\n",
    "messages = [{\"role\": \"user\", \"content\": \"Hello, how are you?\", \"image\": base64_image}]\n",
    "num_tokens = num_tokens_from_messages(messages)\n",
    "num_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "DEFAULT_SYSTEM_PROMPT = \"\"\"You are a helpful assistant designed to see an exam and output JSON \\ \n",
    "with the extracted information. You will be given an image of the exam.\"\"\"\n",
    "\n",
    "DEFAULT_USER_PROMPT =\"\"\"Extract the last name (Apellidos in Spanish) and the first name (Nombre in Spanish) \\\n",
    " from the top of the image. You will find them handwritten after the labels `Apellidos` \\\n",
    " and `Nombre` respectively. The fields of your JSON output will have those exact same label names\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def extract_student_info(path_pdf: str, crop=None, api_key = None, \n",
    "                 model=\"gpt-4o\", prompt=DEFAULT_USER_PROMPT, \n",
    "                 system_prompt=DEFAULT_SYSTEM_PROMPT, verbose=False):\n",
    "    \"\"\"\n",
    "    Extracts student information from a PDF file using OpenAI's chatGPT.\n",
    "\n",
    "    Args:\n",
    "        path_pdf (str): The path to the PDF file.\n",
    "        crop (tuple, optional): Tuple with the coordinates of the crop (left, top, right, bottom).\n",
    "        api_key (str, optional): The API key for accessing the OpenAI API. If \n",
    "            not provided, the function will try to use the OPENAI_API_KEY environment variable.\n",
    "        model (str, optional): The model to use for generating responses.\n",
    "        prompt (str, optional): The user prompt to start the conversation.\n",
    "        system_prompt (str, optional): The system prompt to provide context to the model.\n",
    "        verbose (bool, optional): Whether to print information about the process.\n",
    "\n",
    "    Returns:\n",
    "        str: The extracted information from the PDF.\n",
    "\n",
    "    Raises:\n",
    "        KeyError: If the OPENAI_API_KEY environment variable is not set.\n",
    "        IndexError: If the response from the OpenAI API does not contain any choices.\n",
    "\n",
    "    \"\"\"\n",
    "    with open(path_pdf, 'rb') as file:\n",
    "        pdf = PyPDF2.PdfFileReader(file)\n",
    "\n",
    "        # Check if the PDF has more than one page\n",
    "        if pdf.getNumPages() > 1 and verbose:\n",
    "            print(\"The PDF has more than one page. Only the first page will be \\\n",
    "                  converted to an image.\")\n",
    "        \n",
    "        # Convert the PDF to images and get the first one\n",
    "        image = convert_from_path(path_pdf, last_page=1, first_page=0, fmt='jpeg')[0]\n",
    "\n",
    "        # Crop the image\n",
    "        if crop:\n",
    "            image = image.crop(crop)\n",
    "        \n",
    "        # Convert to base64\n",
    "        buffered = io.BytesIO()\n",
    "        image.save(buffered, format=\"JPEG\")\n",
    "        base64_image = base64.b64encode(buffered.getvalue()).decode('utf-8')\n",
    "\n",
    "        headers = {\n",
    "            \"Content-Type\": \"application/json\",\n",
    "            \"Authorization\": f\"Bearer {ifnone(api_key, os.environ.get('OPENAI_API_KEY'))}\"\n",
    "        }\n",
    "        payload = {\n",
    "            \"model\": f'{model}',\n",
    "            \"response_format\": { \"type\": \"json_object\" },\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"system\", \n",
    "                    \"content\": f\"{system_prompt}\",   \n",
    "                },\n",
    "                {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": f\"{prompt}\"\n",
    "                    },\n",
    "                    {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "                    }\n",
    "                    }\n",
    "                ]\n",
    "                }\n",
    "            ],\n",
    "            \"max_tokens\": 300\n",
    "        }\n",
    "        response = requests.post(\"https://api.openai.com/v1/chat/completions\", \n",
    "                                 headers=headers, json=payload)\n",
    "        \n",
    "        return json.loads(response.json()['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The PDF has more than one page. Only the first page will be                   converted to an image.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'{\\n  \"Apellidos\": \"RODRIGUEZ FERNANDEZ\",\\n  \"Nombre\": \"VICTOR\"\\n}'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test\n",
    "path_pdf = '../example_data/1.pdf'\n",
    "info = extract_student_info(path_pdf)\n",
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m\n",
      "\u001b[0mrename_exam_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mpdf_path\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0moutput_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mcrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mapi_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gpt-4o'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mprompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Extract the last name (Apellidos in Spanish) and the first name (Nombre in Spanish)\\n from the top of the image. You will find them handwritten after the labels `Apellidos` \\n and `Nombre` respectively. The fields of your JSON output will have those exact same label names'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0msystem_prompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'You are a helpful assistant designed to see an exam and output JSON     with the extracted information. You will be given an image of the exam.'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m\n",
      "Extracts student information from an exam PDF file using OpenAI's chatGPT and renames that\n",
      "file with the extracted information as the name.\n",
      "\n",
      "Parameters:\n",
      "- pdf_path (str): The path to the input PDF file.\n",
      "- output_path (str): The path to the directory where the renamed file will be saved.\n",
      "- **kwargs: Additional keyword arguments to be passed to the `extract_student_info` function.\n",
      "\n",
      "Returns:\n",
      "- new_name (str): The new name of the renamed file.\n",
      "\n",
      "Example:\n",
      ">>> rename_exam_file('/path/to/input.pdf', '/path/to/output', option1='value1', option2='value2')\n",
      "'Doe_John.pdf'\n",
      "\u001b[0;31mFile:\u001b[0m      /tmp/ipykernel_99178/384513049.py\n",
      "\u001b[0;31mType:\u001b[0m      function"
     ]
    }
   ],
   "source": [
    "rename_exam_file?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@delegates(extract_student_info)\n",
    "def rename_exam_file(pdf_path: str, output_path, **kwargs):\n",
    "    \"\"\"\n",
    "    Extracts student information from an exam PDF file using OpenAI's chatGPT and renames that\n",
    "    file with the extracted information as the name.\n",
    "\n",
    "    Parameters:\n",
    "    - pdf_path (str): The path to the input PDF file.\n",
    "    - output_path (str): The path to the directory where the renamed file will be saved.\n",
    "    - **kwargs: Additional keyword arguments to be passed to the `extract_student_info` function.\n",
    "\n",
    "    Returns:\n",
    "    - new_name (str): The new name of the renamed file.\n",
    "\n",
    "    Example:\n",
    "    >>> rename_exam_file('/path/to/input.pdf', '/path/to/output', option1='value1', option2='value2')\n",
    "    'Doe_John.pdf'\n",
    "    \"\"\"\n",
    "    info = extract_student_info(pdf_path, **kwargs)\n",
    "    new_name = f\"{info['Apellidos']}_{info['Nombre']}.pdf\"\n",
    "    os.rename(pdf_path, os.path.join(output_path, new_name))\n",
    "    return new_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "path_pdf = '../example_data/1.pdf'\n",
    "output_path = '../example_data/'\n",
    "new_name = rename_exam_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def rename_file(folder_path: str, output_path='./exam_sort_ocr', **kwargs):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    if not os.path.exists(output_path):\n",
    "        os.makedirs(output_path)\n",
    "    for file in os.listdir(folder_path):\n",
    "        if file.endswith('.pdf'):\n",
    "            path_pdf = os.path.join(folder_path, file)\n",
    "            info = extract_info(path_pdf, **kwargs)\n",
    "            info['path'] = path_pdf\n",
    "            with open(os.path.join(output_path, file.replace('.pdf', '.json')), 'w') as f:\n",
    "                json.dump(info, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
